although the internet as level topology has been extensively studied over the past few years  little is known about the details of the as taxonomy __label__MISC
an as  node  can represent a wide variety of organizations  e g   large isp  or small private business  university  with vastly different network characteristics  external connectivity patterns  network growth tendencies  and other properties that we can hardly neglect while working on veracious internet representations in simulation environments __label__MISC
in this paper  we introduce a radically new approach based on machine learning techniques to map all the ases in the internet into a natural as taxonomy __label__AIMX
we believe that this dataset will serve as an invaluable addition to further understanding of the structure and evolution of the internet __label__OWNX
the rapid expansion of the internet in the last two decades has produced a large scale system of thousands of diverse  independently managed networks that collectively provide global connectivity across a wide spectrum of geopolitical environments __label__MISC
from  NUMBER  to  NUMBER  the number of globally routable as identifiers has increased from less than  NUMBER   NUMBER  to more than  NUMBER   NUMBER   exerting significant pressure on interdomain routing as well as other functional and structural parts of the internet __label__MISC
this impressive growth has resulted in a heterogenous and highly complex system that challenges accurate and realistic modeling of the internet infrastructure __label__MISC
in particular  the as level topology is an intermix of networks owned and operated by many different organizations  e g   backbone providers  regional providers  access providers  universities and private companies __label__MISC
in topology modeling  knowledge of as types is mandatory for augmenting synthetically constructed or measured as topologies with realistic intra as and inter as router level topologies __label__MISC
the university will likely contain dozens of internal routers  thousands of hosts  and many other network elements  switches  servers  firewalls __label__MISC
since there is such a diversity among different network types  we cannot accurately augment the as level topology with appropriate router level topologies if we cannot MISC	characterize the composing ases __label__MISC
moreover  annotating the ases in the as topology with their types is a prerequisite for modeling the evolution of the internet  since different types of ases exhibit different growth patterns __label__MISC
for example  internet service providers  isp  grow by attracting new customers and by engaging in business agreements with other isps __label__MISC
on the other hand  small companies that connect to the internet through one or few isps do not grow significantly over time __label__MISC
thus  categorizing different types of ases in the internet is necessary to identify network evolution patterns and develop accurate evolution models __label__MISC
for example  in traffic analysis studies its often required to distinguish between packets that come from home and business users __label__MISC
given an as taxonomy  its possible to realize this goal by checking the type of as that originates the prefix in which an ip address lies __label__MISC
in this work  we introduce a radically new approach based on machine learning to construct a representative as taxonomy __label__AIMX
we develop an algorithm to classify ases based on empirically observed differences between as characteristics __label__OWNX
we use a large set of data from the internet routing registries  irr   CITATION  and from routeviews  CITATION  to identify intrinsic differences between ases of different types __label__OWNX
then  we employ a novel machine learning technique to build a classification algorithm that exploits these differences to classify ases into six representative classes that reflect ases with different network properties and infrastructures __label__AIMX
our validation demonstrates that our classification algorithm achieves high accuracy   NUMBER   NUMBER  percent  of the examined classifications were correct __label__OWNX
finally  we make our results and our classifier publicly available to promote further research and understanding of the internet s structure and evolution __label__OWNX
in section  we start with a brief discussion of related work __label__OWNX
section  describes the data we used  and in section  we specify the set of as classes we use in our experiments __label__OWNX
section  introduces our classification approach and results __label__OWNX
we validate them in section  and conclude in section __label__OWNX
although the internet as level topology has been extensively studied over the past few years  little is known about the details of the as taxonomy __label__MISC
in this paper  we introduce a radically new approach based on machine learning techniques to map all the ases in the internet into a natural as taxonomy __label__AIMX
we successfully classify  NUMBER   NUMBER  percent  of ases with expected accuracy of  NUMBER   NUMBER  percent __label__OWNX
we release to the community the as level topology dataset augmented with   NUMBER   the as taxonomy information and  NUMBER   the set of as attributes we used to classify ases __label__OWNX
the rapid expansion of the internet in the last two decades has produced a large scale system of thousands of diverse  independently managed networks that collectively provide global connectivity across a wide spectrum of geopolitical environments __label__MISC
from  NUMBER  to  NUMBER  the number of globally routable as identifiers has increased from less than  NUMBER   NUMBER  to more than  NUMBER   NUMBER   exerting significant pressure on interdomain routing as well as other functional and structural parts of the internet __label__MISC
this impressive growth has resulted in a heterogenous and highly complex system that challenges accurate and realistic modeling of the internet infrastructure __label__MISC
in particular  the as level topology is an intermix of networks owned and operated by many different organizations  e g   backbone providers  regional providers  access providers  universities and private companies __label__MISC
statistical information that faithfully characterizes different as types is on the critical path toward understanding the structure of the internet  as well as for modeling its topology and growth __label__MISC
in topology modeling  knowledge of as types is mandatory for augmenting synthetically constructed or measured as topologies with realistic intra as and inter as router level topologies __label__MISC
for example  we expect the network of a dual homed university to be drastically different from that of a dual homed small company __label__MISC
the university will likely contain dozens of internal routers  thousands of hosts  and many other network elements  switches  servers  firewalls __label__MISC
on the other hand  the small company will most probably have a single router and a simple network topology __label__MISC
since there is such a diversity among different network types  we cannot accurately augment the as level topology with appropriate router level topologies if we cannot characterize the composing ases __label__MISC
moreover  annotating the ases in the as topology with their types is a prerequisite for modeling the evolution of the internet  since different types of ases exhibit different growth patterns __label__MISC
on the other hand  small companies that connect to the internet through one or few isps do not grow significantly over time __label__MISC
thus  categorizing different types of ases in the internet is necessary to identify network evolution patterns and develop accurate evolution models __label__MISC
for example  in traffic analysis studies its often required to distinguish between packets that come from home and business users __label__MISC
in this work  we introduce a radically new approach based on machine learning to construct a representative as taxonomy __label__AIMX
we develop an algorithm to classify ases based on empirically observed differences between as characteristics __label__AIMX
we derive macroscopic statistics on the different types of ases in the internet and validate our results using a sample of  NUMBER  manually identified as types __label__OWNX
our validation demonstrates that our classification algorithm achieves high accuracy   NUMBER   NUMBER  percent  of the examined classifications were correct __label__OWNX
finally  we make our results and our classifier publicly available to promote further research and understanding of the internet s structure and evolution __label__OWNX
in section  we start with a brief discussion of related work __label__BASE
section  describes the data we used  and in section  we specify the set of as classes we use in our experiments __label__OWNX
An AS "node" can represent a wide variety of organizations, e g , large ISP, or small private business, university, with vastly different network characteristics, external connectivity patterns, network growth tendencies, and other properties that we can hardly neglect while working on veracious Internet representations in simulation environments __label__MISC
In this paper, we introduce a radically new approach based on machine learning techniques to map all the ASes in the Internet into a natural AS taxonomy __label__AIMX
We release to the community the AS-level topology dataset augmented with: 1) the AS taxonomy information and 2) the set of AS attributes we used to classify ASes __label__OWNX
We believe that this dataset will serve as an invaluable addition to further understanding of the structure and evolution of the Internet __label__OWNX
The rapid expansion of the Internet in the last two decades has produced a large-scale system of thousands of diverse, independently managed networks that collectively provide global connectivity across a wide spectrum of geopolitical environments __label__MISC
From 1997 to 2005 the number of globally routable AS identifiers has increased from less than 2,000 to more than 20,000, exerting significant pressure on interdomain routing as well as other functional and structural parts of the Internet __label__MISC
This impressive growth has resulted in a heterogenous and highly complex system that challenges accurate and realistic modeling of the Internet infrastructure __label__MISC
In particular, the AS-level topology is an intermix of networks owned and operated by many different organizations, e g , backbone providers, regional providers, access providers, universities and private companies __label__MISC
Statistical information that faithfully characterizes different AS types is on the critical path toward understanding the structure of the Internet, as well as for modeling its topology and growth __label__MISC
In topology modeling, knowledge of AS types is mandatory for augmenting synthetically constructed or measured AS topologies with realistic intra-AS and inter-AS router-level topologies __label__MISC
The university will likely contain dozens of internal routers, thousands of hosts, and many other network elements (switches, servers, firewalls) __label__MISC
On the other hand, the small company will most probably have a single router and a simple network topology __label__MISC
Moreover, annotating the ASes in the AS topology with their types is a prerequisite for modeling the evolution of the Internet, since different types of ASes exhibit different growth patterns __label__MISC
For example, Internet Service Providers (ISP) grow by attracting new customers and by engaging in business agreements with other ISPs __label__MISC
On the other hand, small companies that connect to the Internet through one or few ISPs do not grow significantly over time __label__MISC
Thus, categorizing different types of ASes in the Internet is necessary to identify network evolution patterns and develop accurate evolution models __label__MISC
An AS taxonomy is also necessary for mapping IP addresses to different types of users __label__MISC
For example, in traffic analysis studies its often required to distinguish between packets that come from home and business users __label__MISC
Given an AS taxonomy, its possible to realize this goal by checking the type of AS that originates the prefix in which an IP address lies __label__MISC
In this work, we introduce a radically new approach based on machine learning to construct a representative AS taxonomy __label__AIMX
We develop an algorithm to classify ASes based on empirically observed differences between AS characteristics __label__OWNX
We use a large set of data from the Internet Routing Registries~(IRR)~ CITATION  and from RouteViews~ CITATION  to identify intrinsic differences between ASes of different types __label__BASE
Then, we employ a novel machine learning technique to build a classification algorithm that exploits these differences to classify ASes into six representative classes that reflect ASes with different network properties and infrastructures __label__OWNX
Our validation demonstrates that our classification algorithm achieves high accuracy:~78 1\% of the examined classifications were correct __label__OWNX
Finally, we make our results and our classifier publicly available to promote further research and understanding of the Internet's structure and evolution __label__OWNX
Section~ describes the data we used, and in Section~ we specify the set of AS classes we use in our experiments __label__OWNX
Section~ introduces our classification approach and results __label__OWNX
We validate them in Section~ and conclude in Section~ __label__OWNX
The Minimum Description Length principle for online sequence estimation/prediction in a proper learning setup is studied __label__MISC
If the underlying model class is discrete, then the total expected square loss is a particularly interesting performance measure: (a) this quantity is finitely bounded, implying convergence with probability one, and (b) it additionally specifies the convergence speed __label__MISC
For MDL, in general one can only have loss bounds which are finite but exponentially larger than those for Bayes mixtures __label__MISC
We show that this is even the case if the model class contains only Bernoulli distributions __label__AIMX
We derive a new upper bound on the prediction error for countable Bernoulli classes __label__OWNX
This implies a small bound (comparable to the one for Bayes mixtures) for certain important model classes __label__OWNX
We discuss the application to Machine Learning tasks such as classification and hypothesis testing, and generalization to countable classes of iid models __label__OWNX
``Bayes mixture", ``Solomonoff induction", ``marginalization", all these terms refer to a central induction principle: Obtain a predictive distribution by integrating the product of prior and evidence over the model class __label__MISC
In many cases however, the Bayes mixture is computationally infeasible, and even a sophisticated approximation is expensive __label__CONT
The MDL or MAP (maximum a posteriori) estimator is both a common approximation for the Bayes mixture and interesting for its own sake: Use the model with the largest product of prior and evidence __label__MISC
In practice, the MDL estimator is usually being approximated too, since only a local maximum is determined __label__MISC
How good are the predictions by Bayes mixtures and MDL __label__MISC
This question has attracted much attention __label__MISC
In many cases, an important quality measure is the  total  or cumulative  expected loss  of a predictor __label__MISC
In particular the square loss is often considered __label__MISC
Assume that the outcome space is finite, and the model class is continuously parameterized __label__MISC
Then for Bayes mixture prediction, the cumulative expected square loss is usually small but unbounded, growing with  SYMBOL , where  SYMBOL  is the sample size  CITATION __label__MISC
This corresponds to an  instantaneous  loss bound of  SYMBOL __label__MISC
For the MDL predictor, the losses behave similarly  CITATION  under appropriate conditions, in particular with a specific prior __label__MISC
Note that in order to do MDL for continuous model classes, one needs to  discretize  the parameter space, see also  CITATION __label__MISC
On the other hand, if the model class is discrete, then Solomonoff's theorem  CITATION  bounds the cumulative expected square loss for the Bayes mixture predictions finitely, namely by  SYMBOL , where  SYMBOL  is the prior weight of the ``true" model  SYMBOL __label__MISC
The only necessary assumption is that the true distribution  SYMBOL  is contained in the model class, ie that we are dealing with  proper learning __label__MISC
It has been demonstrated  CITATION , that for both Bayes mixture and MDL, the proper learning assumption can be essential: If it is violated, then learning may fail very badly __label__MISC
For MDL predictions in the proper learning case, it has been shown  CITATION  that a bound of  SYMBOL  holds __label__MISC
This bound is exponentially larger than the Solomonoff bound, and it is sharp in general __label__MISC
A finite bound on the total expected square loss is particularly interesting:   It implies convergence of the predictive to the true probabilities with probability one __label__MISC
In contrast, an instantaneous loss bound of  SYMBOL  implies only convergence in probability __label__MISC
Additionally, it gives a  convergence speed , in the sense that errors of a certain magnitude cannot occur too often __label__MISC
So for both, Bayes mixtures and MDL, convergence with probability one holds, while the convergence speed is exponentially worse for MDL compared to the Bayes mixture __label__MISC
We avoid the term ``convergence rate" here, since the order of convergence is identical in both cases __label__MISC
It is therefore natural to ask if there are model classes where the cumulative loss of MDL is comparable to that of Bayes mixture predictions __label__MISC
In the present work, we concentrate on the simplest possible stochastic case, namely discrete Bernoulli classes __label__AIMX
Note that then the MDL ``predictor" just becomes an estimator, in that it estimates the true parameter and directly uses that for prediction __label__OWNX
Nevertheless, for consistency of terminology, we keep the term predictor __label__OWNX
It might be surprising to discover that in general the cumulative loss is still exponential __label__MISC
On the other hand, we will give mild conditions on the prior guaranteeing a small bound __label__OWNX
Moreover, it is well-known that the instantaneous square loss of the Maximum Likelihood estimator decays as  SYMBOL  in the Bernoulli case __label__MISC
The same holds for MDL, as we will see __label__MISC
If convergence speed is measured in terms of instantaneous losses, then much more general statements are possible  CITATION , this is briefly discussed in Section __label__MISC
A particular motivation to consider discrete model classes arises in Algorithmic Information Theory __label__MISC
From a computational point of view, the largest relevant model class is the class of all computable models on some fixed universal Turing machine, precisely prefix machine  CITATION __label__MISC
Thus each model corresponds to a program, and there are countably many programs __label__MISC
Moreover, the models are stochastic, precisely they are  semimeasures  on strings (programs need not halt, otherwise the models were even measures) __label__MISC
Each model has a natural description length, namely the length of the corresponding program __label__MISC
By the Kraft inequality, the priors sum up to at most one __label__MISC
Also the Bernoulli case can be studied in the view of Algorithmic Information Theory __label__MISC
We call this the  universal setup : Given a universal Turing machine, the related class of Bernoulli distributions is isomorphic to the countable set of computable reals in  SYMBOL __label__MISC
The description length  SYMBOL  of a parameter  SYMBOL  is then given by the length of its shortest program __label__MISC
A prior weight may then be defined by  SYMBOL __label__MISC
That is, the two-part complexity with respect to the Bernoulli class  is  the shortest description, save for an additive constant __label__MISC
Many Machine Learning tasks are or can be reduced to sequence prediction tasks __label__MISC
An important example is classification __label__MISC
The task of classifying a new instance  SYMBOL  after having seen (instance,class) pairs  SYMBOL  can be phrased as to predict the continuation of the sequence  SYMBOL __label__MISC
Typically the (instance,class) pairs are iid __label__MISC
Cumulative loss bounds for prediction usually generalize to prediction  conditionalized  to some inputs  CITATION __label__MISC
Then we can solve classification problems in the standard form __label__MISC
It is not obvious if and how the proofs in this paper can be conditionalized __label__OWNX
Our main tool for obtaining results is the Kullback-Leibler divergence __label__OWNX
Section  shows that the exponential error bound obtained in  CITATION  is sharp in general __label__OWNX
In Section , we give an upper bound on the instantaneous and the cumulative losses __label__OWNX
The latter bound is small eg under certain conditions on the distribution of the weights, this is the subject of Section __label__OWNX
If the underlying model class is discrete, then the total expected square loss is a particularly interesting performance measure: (a) this quantity is finitely bounded, implying convergence with probability one, and (b) it additionally specifies the convergence speed __label__MISC
We show that this is even the case if the model class contains only Bernoulli distributions __label__AIMX
We derive a new upper bound on the prediction error for countable Bernoulli classes __label__OWNX
We discuss the application to Machine Learning tasks such as classification and hypothesis testing, and generalization to countable classes of iid models __label__OWNX
``Bayes mixture", ``Solomonoff induction", ``marginalization", all these terms refer to a central induction principle: Obtain a predictive distribution by integrating the product of prior and evidence over the model class __label__MISC
In many cases however, the Bayes mixture is computationally infeasible, and even a sophisticated approximation is expensive __label__CONT
The MDL or MAP (maximum a posteriori) estimator is both a common approximation for the Bayes mixture and interesting for its own sake: Use the model with the largest product of prior and evidence __label__MISC
In practice, the MDL estimator is usually being approximated too, since only a local maximum is determined __label__MISC
How good are the predictions by Bayes mixtures and MDL __label__MISC
This question has attracted much attention __label__MISC
In many cases, an important quality measure is the  total  or cumulative  expected loss  of a predictor __label__MISC
In particular the square loss is often considered __label__MISC
Assume that the outcome space is finite, and the model class is continuously parameterized __label__MISC
This corresponds to an  instantaneous  loss bound of  SYMBOL __label__MISC
For the MDL predictor, the losses behave similarly  CITATION  under appropriate conditions, in particular with a specific prior __label__MISC
On the other hand, if the model class is discrete, then Solomonoff's theorem  CITATION  bounds the cumulative expected square loss for the Bayes mixture predictions finitely, namely by  SYMBOL , where  SYMBOL  is the prior weight of the ``true" model  SYMBOL __label__MISC
The only necessary assumption is that the true distribution  SYMBOL  is contained in the model class, ie that we are dealing with  proper learning __label__MISC
This bound is exponentially larger than the Solomonoff bound, and it is sharp in general __label__MISC
A finite bound on the total expected square loss is particularly interesting:   It implies convergence of the predictive to the true probabilities with probability one __label__MISC
We avoid the term ``convergence rate" here, since the order of convergence is identical in both cases __label__MISC
It is therefore natural to ask if there are model classes where the cumulative loss of MDL is comparable to that of Bayes mixture predictions __label__MISC
In the present work, we concentrate on the simplest possible stochastic case, namely discrete Bernoulli classes __label__AIMX
Note that then the MDL ``predictor" just becomes an estimator, in that it estimates the true parameter and directly uses that for prediction __label__OWNX
It might be surprising to discover that in general the cumulative loss is still exponential __label__OWNX
Moreover, it is well-known that the instantaneous square loss of the Maximum Likelihood estimator decays as  SYMBOL  in the Bernoulli case __label__MISC
The same holds for MDL, as we will see __label__MISC
If convergence speed is measured in terms of instantaneous losses, then much more general statements are possible  CITATION , this is briefly discussed in Section __label__MISC
A particular motivation to consider discrete model classes arises in Algorithmic Information Theory __label__MISC
Thus each model corresponds to a program, and there are countably many programs __label__MISC
Moreover, the models are stochastic, precisely they are  semimeasures  on strings (programs need not halt, otherwise the models were even measures) __label__MISC
Each model has a natural description length, namely the length of the corresponding program __label__MISC
If we agree that programs are binary strings, then a prior is defined by two to the negative description length __label__MISC
Also the Bernoulli case can be studied in the view of Algorithmic Information Theory __label__MISC
We call this the  universal setup : Given a universal Turing machine, the related class of Bernoulli distributions is isomorphic to the countable set of computable reals in  SYMBOL __label__MISC
A prior weight may then be defined by  SYMBOL __label__MISC
If a string  SYMBOL  is generated by a Bernoulli distribution with computable parameter  SYMBOL , then with high probability the two-part complexity of  SYMBOL  with respect to the Bernoulli class does not exceed its algorithmic complexity by more than a constant, as shown by Vovk  CITATION __label__MISC
Many Machine Learning tasks are or can be reduced to sequence prediction tasks __label__MISC
An important example is classification __label__MISC
The task of classifying a new instance  SYMBOL  after having seen (instance,class) pairs  SYMBOL  can be phrased as to predict the continuation of the sequence  SYMBOL __label__MISC
Cumulative loss bounds for prediction usually generalize to prediction  conditionalized  to some inputs  CITATION __label__MISC
Then we can solve classification problems in the standard form __label__MISC
It is not obvious if and how the proofs in this paper can be conditionalized __label__OWNX
Lemmata for this quantity are stated in Section __label__OWNX
Section  shows that the exponential error bound obtained in  CITATION  is sharp in general __label__OWNX
In Section , we give an upper bound on the instantaneous and the cumulative losses __label__OWNX
The latter bound is small eg under certain conditions on the distribution of the weights, this is the subject of Section __label__OWNX
Finally, in Section  we discuss the results and give conclusions __label__OWNX
The Minimum Description Length principle for online sequence estimation/prediction in a proper learning setup is studied __label__OWNX
If the underlying model class is discrete, then the total expected square loss is a particularly interesting performance measure: (a) this quantity is finitely bounded, implying convergence with probability one, and (b) it additionally specifies the convergence speed __label__MISC
For MDL, in general one can only have loss bounds which are finite but exponentially larger than those for Bayes mixtures __label__MISC
We show that this is even the case if the model class contains only Bernoulli distributions __label__AIMX
We derive a new upper bound on the prediction error for countable Bernoulli classes __label__OWNX
This implies a small bound (comparable to the one for Bayes mixtures) for certain important model classes __label__OWNX
We discuss the application to Machine Learning tasks such as classification and hypothesis testing, and generalization to countable classes of iid models __label__OWNX
``Bayes mixture", ``Solomonoff induction", ``marginalization", all these terms refer to a central induction principle: Obtain a predictive distribution by integrating the product of prior and evidence over the model class __label__MISC
In many cases however, the Bayes mixture is computationally infeasible, and even a sophisticated approximation is expensive __label__MISC
The MDL or MAP (maximum a posteriori) estimator is both a common approximation for the Bayes mixture and interesting for its own sake: Use the model with the largest product of prior and evidence __label__MISC
In practice, the MDL estimator is usually being approximated too, since only a local maximum is determined __label__MISC
How good are the predictions by Bayes mixtures and MDL __label__MISC
This question has attracted much attention __label__MISC
In particular the square loss is often considered __label__MISC
Assume that the outcome space is finite, and the model class is continuously parameterized __label__MISC
Then for Bayes mixture prediction, the cumulative expected square loss is usually small but unbounded, growing with  SYMBOL , where  SYMBOL  is the sample size  CITATION __label__MISC
This corresponds to an  instantaneous  loss bound of  SYMBOL __label__MISC
For the MDL predictor, the losses behave similarly  CITATION  under appropriate conditions, in particular with a specific prior __label__MISC
Note that in order to do MDL for continuous model classes, one needs to  discretize  the parameter space, see also  CITATION __label__MISC
On the other hand, if the model class is discrete, then Solomonoff's theorem  CITATION  bounds the cumulative expected square loss for the Bayes mixture predictions finitely, namely by  SYMBOL , where  SYMBOL  is the prior weight of the ``true" model  SYMBOL __label__MISC
The only necessary assumption is that the true distribution  SYMBOL  is contained in the model class, ie that we are dealing with  proper learning __label__MISC
It has been demonstrated  CITATION , that for both Bayes mixture and MDL, the proper learning assumption can be essential: If it is violated, then learning may fail very badly __label__MISC
This bound is exponentially larger than the Solomonoff bound, and it is sharp in general __label__MISC
A finite bound on the total expected square loss is particularly interesting:   It implies convergence of the predictive to the true probabilities with probability one __label__MISC
Additionally, it gives a  convergence speed , in the sense that errors of a certain magnitude cannot occur too often __label__MISC
We avoid the term ``convergence rate" here, since the order of convergence is identical in both cases __label__MISC
It is eg  SYMBOL  if we additionally assume that the error is monotonically decreasing, which is not necessarily true in general __label__MISC
In the present work, we concentrate on the simplest possible stochastic case, namely discrete Bernoulli classes __label__AIMX
Note that then the MDL ``predictor" just becomes an estimator, in that it estimates the true parameter and directly uses that for prediction __label__OWNX
Nevertheless, for consistency of terminology, we keep the term predictor __label__OWNX
It might be surprising to discover that in general the cumulative loss is still exponential __label__OWNX
On the other hand, we will give mild conditions on the prior guaranteeing a small bound __label__OWNX
Moreover, it is well-known that the instantaneous square loss of the Maximum Likelihood estimator decays as  SYMBOL  in the Bernoulli case __label__MISC
The same holds for MDL, as we will see __label__OWNX
If convergence speed is measured in terms of instantaneous losses, then much more general statements are possible  CITATION , this is briefly discussed in Section __label__OWNX
A particular motivation to consider discrete model classes arises in Algorithmic Information Theory __label__MISC
From a computational point of view, the largest relevant model class is the class of all computable models on some fixed universal Turing machine, precisely prefix machine  CITATION __label__MISC
Thus each model corresponds to a program, and there are countably many programs __label__MISC
Moreover, the models are stochastic, precisely they are  semimeasures  on strings (programs need not halt, otherwise the models were even measures) __label__MISC
If we agree that programs are binary strings, then a prior is defined by two to the negative description length __label__MISC
By the Kraft inequality, the priors sum up to at most one __label__MISC
Also the Bernoulli case can be studied in the view of Algorithmic Information Theory __label__MISC
The description length  SYMBOL  of a parameter  SYMBOL  is then given by the length of its shortest program __label__MISC
If a string  SYMBOL  is generated by a Bernoulli distribution with computable parameter  SYMBOL , then with high probability the two-part complexity of  SYMBOL  with respect to the Bernoulli class does not exceed its algorithmic complexity by more than a constant, as shown by Vovk  CITATION __label__MISC
That is, the two-part complexity with respect to the Bernoulli class  is  the shortest description, save for an additive constant __label__MISC
The task of classifying a new instance  SYMBOL  after having seen (instance,class) pairs  SYMBOL  can be phrased as to predict the continuation of the sequence  SYMBOL __label__MISC
Cumulative loss bounds for prediction usually generalize to prediction  conditionalized  to some inputs  CITATION __label__MISC
Then we can solve classification problems in the standard form __label__OWNX
It is not obvious if and how the proofs in this paper can be conditionalized __label__OWNX
Our main tool for obtaining results is the Kullback-Leibler divergence __label__OWNX
Lemmata for this quantity are stated in Section __label__OWNX
Section  shows that the exponential error bound obtained in  CITATION  is sharp in general __label__OWNX
The latter bound is small eg under certain conditions on the distribution of the weights, this is the subject of Section __label__OWNX
Section  treats the universal setup __label__OWNX
Finally, in Section  we discuss the results and give conclusions __label__OWNX
in this paper we derive the equations for loop corrected belief propagation on a continuous variable gaussian model __label__AIMX
using the exactness of the averages for belief propagation for gaussian models  a  different way of obtaining the covariances is found   based on belief propagation on cavity graphs __label__OWNX
we discuss the relation of this  loop correction algorithm to expectation propagation  algorithms for the case in which the model is no longer  gaussian  but slightly perturbed by nonlinear terms __label__OWNX
message passing techniques in graphical models allow for the computation of  approximate   marginal probabilities in a time interval scaling polynomially in the  model size __label__MISC
their discovery has consequently revolutionized several  fields of applications in the past years  of which error correcting codes and vision are probably the most prominent examples __label__MISC
in many cases  the corresponding graphs are loopy  implying either that the error resulting from the application of loopy belief propagation  bp  is negligible for the particular model  or it  can be tolerated for the particular purpose bp serves __label__MISC
in other cases  more sophisticated refinements of bp are necessary  taking into account  part of  the loop errors __label__MISC
finding the optimal treatment of these   loop errors    motivates an active field of research  in which  different solutions applying to different model classes are developed __label__MISC
for models involving many short loops   like on regular lattices  cvm type approaches work well  CITATION   or tree ep approaches  CITATION __label__MISC
the latter may also be  applied to correct for an incidental large loop __label__MISC
unifying frameworks like the region graphs of  CITATION   lead to general strategies for selecting the basic clusters underlying such approaches for general model classes __label__MISC
these quantities are parameterizations of the   cavity distributions     i e   the  distribution over neighbor variables of a central variable which has been removed from the graph __label__MISC
the bethe approximation and bp are recovered when this  cavity distribution is assumed to factorize  whereas the first order correction to the local update equations is obtained when one takes into account the pair cumulants  CITATION __label__MISC
estimation of these pair cumulants is possible with extra runs of bp  allowing for new polynomial time algorithms  reducing errors to order    when applying algorithms of which running time scales with an extra factor  of    CITATION __label__MISC
although this scaling seems heavy  the large benefit of the approach is that it does not require selection of basic clusters or underlying  tree structures  since it takes into account the effect of all loops that contribute to nontrivial correlations in the cavity distribution at once __label__MISC
the above   loop correction    strategy is applicable in the class of models where a perturbative expansion around the bethe approximation makes sense  i e   in models with large loops and relatively weak interactions __label__MISC
the principal requirement  is that the magnitude of pair variable cumulants of cavity distributions is an order smaller than the  single variable cumulants  and third order cumulants are even smaller  etc __label__MISC
however  heuristics based on the strategy allow for other good algorithms  performing well outside these parameter regimes  CITATION __label__MISC
so far the approach has been developed for discrete variable models on a more abstract  CITATION  versus practical level  CITATION __label__CONT
in this paper we apply the idea to graphical models for continuous variables __label__AIMX
we derive the loop corrected belief propagation equations  for simple tractable gaussian models   yielding a message passing scheme that  besides the correct average marginals  also yields the correct variances __label__OWNX
besides that we discuss some approaches potentially  applicable to cases in which extra function approximations are necessary   and the relation with expectation propagation __label__OWNX
a by product of our loop corrected belief propagation equations is an algorithm that calculates exact covariance matrices for gaussian models like the one discussed in  CITATION   but without explicitly using linear response __label__CONT
Using the exactness of the averages for belief propagation for Gaussian models, a  different way of obtaining the covariances is found,  based on Belief Propagation on cavity graphs __label__OWNX
We discuss the relation of this  loop correction algorithm to Expectation Propagation  algorithms for the case in which the model is no longer  Gaussian, but slightly perturbed by nonlinear terms __label__AIMX
Message passing techniques in graphical models allow for the computation of (approximate)  marginal probabilities in a time interval scaling polynomially in the  model size __label__MISC
Their discovery has consequently revolutionized several  fields of applications in the past years, of which error correcting codes and vision are probably the most prominent examples __label__MISC
In many cases, the corresponding graphs are loopy, implying either that the error resulting from the application of loopy belief propagation (BP) is negligible for the particular model, or it  can be tolerated for the particular purpose BP serves __label__MISC
In other cases  more sophisticated refinements of BP are necessary, taking into account (part of) the loop errors __label__MISC
Finding the optimal treatment of these ``loop errors''  motivates an active field of research, in which  different solutions applying to different model classes are developed __label__MISC
For models involving many short loops,  like on regular lattices, CVM type approaches work well  CITATION , or tree EP approaches  CITATION __label__MISC
Unifying frameworks like the Region graphs of  CITATION   lead to general strategies for selecting the basic clusters underlying such approaches for general model classes __label__MISC
A recent analysis has shown that the local update equations of BP may be interpreted as the zero order term of an expansion in ``cavity connected correlations'' __label__MISC
These quantities are parameterizations of the ``cavity distributions'',  i e , the  distribution over neighbor variables of a central variable which has been removed from the graph __label__MISC
The Bethe approximation and BP are recovered when this  cavity distribution is assumed to factorize, whereas the first order correction to the local update equations is obtained when one takes into account the pair cumulants  CITATION __label__MISC
The above ``loop correction''  strategy is applicable in the class of models where a perturbative expansion around the Bethe approximation makes sense, i e , in models with large loops and relatively weak interactions __label__MISC
So far the approach has been developed for discrete variable models on a more abstract  CITATION  versus practical level  CITATION __label__MISC
We derive the loop corrected belief propagation equations  for simple tractable Gaussian models,  yielding a message passing scheme that, besides the correct average marginals, also yields the correct variances __label__OWNX
Besides that we discuss some approaches potentially  applicable to cases in which extra function approximations are necessary,  and the relation with expectation propagation __label__AIMX
A by-product of our loop corrected belief propagation equations is an algorithm that calculates exact covariance matrices for Gaussian models like the one discussed in  CITATION , but without explicitly using linear response __label__OWNX
Using the exactness of the averages for belief propagation for Gaussian models, a  different way of obtaining the covariances is found,  based on Belief Propagation on cavity graphs __label__BASE
We discuss the relation of this  loop correction algorithm to Expectation Propagation  algorithms for the case in which the model is no longer  Gaussian, but slightly perturbed by nonlinear terms __label__OWNX
Message passing techniques in graphical models allow for the computation of (approximate)  marginal probabilities in a time interval scaling polynomially in the  model size __label__MISC
Their discovery has consequently revolutionized several  fields of applications in the past years, of which error correcting codes and vision are probably the most prominent examples __label__MISC
In many cases, the corresponding graphs are loopy, implying either that the error resulting from the application of loopy belief propagation (BP) is negligible for the particular model, or it  can be tolerated for the particular purpose BP serves __label__MISC
In other cases  more sophisticated refinements of BP are necessary, taking into account (part of) the loop errors __label__MISC
Finding the optimal treatment of these ``loop errors''  motivates an active field of research, in which  different solutions applying to different model classes are developed __label__MISC
For models involving many short loops,  like on regular lattices, CVM type approaches work well  CITATION , or tree EP approaches  CITATION __label__MISC
The latter may also be  applied to correct for an incidental large loop __label__MISC
A recent analysis has shown that the local update equations of BP may be interpreted as the zero order term of an expansion in ``cavity connected correlations'' __label__MISC
These quantities are parameterizations of the ``cavity distributions'',  i e , the  distribution over neighbor variables of a central variable which has been removed from the graph __label__MISC
The Bethe approximation and BP are recovered when this  cavity distribution is assumed to factorize, whereas the first order correction to the local update equations is obtained when one takes into account the pair cumulants  CITATION __label__MISC
Estimation of these pair cumulants is possible with extra runs of BP, allowing for new polynomial time algorithms, reducing errors to order  SYMBOL   when applying algorithms of which running time scales with an extra factor  of  SYMBOL   CITATION __label__MISC
Although this scaling seems heavy, the large benefit of the approach is that it does not require selection of basic clusters or underlying  tree-structures, since it takes into account the effect of all loops that contribute to nontrivial correlations in the cavity distribution at once __label__MISC
The principal requirement  is that the magnitude of pair variable cumulants of cavity distributions is an order smaller than the  single variable cumulants, and third order cumulants are even smaller, etc __label__MISC
However, heuristics based on the strategy allow for other good algorithms  performing well outside these parameter regimes  CITATION __label__MISC
So far the approach has been developed for discrete variable models on a more abstract  CITATION  versus practical level  CITATION __label__MISC
In this paper we apply the idea to graphical models for continuous variables __label__AIMX
Besides that we discuss some approaches potentially  applicable to cases in which extra function approximations are necessary,  and the relation with expectation propagation __label__OWNX
A by-product of our loop corrected belief propagation equations is an algorithm that calculates exact covariance matrices for Gaussian models like the one discussed in  CITATION , but without explicitly using linear response __label__BASE
there are two known varieties of defensive forecasting    continuous    in which sceptic s moves are assumed to depend on the forecasts in a  semi continuous manner and which produces deterministic forecasts  and   randomized    in which the dependence of sceptic s moves on the forecasts is arbitrary and forecaster s moves are allowed to be randomized __label__MISC
this note shows that the randomized variety can be obtained from the continuous variety by smearing sceptic s moves to make them continuous __label__AIMX
textbf new as compared to version  NUMBER    NUMBER  august  NUMBER   of this report   the assumption of version  NUMBER  that the outcome space   is finite is relaxed  and now it is only assumed to be compact __label__CONT
in the case where   is finite  it is shown that forecaster can choose his randomized forecasts concentrated on a finite set of cardinality at most __label__CONT
non asymptotic versions of the randomized variety were proposed by sandroni  CITATION   based on standard measure theoretic probability  and vovk and shafer  CITATION   based on game theoretic probability __label__CONT
this note states two simple results about defensive forecasting  theorem  about the continuous variety and theorem  about the randomized variety __label__AIMX
the proof of theorem  is obtained from the proof of theorem  by blurring sceptic s moves __label__OWNX
in our informal discussions we will be assuming that the set   of all possible outcomes is finite  although we will try to make mathematical statements as general as possible __label__OWNX
the reader who is only interested in the main ideas might choose to specialize theorems  and  and their proofs to the case of finite __label__OWNX
defensive forecasting is a method of transforming laws of probability  stated in game theoretic terms as strategies for sceptic  into forecasting algorithms __label__MISC
there are two known varieties of defensive forecasting    continuous    in which sceptic s moves are assumed to depend on the forecasts in a  semi continuous manner and which produces deterministic forecasts  and   randomized    in which the dependence of sceptic s moves on the forecasts is arbitrary and forecaster s moves are allowed to be randomized __label__MISC
this note shows that the randomized variety can be obtained from the continuous variety by smearing sceptic s moves to make them continuous __label__MISC
new as compared to version  NUMBER    NUMBER  august  NUMBER   of this report   the assumption of version  NUMBER  that the outcome space   is finite is relaxed  and now it is only assumed to be compact __label__OWNX
the continuous variety of defensive forecasting was essentially introduced by levin  CITATION   but was later rediscovered by kakade and foster  CITATION  and takemura  et al    CITATION __label__MISC
the randomized variety was introduced  in the case of von mises s version of the game theoretic approach to probability  by foster and vohra  CITATION  and further developed by  among others  sandroni  et al    CITATION   these papers  however  were only concerned with asymptotic calibration __label__MISC
non asymptotic versions of the randomized variety were proposed by sandroni  CITATION   based on standard measure theoretic probability  and vovk and shafer  CITATION   based on game theoretic probability __label__MISC
kakade and foster  CITATION  noticed that some calibration results require very little randomization  this will be an important aspect of our theorem __label__BASE
this note states two simple results about defensive forecasting  theorem  about the continuous variety and theorem  about the randomized variety __label__AIMX
in our informal discussions we will be assuming that the set   of all possible outcomes is finite  although we will try to make mathematical statements as general as possible __label__AIMX
the reader who is only interested in the main ideas might choose to specialize theorems  and  and their proofs to the case of finite __label__OWNX
This note shows that the randomized variety can be obtained from the continuous variety by smearing Sceptic's moves to make them continuous __label__AIMX
New as compared to version 1 (17 August 2007) of this report: The assumption of version 1 that the outcome space  SYMBOL  is finite is relaxed, and now it is only assumed to be compact __label__OWNX
In the case where  SYMBOL  is finite, it is shown that Forecaster can choose his randomized forecasts concentrated on a finite set of cardinality at most  SYMBOL __label__OWNX
The randomized variety was introduced (in the case of von Mises's version of the game-theoretic approach to probability) by Foster and Vohra  CITATION  and further developed by, among others, Sandroni  et al CITATION ; these papers, however, were only concerned with asymptotic calibration __label__MISC
Kakade and Foster  CITATION  noticed that some calibration results require very little randomization (this will be an important aspect of our Theorem ) __label__BASE
This note states two simple results about defensive forecasting, Theorem  about the continuous variety and Theorem  about the randomized variety __label__AIMX
In our informal discussions we will be assuming that the set  SYMBOL  of all possible outcomes is finite, although we will try to make mathematical statements as general as possible __label__OWNX
The reader who is only interested in the main ideas might choose to specialize Theorems  and  and their proofs to the case of finite  SYMBOL __label__MISC
most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used  independently of any algorithm __label__CONT
in contrast  the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties __label__CONT
however  as in much of learning theory  existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed __label__CONT
in many machine learning applications  however  this assumption does not hold __label__CONT
the observations received by the learning algorithm often have some inherent temporal dependence __label__CONT
this paper studies the scenario where the observations are drawn from a stationary   mixing or   mixing sequence  a widely adopted assumption in the study of non independent and identically distributed   processes that implies a dependence between observations weakening over time __label__AIMX
we prove novel and distinct stability based generalization bounds for stationary   mixing and   mixing sequences __label__OWNX
these bounds strictly generalize the bounds given in the independent and identically distributed   case and apply to all stable learning algorithms  thereby extending the use of stability bounds to non independent and identically distributed   scenarios __label__BASE
we also illustrate the application of our   mixing generalization bounds to general classes of learning algorithms  including support vector regression  kernel ridge regression  and support vector machines  and many other kernel regularization based and relative entropy based regularization algorithms __label__OWNX
these novel bounds can thus be viewed as the first theoretical basis for the use of these algorithms in non independent and identically distributed   scenarios __label__OWNX
most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used  such as the vc dimension  covering numbers  or rademacher complexity __label__CONT
these measures characterize a class of hypotheses  independently of any algorithm __label__CONT
in contrast  the notion of algorithmic stability can be used to derive bounds that are tailored to specific learning algorithms and exploit their particular properties __label__CONT
a learning algorithm is stable if the hypothesis it outputs varies in a limited way in response to small changes made to the training set __label__CONT
algorithmic stability has been used effectively in the past to derive tight generalization bounds  CITATION __label__CONT
but  as in much of learning theory  existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed  independent and identically distributed __label__CONT
in many machine learning applications  this assumption  however  does not hold  in fact  the independent and identically distributed   assumption is not tested or derived from any data analysis __label__CONT
the observations received by the learning algorithm often have some inherent temporal dependence __label__CONT
this is clear in system diagnosis or time series prediction problems __label__CONT
clearly  prices of different stocks on the same day  or of the same stock on different days  may be dependent __label__CONT
but  a less apparent time dependency may affect data sampled in many other tasks as well __label__CONT
this paper studies the scenario where the observations are drawn from a stationary   mixing or   mixing sequence  a widely adopted assumption in the study of non independent and identically distributed   processes that implies a dependence between observations weakening over time  CITATION __label__AIMX
these bounds strictly generalize the bounds given in the independent and identically distributed   case and apply to all stable learning algorithms  thereby extending the usefulness of stability bounds to non independent and identically distributed   scenarios __label__BASE
our proofs are based on the independent block technique described by  CITATION  and attributed to  CITATION   which is commonly used in such contexts __label__BASE
however  our analysis differs from previous uses of this technique in that the blocks of points considered are not of equal size __label__CONT
our generalization bounds for stationary   mixing sequences cover a more general non independent and identically distributed   scenario and use the standard mcdiarmid s inequality  however  unlike the   mixing case  the   mixing bound presented here is not a purely exponential bound and contains an additive term depending on the mixing coefficient __label__OWNX
algorithms such as support vector regression  svr   CITATION  have been used in the context of time series prediction in which the independent and identically distributed   assumption does not hold  some with good experimental results  CITATION __label__CONT
the stability bounds we give for svr  svms  and many other kernel regularization based and relative entropy based regularization algorithms can thus be viewed as the first theoretical basis for their use in such scenarios __label__CONT
the following sections are organized as follows __label__OWNX
section  gives our main generalization bounds for stationary   mixing sequences based on stability  as well as the illustration of its applications to general kernel regularization based algorithms  including svr  krr  and svms  as well as to relative entropy based regularization algorithms __label__OWNX
finally  section  presents the first known stability bounds for the more general stationary   mixing scenario __label__OWNX
Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, independently of any algorithm __label__MISC
In contrast, the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties __label__MISC
However, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed __label__MISC
The observations received by the learning algorithm often have some inherent temporal dependence __label__MISC
This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid  processes that implies a dependence between observations weakening over time __label__AIMX
These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the use of stability-bounds to non-iid scenarios __label__OWNX
We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression, Kernel Ridge Regression, and Support Vector Machines, and many other kernel regularization-based and relative entropy-based regularization algorithms __label__OWNX
These novel bounds can thus be viewed as the first theoretical basis for the use of these algorithms in non-iid scenarios __label__OWNX
Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, such as the VC-dimension, covering numbers, or Rademacher complexity __label__MISC
In contrast, the notion of algorithmic stability can be used to derive bounds that are tailored to specific learning algorithms and exploit their particular properties __label__MISC
A learning algorithm is stable if the hypothesis it outputs varies in a limited way in response to small changes made to the training set __label__MISC
Algorithmic stability has been used effectively in the past to derive tight generalization bounds  CITATION __label__MISC
But, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed (iid) __label__MISC
In many machine learning applications, this assumption, however, does not hold; in fact, the iid assumption is not tested or derived from any data analysis __label__MISC
The observations received by the learning algorithm often have some inherent temporal dependence __label__MISC
This is clear in system diagnosis or time series prediction problems __label__MISC
Clearly, prices of different stocks on the same day, or of the same stock on different days, may be dependent __label__MISC
This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid processes that implies a dependence between observations weakening over time  CITATION __label__AIMX
These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the usefulness of stability-bounds to non-iid scenarios __label__OWNX
Our proofs are based on the independent block technique described by  CITATION  and attributed to  CITATION , which is commonly used in such contexts __label__BASE
However, our analysis differs from previous uses of this technique in that the blocks of points considered are not of equal size __label__CONT
For our analysis of stationary  SYMBOL -mixing sequences, we make use of a generalized version of McDiarmid's inequality  CITATION  that holds for  SYMBOL -mixing sequences __label__BASE
This leads to stability-based generalization bounds with the standard exponential form __label__BASE
Our generalization bounds for stationary  SYMBOL -mixing sequences cover a more general non-iid scenario and use the standard McDiarmid's inequality, however, unlike the  SYMBOL -mixing case, the  SYMBOL -mixing bound presented here is not a purely exponential bound and contains an additive term depending on the mixing coefficient __label__CONT
To our knowledge, the use of these algorithms in non-iid scenarios has not been previously supported by any theoretical analysis __label__CONT
The stability bounds we give for SVR, SVMs, and many other kernel regularization-based and relative entropy-based regularization algorithms can thus be viewed as the first theoretical basis for their use in such scenarios __label__OWNX
The following sections are organized as follows __label__OWNX
In Section~, we introduce the necessary definitions for the non-iid problems that we are considering and discuss the learning scenarios in that context __label__OWNX
Section~ gives our main generalization bounds for stationary  SYMBOL -mixing sequences based on stability, as well as the illustration of its applications to general kernel regularization-based algorithms, including SVR, KRR, and SVMs, as well as to relative entropy-based regularization algorithms __label__OWNX
Finally, Section~ presents the first known stability bounds for the more general stationary  SYMBOL -mixing scenario __label__OWNX
Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, independently of any algorithm __label__MISC
In contrast, the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties __label__MISC
However, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed __label__MISC
In many machine learning applications, however, this assumption does not hold __label__MISC
The observations received by the learning algorithm often have some inherent temporal dependence __label__MISC
This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid  processes that implies a dependence between observations weakening over time __label__AIMX
We prove novel and distinct stability-based generalization bounds for stationary  SYMBOL -mixing and  SYMBOL -mixing sequences __label__OWNX
These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the use of stability-bounds to non-iid scenarios __label__OWNX
We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression, Kernel Ridge Regression, and Support Vector Machines, and many other kernel regularization-based and relative entropy-based regularization algorithms __label__OWNX
These novel bounds can thus be viewed as the first theoretical basis for the use of these algorithms in non-iid scenarios __label__OWNX
Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, such as the VC-dimension, covering numbers, or Rademacher complexity __label__MISC
These measures characterize a class of hypotheses, independently of any algorithm __label__MISC
A learning algorithm is stable if the hypothesis it outputs varies in a limited way in response to small changes made to the training set __label__MISC
Algorithmic stability has been used effectively in the past to derive tight generalization bounds  CITATION __label__MISC
But, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed (iid) __label__MISC
The observations received by the learning algorithm often have some inherent temporal dependence __label__MISC
This paper studies the scenario where the observations are drawn from a stationary  SYMBOL -mixing or  SYMBOL -mixing sequence, a widely adopted assumption in the study of non-iid processes that implies a dependence between observations weakening over time  CITATION __label__AIMX
We prove novel and distinct stability-based generalization bounds for stationary  SYMBOL -mixing and  SYMBOL -mixing sequences __label__OWNX
These bounds strictly generalize the bounds given in the iid case and apply to all stable learning algorithms, thereby extending the usefulness of stability-bounds to non-iid scenarios __label__OWNX
Our proofs are based on the independent block technique described by  CITATION  and attributed to  CITATION , which is commonly used in such contextsMISC __label__BASE
However, our analysis differs from previous uses of this technique in that the blocks of points considered are not of equal size __label__CONT
For our analysis of stationary  SYMBOL -mixing sequences, we make use of a generalized version of McDiarmid's inequality  CITATION  that holds for  SYMBOL -mixing sequences __label__BASE
This leads to stability-based generalization bounds with the standard exponential form __label__OWNX
We also illustrate the application of our  SYMBOL -mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression (SVR)  CITATION , Kernel Ridge Regression  CITATION , and Support Vector Machines (SVMs)  CITATION __label__OWNX
Algorithms such as support vector regression (SVR)  CITATION  have been used in the context of time series prediction in which the iid assumption does not hold, some with good experimental results  CITATION __label__MISC
To our knowledge, the use of these algorithms in non-iid scenarios has not been previously supported by any theoretical analysis __label__MISC
The stability bounds we give for SVR, SVMs, and many other kernel regularization-based and relative entropy-based regularization algorithms can thus be viewed as the first theoretical basis for their use in such scenarios __label__OWNX
The following sections are organized as follows __label__MISC
In Section~, we introduce the necessary definitions for the non-iid problems that we are considering and discuss the learning scenarios in that context __label__OWNX
Section~ gives our main generalization bounds for stationary  SYMBOL -mixing sequences based on stability, as well as the illustration of its applications to general kernel regularization-based algorithms, including SVR, KRR, and SVMs, as well as to relative entropy-based regularization algorithms __label__OWNX
Finally, Section~ presents the first known stability bounds for the more general stationary  SYMBOL -mixing scenario __label__OWNX
we derive a qa algorithm for clustering and propose an annealing schedule  which is crucial in practice __label__OWNX
experiments show the proposed qa algorithm finds better clustering assignments than sa __label__CONT
furthermore  qa is as easy as sa to implement __label__CONT
typically  clustering problems are formulated as optimization problems  which are solved by algorithms  for example the em algorithm or convex relaxation __label__MISC
the simulated annealing  sa   CITATION  is a promising candidate __label__MISC
CITATION  proved sa was able to find the global optimum with a slow cooling schedule of temperature __label__MISC
although their schedule is in practice too slow for clustering of a large amount of data  it is well known that sa still finds a reasonably good solution even with a faster schedule than what  citeauthor geman NUMBER   proposed __label__CONT
in statistical mechanics  quantum annealing  qa  has been proposed as a novel alternative to sa  CITATION __label__CONT
qa adds another dimension     to sa for annealing  see fig __label__CONT
thus  it can be seen as an extension of sa __label__BASE
qa has succeeded in specific problems  e g the ising model in statistical mechanics  and it is still unclear that qa works better than sa in general __label__MISC
a derived qa algorithm depends on the definition of quantum effect __label__MISC
we propose quantum effect    which leads to a search strategy fit to clustering __label__OWNX
we also show the proposed algorithm is as easy as sa to implement __label__OWNX
	the algorithm we propose is a markov chain monte carlo  mcmc  sampler  which we call qa st sampler __label__OWNX
thus  we approximate qa by the suzuki trotter  st  expansion  CITATION  to derive a tractable sampler  which is the qa st sampler __label__OWNX
qa st looks like parallel   sas with interaction    see fig __label__OWNX
at the beginning of the annealing process  qa st is almost the same as   sas __label__OWNX
hence  qa st finds    local  optima independently __label__OWNX
as the annealing process continues  interaction   in fig becomes stronger to move   states closer __label__OWNX
qa st at the end picks up the state with the lowest energy in   states as the final solution __label__OWNX
qa st with the proposed quantum effect   works well for clustering __label__OWNX
fig is an example where data points are grouped into four clusters __label__OWNX
SYMBOL and SYMBOL are locally optimal and   is globally optimal __label__OWNX
suppose SYMBOL is equal to two and SYMBOL and SYMBOL in fig correspond to SYMBOL and SYMBOL in fig __label__OWNX
although   and   are local optima  the interaction   in fig allows   and   to search for a better clustering assignment between   and __label__OWNX
quantum effect   defines the distance metric of clustering assignments __label__OWNX
thus  the interaction   gives good chance to go to   because   makes   and   closer  see fig __label__OWNX
the proposed algorithm actually finds   from   and __label__OWNX
fig is just an example __label__OWNX
however  a similar situation often occurs in clustering __label__MISC
clustering algorithms in most cases give   almost   globally optimal solutions like   and    where the majority of data points are well clustered  but some of them are not __label__MISC
note an assignment constructed in such a way is located between the sub optimal ones by the proposed quantum effect   so that qa st can find a better assignment between sub optimal ones __label__MISC
This paper studies quantum annealing (QA) for clustering, which can be seen as an extension of simulated annealing (SA) __label__AIMX
We derive a QA algorithm for clustering and propose an annealing schedule, which is crucial in practice __label__AIMX
Experiments show the proposed QA algorithm finds better clustering assignments than SA __label__OWNX
Furthermore, QA is as easy as SA to implement __label__OWNX
Clustering is one of the most popular methods in data mining __label__MISC
Typically, clustering problems are formulated as optimization problems, which are solved by algorithms, for example the EM algorithm or convex relaxation __label__MISC
The simulated annealing (SA)  CITATION  is a promising candidate __label__MISC
Although their schedule is in practice too slow for clustering of a large amount of data, it is well known that SA still finds a reasonably good solution even with a faster schedule than what CITATION proposed __label__MISC
In statistical mechanics, quantum annealing (QA) has been proposed as a novel alternative to SA  CITATION __label__MISC
QA adds another dimension,  SYMBOL , to SA for annealing, see Fig __label__MISC
Thus, it can be seen as an extension of SA __label__MISC
QA has succeeded in specific problems, e g the Ising model in statistical mechanics, and it is still unclear that QA works better than SA in general __label__MISC
We do not actually think QA intuitively helps clustering, but we apply QA to clustering just as procedure to derive an algorithm __label__OWNX
A derived QA algorithm depends on the definition of quantum effect  SYMBOL __label__MISC
Our contribution is, 1) to propose a QA-based optimization algorithm for clustering, in particular quantum effect  SYMBOL  for clustering  and a good annealing schedule, which is crucial for applications, 2) and to experimentally show the proposed algorithm optimizes clustering assignments better than SA __label__AIMX
We also show the proposed algorithm is as easy as SA to implement __label__OWNX
The algorithm we propose is a Markov chain Monte Carlo (MCMC) sampler, which we call QA-ST sampler __label__OWNX
As we explain later, a naive QA sampler is intractable even with MCMC __label__OWNX
Thus, we approximate QA by the Suzuki-Trotter (ST) expansion  CITATION  to derive a tractable sampler, which is the QA-ST sampler __label__AIMX
Hence, QA-ST finds  SYMBOL  (local) optima independently __label__OWNX
As the annealing process continues, interaction  SYMBOL  in Fig becomes stronger to move  SYMBOL  states closer __label__OWNX
QA-ST at the end picks up the state with the lowest energy in  SYMBOL  states as the final solution __label__OWNX
QA-ST with the proposed quantum effect  SYMBOL  works well for clustering __label__OWNX
SYMBOL and  SYMBOL are locally optimal and  SYMBOL  is globally optimal __label__OWNX
Suppose  SYMBOL  is equal to two and  SYMBOL  and  SYMBOL  in Fig correspond to  SYMBOL  and  SYMBOL  in Fig __label__OWNX
Although  SYMBOL  and  SYMBOL  are local optima, the interaction  SYMBOL  in Fig allows  SYMBOL  and  SYMBOL  to search for a better clustering assignment between  SYMBOL  and  SYMBOL __label__OWNX
Quantum effect  SYMBOL  defines the distance metric of clustering assignments __label__OWNX
In this case, the proposed  SYMBOL  locates  SYMBOL  between  SYMBOL  and  SYMBOL __label__OWNX
Thus, the interaction  SYMBOL  gives good chance to go to  SYMBOL  because  SYMBOL  makes  SYMBOL  and  SYMBOL  closer (see Fig ) __label__OWNX
However, a similar situation often occurs in clustering __label__MISC
Clustering algorithms in most cases give ``almost'' globally optimal solutions like  SYMBOL  and  SYMBOL , where the majority of data points are well-clustered, but some of them are not __label__CONT
Thus, a better clustering assignment can be constructed by picking up well-clustered data points from many sub-optimal clustering assignments __label__CONT
Note an assignment constructed in such a way is located between the sub-optimal ones by the proposed quantum effect  SYMBOL  so that QA-ST can find a better assignment between sub-optimal ones __label__CONT
This paper studies quantum annealing (QA) for clustering, which can be seen as an extension of simulated annealing (SA) __label__OWNX
We derive a QA algorithm for clustering and propose an annealing schedule, which is crucial in practice __label__AIMX
Furthermore, QA is as easy as SA to implement __label__OWNX
Typically, clustering problems are formulated as optimization problems, which are solved by algorithms, for example the EM algorithm or convex relaxation __label__MISC
However, clustering is typically NP-hard __label__MISC
Although their schedule is in practice too slow for clustering of a large amount of data, it is well known that SA still finds a reasonably good solution even with a faster schedule than what CITATION proposed __label__MISC
In statistical mechanics, quantum annealing (QA) has been proposed as a novel alternative to SA  CITATION __label__MISC
QA adds another dimension,  SYMBOL , to SA for annealing, see Fig __label__MISC
Thus, it can be seen as an extension of SA __label__MISC
QA has succeeded in specific problems, e g the Ising model in statistical mechanics, and it is still unclear that QA works better than SA in general __label__MISC
We do not actually think QA intuitively helps clustering, but we apply QA to clustering just as procedure to derive an algorithm __label__OWNX
We propose quantum effect  SYMBOL , which leads to a search strategy fit to clustering __label__AIMX
We also show the proposed algorithm is as easy as SA to implement __label__OWNX
The algorithm we propose is a Markov chain Monte Carlo (MCMC) sampler, which we call QA-ST sampler __label__OWNX
Thus, we approximate QA by the Suzuki-Trotter (ST) expansion  CITATION  to derive a tractable sampler, which is the QA-ST sampler __label__OWNX
QA-ST looks like parallel  SYMBOL  SAs with interaction  SYMBOL  (see Fig ) __label__OWNX
At the beginning of the annealing process, QA-ST is almost the same as  SYMBOL  SAs __label__OWNX
Hence, QA-ST finds  SYMBOL  (local) optima independently __label__OWNX
As the annealing process continues, interaction  SYMBOL  in Fig becomes stronger to move  SYMBOL  states closer __label__OWNX
QA-ST at the end picks up the state with the lowest energy in  SYMBOL  states as the final solution __label__OWNX
QA-ST with the proposed quantum effect  SYMBOL  works well for clustering __label__OWNX
Fig is an example where data points are grouped into four clusters __label__MISC
Suppose  SYMBOL  is equal to two and  SYMBOL  and  SYMBOL  in Fig correspond to  SYMBOL  and  SYMBOL  in Fig __label__MISC
Although  SYMBOL  and  SYMBOL  are local optima, the interaction  SYMBOL  in Fig allows  SYMBOL  and  SYMBOL  to search for a better clustering assignment between  SYMBOL  and  SYMBOL __label__MISC
Quantum effect  SYMBOL  defines the distance metric of clustering assignments __label__MISC
In this case, the proposed  SYMBOL  locates  SYMBOL  between  SYMBOL  and  SYMBOL __label__MISC
The proposed algorithm actually finds  SYMBOL  from  SYMBOL  and  SYMBOL __label__OWNX
Fig is just an example __label__MISC
However, a similar situation often occurs in clustering __label__MISC
Thus, a better clustering assignment can be constructed by picking up well-clustered data points from many sub-optimal clustering assignments __label__MISC
Note an assignment constructed in such a way is located between the sub-optimal ones by the proposed quantum effect  SYMBOL  so that QA-ST can find a better assignment between sub-optimal ones __label__OWNX
we introduce a new principle for model selection in regression and classification __label__AIMX
many regression models are controlled by some smoothness or flexibility or complexity parameter    e g   the number of neighbors to be averaged over in k nearest neighbor  knn  regression or the polynomial degree in regression with polynomials __label__MISC
let   be the  best  regressor of complexity   on data __label__OWNX
a more flexible regressor can fit more data   well than a more rigid one __label__MISC
we define the loss rank of   as the number of other  fictitious  data   that are fitted better by   than   is fitted by __label__OWNX
we suggest selecting the model complexity   that has minimal loss rank  lorp __label__OWNX
it works without a stochastic noise model  and is directly applicable to any non parametric regressor  like knn __label__MISC
consider a regression or classification problem in which we want to determine the functional relationship   from data    i e   we seek a function   such that   is close to the unknown   for all __label__OWNX
if the class   is not too large  e g the polynomials of fixed reasonable degree    this often works well __label__MISC
what remains is to select the right model complexity    like   or __label__MISC
this selection cannot be based on the training error  since the more complex the model  large    small    the better the fit on    perfect for   and __label__MISC
this problem is called overfitting  for which various remedies have been suggested   we will not discuss empirical test set methods like cross validation  but only training set based methods __label__OWNX
see e g    CITATION  for a comparison of cross validation with bayesian model selection __label__MISC
the most popular ones can be regarded as penalized versions of maximum likelihood  ml __label__MISC
in addition to the function class    one has to specify a sampling model    e g   that the   have independent gaussian distribution with mean __label__MISC
ml chooses    penalized ml  pml  then chooses  penalty   where the penalty depends on the used approach  mdl  CITATION   bic  CITATION   aic  CITATION __label__MISC
in particular  modern mdl  CITATION  has sound exact foundations and works very well in practice __label__MISC
all pml variants rely on a proper sampling model  which may be difficult to establish   ignore  or at least do not tell how to incorporate  a potentially given loss function  and are typically limited to  semi parametric models __label__CONT
the loss rank is large for regressors fitting   not well  and  for too flexible regressors  in both cases the regressor fits many other   better __label__MISC
the loss rank has a minimum for not too flexible regressors which fit   not too bad __label__MISC
we claim that minimizing the loss rank is a suitable model selection criterion  since it trades off the quality of fit with the flexibility of the model __label__OWNX
unlike pml  our new loss rank principle  lorp  works without a noise  stochastic sampling  model  and is directly applicable to any non parametric regressor  like knn __label__CONT
in section   after giving a brief introduction to regression  we formally state lorp for model selection __label__OWNX
in section  we derive explicit expressions for the loss rank for the important class of linear regressors  which includes knn  polynomial  linear basis function  lbfr   kernel  and projective regression __label__OWNX
in section  we compare linear lorp to bayesian model selection for linear regression with gaussian noise and prior  and in section  to pml  in particular mdl  bic  aic  and mackay s  CITATION  and hastie s et al    CITATION  trace formulas for the effective dimension __label__OWNX
section  contains further considerations  to be elaborated on in the future __label__OWNX
We introduce a new principle for model selection in regression and classification __label__OWNX
Many regression models are controlled by some smoothness or flexibility or complexity parameter  SYMBOL , eg the number of neighbors to be averaged over in k nearest neighbor (kNN) regression or the polynomial degree in regression with polynomials __label__MISC
Let  SYMBOL  be the (best) regressor of complexity  SYMBOL  on data  SYMBOL __label__MISC
A more flexible regressor can fit more data  SYMBOL  well than a more rigid one __label__MISC
If something (here small loss) is easy to achieve it's typically worth less __label__MISC
We suggest selecting the model complexity  SYMBOL  that has minimal loss rank (LoRP) __label__OWNX
Unlike most penalized maximum likelihood variants (AIC,BIC,MDL), LoRP only depends on the regression functions and the loss function __label__CONT
In this paper we formalize, discuss, and motivate LoRP, study it for specific regression problems, in particular linear ones, and compare it to other model selection schemes __label__AIMX
Consider a regression or classification problem in which we want to determine the functional relationship  SYMBOL  from data  SYMBOL , ie we seek a function  SYMBOL  such that  SYMBOL  is close to the unknown  SYMBOL  for all  SYMBOL __label__OWNX
One may define regressor  SYMBOL  directly, eg `average the  SYMBOL  values of the  SYMBOL  nearest neighbors (kNN) of  SYMBOL  in  SYMBOL ', or select the  SYMBOL  from a class of functions  SYMBOL  that has smallest (training) error on  SYMBOL __label__OWNX
What remains is to select the right model complexity  SYMBOL , like  SYMBOL  or  SYMBOL __label__OWNX
This selection cannot be based on the training error, since the more complex the model (large  SYMBOL , small  SYMBOL ) the better the fit on  SYMBOL  (perfect for  SYMBOL  and  SYMBOL ) __label__OWNX
This problem is called overfitting, for which various remedies have been suggested:  We will not discuss empirical test set methods like cross-validation, but only training set based methods __label__MISC
The most popular ones can be regarded as penalized versions of Maximum Likelihood (ML) __label__MISC
In addition to the function class  SYMBOL , one has to specify a sampling model  SYMBOL , eg that the  SYMBOL  have independent Gaussian distribution with mean  SYMBOL __label__OWNX
ML chooses  SYMBOL , Penalized ML (PML) then chooses  SYMBOL Penalty SYMBOL , where the penalty depends on the used approach (MDL  CITATION , BIC  CITATION , AIC  CITATION ) __label__OWNX
All PML variants rely on a proper sampling model (which may be difficult to establish), ignore (or at least do not tell how to incorporate) a potentially given loss function, and are typically limited to (semi)parametric models __label__MISC
The key observation we exploit is that large classes  SYMBOL  or more flexible   regressors  SYMBOL  can fit more data  SYMBOL  well than more rigid ones, eg many  SYMBOL  can be fit well with high order polynomials __label__OWNX
We define the  loss rank  of  SYMBOL  as the number of other (fictitious) data  SYMBOL  that are fitted better by  SYMBOL  than  SYMBOL  is fitted by  SYMBOL , as measured by some loss function __label__OWNX
The loss rank has a minimum for not too flexible regressors which fit  SYMBOL  not too bad __label__OWNX
We claim that minimizing the loss rank is a suitable model selection criterion, since it trades off the quality of fit with the flexibility of the model __label__OWNX
Unlike PML, our new Loss Rank Principle (LoRP) works without a noise (stochastic sampling) model, and is directly applicable to any non-parametric regressor, like kNN __label__OWNX
In Section , after giving a brief introduction to regression, we formally state LoRP for model selection __label__OWNX
In Section  we compare linear LoRP to Bayesian model selection for linear regression with Gaussian noise and prior, and in Section  to PML, in particular MDL, BIC, AIC, and MacKay's  CITATION  and Hastie's et al  CITATION  trace formulas for the effective dimension __label__OWNX
In this paper we just scratch at the surface of LoRP __label__OWNX
Section  contains further considerations, to be elaborated on in the future __label__OWNX
We introduce a new principle for model selection in regression and classification __label__AIMX
Many regression models are controlled by some smoothness or flexibility or complexity parameter  SYMBOL , eg the number of neighbors to be averaged over in k nearest neighbor (kNN) regression or the polynomial degree in regression with polynomials __label__MISC
If something (here small loss) is easy to achieve it's typically worth less __label__MISC
We define the loss rank of  SYMBOL  as the number of other (fictitious) data  SYMBOL  that are fitted better by  SYMBOL  than  SYMBOL  is fitted by  SYMBOL __label__OWNX
We suggest selecting the model complexity  SYMBOL  that has minimal loss rank (LoRP) __label__OWNX
It works without a stochastic noise model, and is directly applicable to any non-parametric regressor, like kNN __label__CONT
In this paper we formalize, discuss, and motivate LoRP, study it for specific regression problems, in particular linear ones, and compare it to other model selection schemes __label__OWNX
Consider a regression or classification problem in which we want to determine the functional relationship  SYMBOL  from data  SYMBOL , ie we seek a function  SYMBOL  such that  SYMBOL  is close to the unknown  SYMBOL  for all  SYMBOL __label__MISC
One may define regressor  SYMBOL  directly, eg `average the  SYMBOL  values of the  SYMBOL  nearest neighbors (kNN) of  SYMBOL  in  SYMBOL ', or select the  SYMBOL  from a class of functions  SYMBOL  that has smallest (training) error on  SYMBOL __label__MISC
If the class  SYMBOL  is not too large, e g the polynomials of fixed reasonable degree  SYMBOL , this often works well __label__MISC
What remains is to select the right model complexity  SYMBOL , like  SYMBOL  or  SYMBOL __label__MISC
This selection cannot be based on the training error, since the more complex the model (large  SYMBOL , small  SYMBOL ) the better the fit on  SYMBOL  (perfect for  SYMBOL  and  SYMBOL ) __label__MISC
This problem is called overfitting, for which various remedies have been suggested:  We will not discuss empirical test set methods like cross-validation, but only training set based methods __label__MISC
See eg CITATION  for a comparison of cross-validation with Bayesian model selection __label__MISC
Training set based model selection methods allow using all data  SYMBOL  for regression __label__MISC
The most popular ones can be regarded as penalized versions of Maximum Likelihood (ML) __label__MISC
In addition to the function class  SYMBOL , one has to specify a sampling model  SYMBOL , eg that the  SYMBOL  have independent Gaussian distribution with mean  SYMBOL __label__MISC
ML chooses  SYMBOL , Penalized ML (PML) then chooses  SYMBOL Penalty SYMBOL , where the penalty depends on the used approach (MDL  CITATION , BIC  CITATION , AIC  CITATION ) __label__MISC
In particular, modern MDL  CITATION  has sound exact foundations and works very well in practice __label__MISC
All PML variants rely on a proper sampling model (which may be difficult to establish), ignore (or at least do not tell how to incorporate) a potentially given loss function, and are typically limited to (semi)parametric models __label__CONT
The main goal of the paper is to establish a criterion for selecting the ``best'' model complexity  SYMBOL based on regressors  SYMBOL  given as a black box without insight into the origin or inner structure of  SYMBOL , that does not depend on things often not given (like a stochastic noise model),  and that exploits what is given (like the loss function) __label__AIMX
The key observation we exploit is that large classes  SYMBOL  or more flexible regressors  SYMBOL  can fit more data  SYMBOL  well than more rigid ones, eg many  SYMBOL  can be fit well with high order polynomials __label__OWNX
We define the  loss rank  of  SYMBOL  as the number of other (fictitious) data  SYMBOL  that are fitted better by  SYMBOL  than  SYMBOL  is fitted by  SYMBOL , as measured by some loss function __label__OWNX
The loss rank is large for regressors fitting  SYMBOL  not well  and  for too flexible regressors (in both cases the regressor fits many other  SYMBOL  better) __label__OWNX
The loss rank has a minimum for not too flexible regressors which fit  SYMBOL  not too bad __label__OWNX
We claim that minimizing the loss rank is a suitable model selection criterion, since it trades off the quality of fit with the flexibility of the model __label__OWNX
Unlike PML, our new Loss Rank Principle (LoRP) works without a noise (stochastic sampling) model, and is directly applicable to any non-parametric regressor, like kNN __label__CONT
In Section  we derive explicit expressions for the loss rank for the important class of linear regressors, which includes kNN, polynomial, linear basis function (LBFR), Kernel, and projective regression __label__OWNX
In this paper we just scratch at the surface of LoRP __label__OWNX
Section  contains further considerations, to be elaborated on in the future __label__OWNX
we propose a nonparametric bayesian factor regression model that accounts for uncertainty in the number of factors  and the relationship between factors __label__AIMX
to accomplish this  we propose a sparse variant of the indian buffet process and couple this with a hierarchical model over factors  based on kingman s coalescent __label__OWNX
we apply this model to two problems  factor analysis and factor regression  in gene expression data analysis __label__AIMX
factor analysis is the task of explaining data by means of a set of  latent factors __label__MISC
the latent factor representation achieves two fold benefits    NUMBER   discovering the latent  process  underlying the data    NUMBER   simpler predictive modeling through a compact data representation __label__MISC
in particular    NUMBER   is motivated by the problem of prediction in the    large p small n    paradigm  CITATION   where the number of features   greatly exceeds the number of examples    potentially resulting in overfitting __label__MISC
we address three fundamental shortcomings of standard factor analysis approaches  CITATION     NUMBER   we do not assume a known number of factors    NUMBER   we do not assume factors are independent    NUMBER   we do not assume all features are relevant to the factor analysis __label__CONT
our motivation for this work stems from the task of reconstructing regulatory structure from gene expression data __label__AIMX
in this context  factors correspond to regulatory pathways __label__MISC
our contributions thus parallel the needs of gene pathway modeling __label__AIMX
our factor regression model is fundamentally nonparametric __label__OWNX
in particular  we treat the gene to factor relationship nonparametrically by proposing a sparse variant of the indian buffet process  ibp   CITATION   designed to account for the sparsity of relevant genes  features __label__OWNX
the nonparametric nature of our sparse ibp requires that the hierarchical prior  also  be nonparametric __label__OWNX
a natural choice is kingman s coalescent  CITATION   a popular distribution over infinite binary trees __label__BASE
since our motivation is an application in bioinformatics  our notation and terminology will be drawn from that area __label__OWNX
in particular   genes  are  features    samples  are  examples   and  pathways  are  factors __label__OWNX
in this context  all three contributions of our model still make sense  we do not know how many movie genres there are  some genres are closely related  romance to comedy versus to action   many movies may be spurious __label__OWNX
We propose a nonparametric Bayesian factor regression model that accounts for uncertainty in the number of factors, and the relationship between factors __label__AIMX
To accomplish this, we propose a sparse variant of the Indian Buffet Process and couple this with a hierarchical model over factors, based on Kingman's coalescent __label__OWNX
We apply this model to two problems (factor analysis and factor regression) in gene-expression data analysis __label__OWNX
Factor analysis is the task of explaining data by means of a set of  latent factors __label__MISC
Factor  regression  couples this analysis with a prediction task, where the predictions are made solely on the basis of the factor representation __label__MISC
We address three fundamental shortcomings of standard factor analysis approaches  CITATION : (1) we do not assume a known number of factors; (2) we do not assume factors are independent; (3) we do not assume all features are relevant to the factor analysis __label__AIMX
Our motivation for this work stems from the task of reconstructing regulatory structure from gene-expression data __label__OWNX
In this context, factors correspond to regulatory pathways __label__OWNX
Our contributions thus parallel the needs of gene pathway modeling __label__OWNX
In addition, we couple predictive modeling (for factor regression) within the factor analysis framework itself, instead of having to model it separately __label__OWNX
Our factor regression model is fundamentally nonparametric __label__OWNX
In particular, we treat the gene-to-factor relationship nonparametrically by proposing a sparse variant of the Indian Buffet Process (IBP)  CITATION , designed to account for the sparsity of relevant genes (features) __label__OWNX
We  couple  this IBP with a hierarchical prior over the factors __label__OWNX
This prior explains the fact that pathways are fundamentally related: some are involved in transcription, some in signaling, some in synthesis __label__OWNX
A natural choice is Kingman's coalescent  CITATION , a popular distribution over infinite binary trees __label__BASE
Since our motivation is an application in bioinformatics, our notation and terminology will be drawn from that area __label__OWNX
In particular,  genes  are  features ,  samples  are  examples , and  pathways  are  factors __label__OWNX
However, our model is more general __label__OWNX
An alternative application might be to a collaborative filtering problem, in which case our genes might correspond to movies, our samples might correspond to users and our pathways might correspond to genres __label__OWNX
We propose a nonparametric Bayesian factor regression model that accounts for uncertainty in the number of factors, and the relationship between factors __label__AIMX
We apply this model to two problems (factor analysis and factor regression) in gene-expression data analysis __label__OWNX
Factor  regression  couples this analysis with a prediction task, where the predictions are made solely on the basis of the factor representation __label__MISC
The latent factor representation achieves two-fold benefits: (1) discovering the latent  process  underlying the data; (2) simpler predictive modeling through a compact data representation __label__MISC
In particular, (2) is motivated by the problem of prediction in the  ``large P small N''  paradigm  CITATION , where the number of features  SYMBOL  greatly exceeds the number of examples  SYMBOL , potentially resulting in overfitting __label__MISC
We address three fundamental shortcomings of standard factor analysis approaches  CITATION : (1) we do not assume a known number of factors; (2) we do not assume factors are independent; (3) we do not assume all features are relevant to the factor analysis __label__CONT
Our motivation for this work stems from the task of reconstructing regulatory structure from gene-expression data __label__OWNX
In this context, factors correspond to regulatory pathways __label__OWNX
Our contributions thus parallel the needs of gene pathway modeling __label__OWNX
In addition, we couple predictive modeling (for factor regression) within the factor analysis framework itself, instead of having to model it separately __label__OWNX
In particular, we treat the gene-to-factor relationship nonparametrically by proposing a sparse variant of the Indian Buffet Process (IBP)  CITATION , designed to account for the sparsity of relevant genes (features) __label__OWNX
We  couple  this IBP with a hierarchical prior over the factors __label__OWNX
This prior explains the fact that pathways are fundamentally related: some are involved in transcription, some in signaling, some in synthesis __label__OWNX
The nonparametric nature of our sparse IBP requires that the hierarchical prior  also  be nonparametric __label__OWNX
A natural choice is Kingman's coalescent  CITATION , a popular distribution over infinite binary trees __label__MISC
Since our motivation is an application in bioinformatics, our notation and terminology will be drawn from that area __label__OWNX
In particular,  genes  are  features ,  samples  are  examples , and  pathways  are  factors __label__OWNX
However, our model is more general __label__OWNX
An alternative application might be to a collaborative filtering problem, in which case our genes might correspond to movies, our samples might correspond to users and our pathways might correspond to genres __label__OWNX
In this context, all three contributions of our model still make sense: we do not know how many movie genres there are; some genres are closely related (romance to comedy versus to action); many movies may be spurious __label__OWNX
in the constraint satisfaction problem      the aim is to find an assignment of values to a set of variables subject to specified constraints __label__MISC
in the minimum cost homomorphism problem      one is additionally given weights   for every variable   and value    and the aim is to find an assignment   to the variables that minimizes __label__MISC
let   denote the   problem parameterized by the set of predicates allowed for constraints __label__MISC
we show that   can be studied by using algebraic methods similar to those used for csps __label__AIMX
our result settles a general dichotomy conjecture previously resolved only for certain classes of directed graphs   gutin  hell  rafiey  yeo  european j of combinatorics   NUMBER __label__CONT
constraint satisfaction problems     are a natural way of formalizing a large number of computational problems arising in combinatorial optimization  artificial intelligence  and database theory __label__MISC
this problem has the following two equivalent formulations    NUMBER   to find an assignment of values to a given set of variables  subject to constraints on the values that can be assigned simultaneously to specified subsets of variables  and   NUMBER   to find a homomorphism between two finite relational structures   and __label__MISC
considerable attention has been given to the case where the constraints are restricted to a given finite set of relations    called a constraint language  CITATION __label__MISC
for example  when   is a constraint language over the boolean set   with four ternary predicates            we obtain  NUMBER  sat __label__MISC
this direction of research has been mainly concerned with the computational complexity of   as a function of __label__MISC
it has been shown that the complexity of   is highly connected with relational clones of universal algebra  CITATION __label__MISC
in the minimum cost homomorphism problem      we are given variables subject to constraints and  additionally  costs on variable value pairs __label__MISC
now  the task is not just to find any satisfying assignment to the variables  but one that minimizes the total cost __label__MISC
was introduced in  CITATION  where it was motivated by a real world problem in defence logistics __label__MISC
the question for which directed graphs   the problem   is polynomial time solvable was considered in  CITATION __label__MISC
from this characterization  we obtain a dichotomy for    i e   if   is not polynomial time solvable  then it is np hard __label__OWNX
of course  this dichotomy implies the dichotomy for directed graphs __label__OWNX
in section  NUMBER   we present some preliminaries together with results connecting the complexity of   with conservative algebras __label__OWNX
the main dichotomy theorem is stated in section  NUMBER  and its proof is divided into several parts which can be found in sections  NUMBER   NUMBER __label__OWNX
the np hardness results are collected in section  NUMBER  followed by the building blocks for the tractability result  existence of majority polymorphisms  section  NUMBER   and connections with optimization in perfect graphs  section  NUMBER __label__OWNX
section  NUMBER  introduces the concept of  arithmetical deadlocks  which lay the foundation for the final proof in section  NUMBER __label__OWNX
in section  NUMBER  we reformulate our main result in terms of relational clones __label__OWNX
finally  in section  NUMBER  we explain the relation of our results to previous research and present directions for future research __label__BASE
In the constraint satisfaction problem ( SYMBOL ), the aim is to find an assignment of values to a set of variables subject to specified constraints __label__MISC
In the minimum cost homomorphism problem ( SYMBOL ), one is additionally given weights  SYMBOL  for every variable  SYMBOL  and value  SYMBOL , and the aim is to find an assignment  SYMBOL  to the variables that minimizes  SYMBOL __label__MISC
Let  SYMBOL  denote the  SYMBOL  problem parameterized by the set of predicates allowed for constraints __label__OWNX
We show that  SYMBOL  can be studied by using algebraic methods similar to those used for CSPs __label__OWNX
With the aid of algebraic techniques, we classify the computational complexity of  SYMBOL  for all choices of  SYMBOL __label__OWNX
Our result settles a general dichotomy conjecture previously resolved only for certain classes of directed graphs CITATION __label__AIMX
Constraint satisfaction problems ( SYMBOL ) are a natural way of formalizing a large number of computational problems arising in combinatorial optimization, artificial intelligence, and database theory __label__MISC
This problem has the following two equivalent formulations: (1) to find an assignment of values to a given set of variables, subject to constraints on the values that can be assigned simultaneously to specified subsets of variables, and (2) to find a homomorphism between two finite relational structures  SYMBOL  and  SYMBOL __label__MISC
Applications of  SYMBOL s arise in the propositional logic, database and graph theory, scheduling and many other areas __label__MISC
During the past 30 years,  SYMBOL  and its subproblems has been intensively studied by computer scientists and mathematicians __label__MISC
Considerable attention has been given to the case where the constraints are restricted to a given finite set of relations  SYMBOL , called a constraint language  CITATION __label__MISC
For example, when  SYMBOL  is a constraint language over the boolean set  SYMBOL  with four ternary predicates  SYMBOL ,  SYMBOL ,  SYMBOL ,  SYMBOL  we obtain 3-SAT __label__MISC
This direction of research has been mainly concerned with the computational complexity of  SYMBOL  as a function of  SYMBOL __label__MISC
It has been shown that the complexity of  SYMBOL  is highly connected with relational clones of universal algebra  CITATION __label__MISC
For every constraint language  SYMBOL , it has been conjectured that  SYMBOL  is either in P or NP-complete  CITATION __label__MISC
In the minimum cost homomorphism problem ( SYMBOL ), we are given variables subject to constraints and, additionally, costs on variable/value pairs __label__MISC
Now, the task is not just to find any satisfying assignment to the variables, but one that minimizes the total cost __label__MISC
SYMBOL  was introduced in  CITATION  where it was motivated by a real-world problem in defence logistics __label__MISC
The question for which directed graphs  SYMBOL  the problem  SYMBOL  is polynomial-time solvable was considered in  CITATION __label__MISC
In this paper, we approach the problem in its most general form by algebraic methods and give a complete algebraic characterization of tractable constraint languages __label__AIMX
From this characterization, we obtain a dichotomy for  SYMBOL , i e , if  SYMBOL  is not polynomial-time solvable, then it is NP-hard __label__OWNX
Of course, this dichotomy implies the dichotomy for directed graphs __label__OWNX
In Section 2, we present some preliminaries together with results connecting the complexity of  SYMBOL  with conservative algebras __label__OWNX
The main dichotomy theorem is stated in Section 3 and its proof is divided into several parts which can be found in Sections 4-8 __label__OWNX
Section 7 introduces the concept of  arithmetical deadlocks  which lay the foundation for the final proof in Section 8 __label__OWNX
In Section 9 we reformulate our main result in terms of relational clones __label__OWNX
Finally, in Section 10 we explain the relation of our results to previous research and present directions for future research __label__OWNX
In the constraint satisfaction problem ( SYMBOL ), the aim is to find an assignment of values to a set of variables subject to specified constraints __label__MISC
In the minimum cost homomorphism problem ( SYMBOL ), one is additionally given weights  SYMBOL  for every variable  SYMBOL  and value  SYMBOL , and the aim is to find an assignment  SYMBOL  to the variables that minimizes  SYMBOL __label__MISC
Let  SYMBOL  denote the  SYMBOL  problem parameterized by the set of predicates allowed for constraints __label__MISC
SYMBOL  is related to many well-studied combinatorial optimization problems, and concrete applications can be found in, for instance, defence logistics and machine learning __label__MISC
We show that  SYMBOL  can be studied by using algebraic methods similar to those used for CSPs __label__AIMX
With the aid of algebraic techniques, we classify the computational complexity of  SYMBOL  for all choices of  SYMBOL __label__OWNX
Our result settles a general dichotomy conjecture previously resolved only for certain classes of directed graphs CITATION __label__OWNX
Constraint satisfaction problems ( SYMBOL ) are a natural way of formalizing a large number of computational problems arising in combinatorial optimization, artificial intelligence, and database theory __label__MISC
Applications of  SYMBOL s arise in the propositional logic, database and graph theory, scheduling and many other areas __label__MISC
During the past 30 years,  SYMBOL  and its subproblems has been intensively studied by computer scientists and mathematicians __label__MISC
Considerable attention has been given to the case where the constraints are restricted to a given finite set of relations  SYMBOL , called a constraint language  CITATION __label__MISC
This direction of research has been mainly concerned with the computational complexity of  SYMBOL  as a function of  SYMBOL __label__MISC
It has been shown that the complexity of  SYMBOL  is highly connected with relational clones of universal algebra  CITATION __label__MISC
For every constraint language  SYMBOL , it has been conjectured that  SYMBOL  is either in P or NP-complete  CITATION __label__MISC
Now, the task is not just to find any satisfying assignment to the variables, but one that minimizes the total cost __label__MISC
SYMBOL  was introduced in  CITATION  where it was motivated by a real-world problem in defence logistics __label__MISC
The question for which directed graphs  SYMBOL  the problem  SYMBOL  is polynomial-time solvable was considered in  CITATION __label__MISC
In this paper, we approach the problem in its most general form by algebraic methods and give a complete algebraic characterization of tractable constraint languages __label__AIMX
From this characterization, we obtain a dichotomy for  SYMBOL , i e , if  SYMBOL  is not polynomial-time solvable, then it is NP-hard __label__OWNX
In Section 2, we present some preliminaries together with results connecting the complexity of  SYMBOL  with conservative algebras __label__OWNX
The main dichotomy theorem is stated in Section 3 and its proof is divided into several parts which can be found in Sections 4-8 __label__OWNX
The NP-hardness results are collected in Section 4 followed by the building blocks for the tractability result: existence of majority polymorphisms (Section 5) and connections with optimization in perfect graphs (Section 6) __label__OWNX
In Section 9 we reformulate our main result in terms of relational clones __label__OWNX
Finally, in Section 10 we explain the relation of our results to previous research and present directions for future research __label__OWNX
Regularized risk minimization with the binary hinge loss and its variants lies at the heart of many machine learning problems __label__MISC
Bundle methods for regularized risk minimization (BMRM) and the closely related SVMStruct are considered the best general purpose solvers to tackle this problem __label__MISC
It was recently shown that BMRM requires  SYMBOL  iterations to converge to an  SYMBOL  accurate solution __label__MISC
In the first part of the paper we use the Hadamard matrix to construct a regularized risk minimization problem and show that these rates cannot be improved __label__AIMX
We then show how one can exploit the structure of the objective function to devise an algorithm for the binary hinge loss which converges to an  SYMBOL  accurate solution in  SYMBOL  iterations __label__OWNX
Let  SYMBOL  denote samples and  SYMBOL  be the corresponding labels __label__MISC
Given a training set of  SYMBOL  sample label pairs  SYMBOL , drawn i i d from a joint probability distribution on  SYMBOL , many machine learning algorithms solve the following regularized risk minimization problem: __label__MISC
Here  SYMBOL  denotes the loss on instance  SYMBOL  using the current model  SYMBOL  and  SYMBOL , the empirical risk, is the average loss on the training set __label__MISC
The regularizer  SYMBOL  acts as a penalty on the complexity of the classifier and prevents overfitting __label__MISC
Usually the loss is convex in  SYMBOL  but can be nonsmooth while the regularizer is usually a smooth strongly convex function __label__MISC
Binary Support Vector Machines (SVMs) are a prototypical example of such regularized risk minimization problems where  SYMBOL  and the loss considered is the binary hinge loss: __label__MISC
Recently, a number of solvers have been proposed for the regularized risk minimization problem __label__MISC
The convergence analysis of SVMStruct was improved to  SYMBOL  iterations by  CITATION __label__MISC
In fact,  CITATION  showed that their convergence analysis holds for a more general solver than SVMStruct namely BMRM (Bundle method for regularized risk minimization) __label__MISC
At every iteration BMRM replaces  SYMBOL  by a piecewise linear lower bound  SYMBOL  and optimizes    to obtain the next iterate  SYMBOL __label__MISC
Here  SYMBOL  denotes an arbitrary subgradient of  SYMBOL  at  SYMBOL  (see Section ) and  SYMBOL __label__MISC
The piecewise linear lower bound is successively tightened until the gap     falls below a predefined tolerance  SYMBOL __label__MISC
Even though BMRM solves an expensive optimization problem at every iteration, the convergence analysis only uses a simple one-dimensional line search to bound the decrease in  SYMBOL __label__CONT
Furthermore, the empirical convergence behavior of BMRM is much better than the theoretically predicted rates on a number of real life problems __label__CONT
It was therefore conjectured that the rates of convergence of BMRM could be improved __label__MISC
In this paper we answer this question in the negative by explicitly constructing a regularized risk minimization problem for which BMRM takes at least  SYMBOL  iterations __label__AIMX
Using a very old result of Nesterov  CITATION  we obtain an algorithm for SVMs which only requires  SYMBOL  iterations to converge to an  SYMBOL  accurate solution; each iteration of the algorithm requires  SYMBOL  work __label__OWNX
Although we primarily focus on the regularized risk minimization with the binary hinge loss, our algorithm can also be used whenever the empirical risk is piecewise linear and contains a small number of pieces __label__OWNX
Examples of this include multiclass, multi-label, and ordinal regression hinge loss and other related losses __label__OWNX
Regularized risk minimization with the binary hinge loss and its variants lies at the heart of many machine learning problems __label__MISC
Bundle methods for regularized risk minimization (BMRM) and the closely related SVMStruct are considered the best general purpose solvers to tackle this problem __label__MISC
It was recently shown that BMRM requires  SYMBOL  iterations to converge to an  SYMBOL  accurate solution __label__MISC
In the first part of the paper we use the Hadamard matrix to construct a regularized risk minimization problem and show that these rates cannot be improved __label__OWNX
We then show how one can exploit the structure of the objective function to devise an algorithm for the binary hinge loss which converges to an  SYMBOL  accurate solution in  SYMBOL  iterations __label__AIMX
Let  SYMBOL  denote samples and  SYMBOL  be the corresponding labels __label__MISC
Given a training set of  SYMBOL  sample label pairs  SYMBOL , drawn iid from a joint probability distribution on  SYMBOL , many machine learning algorithms solve the following regularized risk minimization problem: __label__MISC
Here  SYMBOL  denotes the loss on instance  SYMBOL  using the current model  SYMBOL  and  SYMBOL , the empirical risk, is the average loss on the training set __label__MISC
The regularizer  SYMBOL  acts as a penalty on the complexity of the classifier and prevents overfitting __label__MISC
Usually the loss is convex in  SYMBOL  but can be nonsmooth while the regularizer is usually a smooth strongly convex function __label__MISC
Binary Support Vector Machines (SVMs) are a prototypical example of such regularized risk minimization problems where  SYMBOL  and the loss considered is the binary hinge loss: __label__MISC
Recently, a number of solvers have been proposed for the regularized risk minimization problem __label__MISC
The first and perhaps the best known solver is SVMStruct  CITATION , which was shown to converge in  SYMBOL  iterations to an  SYMBOL  accurate solution __label__MISC
The convergence analysis of SVMStruct was improved to  SYMBOL  iterations by  CITATION __label__MISC
In fact,  CITATION  showed that their convergence analysis holds for a more general solver than SVMStruct namely BMRM (Bundle method for regularized risk minimization) __label__MISC
At every iteration BMRM replaces  SYMBOL  by a piecewise linear lower bound  SYMBOL  and optimizes    to obtain the next iterate  SYMBOL __label__MISC
Here  SYMBOL  denotes an arbitrary subgradient of  SYMBOL  at  SYMBOL  (see Section ) and  SYMBOL __label__MISC
Furthermore, the empirical convergence behavior of BMRM is much better than the theoretically predicted rates on a number of real life problems __label__MISC
It was therefore conjectured that the rates of convergence of BMRM could be improved __label__MISC
In this paper we answer this question in the negative by explicitly constructing a regularized risk minimization problem for which BMRM takes at least  SYMBOL  iterations __label__AIMX
One possible way to circumvent the  SYMBOL  lower bound is to solve the problem in the dual __label__OWNX
Although we primarily focus on the regularized risk minimization with the binary hinge loss, our algorithm can also be used whenever the empirical risk is piecewise linear and contains a small number of pieces __label__OWNX
Examples of this include multiclass, multi-label, and ordinal regression hinge loss and other related losses __label__OWNX
Bundle methods for regularized risk minimization (BMRM) and the closely related SVMStruct are considered the best general purpose solvers to tackle this problem __label__MISC
It was recently shown that BMRM requires  SYMBOL  iterations to converge to an  SYMBOL  accurate solution __label__MISC
In the first part of the paper we use the Hadamard matrix to construct a regularized risk minimization problem and show that these rates cannot be improved __label__AIMX
We then show how one can exploit the structure of the objective function to devise an algorithm for the binary hinge loss which converges to an  SYMBOL  accurate solution in  SYMBOL  iterations __label__AIMX
Given a training set of  SYMBOL  sample label pairs  SYMBOL , drawn iid from a joint probability distribution on  SYMBOL , many machine learning algorithms solve the following regularized risk minimization problem: __label__MISC
Here  SYMBOL  denotes the loss on instance  SYMBOL  using the current model  SYMBOL  and  SYMBOL , the empirical risk, is the average loss on the training set __label__MISC
Usually the loss is convex in  SYMBOL  but can be nonsmooth while the regularizer is usually a smooth strongly convex function __label__MISC
Recently, a number of solvers have been proposed for the regularized risk minimization problem __label__MISC
The first and perhaps the best known solver is SVMStruct  CITATION , which was shown to converge in  SYMBOL  iterations to an  SYMBOL  accurate solution __label__MISC
At every iteration BMRM replaces  SYMBOL  by a piecewise linear lower bound  SYMBOL  and optimizes    to obtain the next iterate  SYMBOL __label__MISC
Here  SYMBOL  denotes an arbitrary subgradient of  SYMBOL  at  SYMBOL  (see Section ) and  SYMBOL __label__MISC
The piecewise linear lower bound is successively tightened until the gap     falls below a predefined tolerance  SYMBOL __label__MISC
Furthermore, the empirical convergence behavior of BMRM is much better than the theoretically predicted rates on a number of real life problems __label__MISC
It was therefore conjectured that the rates of convergence of BMRM could be improved __label__MISC
In this paper we answer this question in the negative by explicitly constructing a regularized risk minimization problem for which BMRM takes at least  SYMBOL  iterations __label__AIMX
One possible way to circumvent the  SYMBOL  lower bound is to solve the problem in the dual __label__MISC
Using a very old result of Nesterov  CITATION  we obtain an algorithm for SVMs which only requires  SYMBOL  iterations to converge to an  SYMBOL  accurate solution; each iteration of the algorithm requires  SYMBOL  work __label__OWNX
Although we primarily focus on the regularized risk minimization with the binary hinge loss, our algorithm can also be used whenever the empirical risk is piecewise linear and contains a small number of pieces __label__OWNX
Examples of this include multiclass, multi-label, and ordinal regression hinge loss and other related losses __label__MISC
similar to research on risky choice, the traditional analysis of intertemporal choice takes the view that an individual behaves so as to maximize the discounted sum of all future utilities __label__MISC
the well-known allais paradox contradicts the fundamental postulates of maximizing the expected value or utility of a risky option __label__MISC
in the field of intertemporal choice, the discounted-utility du theory proposed by paul samuelson in 1937 was presented not only as a valid normative standard but also as a descriptive theory of actual intertemporal choice behavior  CITATION __label__MISC
in its general form, the du theory proposes that the value of an option, x; t, is the product of its present utility, ux, and an exponential temporal discounting function, ft, where t is the time at which x is acquired __label__MISC
the overall value of a mixed option, a = {x, t, x, t, }, denoted va, is simply the sum of these products __label__MISC
that is, va = sigma  ux ft __label__MISC
an option a will be preferred to an option b if and only if va  greater than  vb __label__MISC
however, a large body of empirical evidence demonstrates that people systematically violate this theory __label__MISC
this includes the common difference effect, the magnitude effect, the gain-loss asymmetry, the delay-speedup asymmetry, and so on  CITATION __label__MISC
this situation has led researchers to consider extensions and modifications of the du theory to reconcile it with the experimental data __label__MISC
the most prominent idea to account for these anomalies is the hyperbolic discounting model  CITATION __label__MISC
this model suggests that the discount rate is not dynamically consistent but that the rate is higher between the present and near future and lower between the near and far distant future __label__MISC
however, these models focus on intertemporal choice between pairs of single-dated outcomes represented as pure gains or losses __label__MISC
when these models are applied to intertemporal choice between pairs of multiple-dated outcomes in mixed contexts, there is general agreement on the additive assumption and the independence assumption __label__MISC
with an apt transformation of the discounting rate, the additive assumption means that preferences for outcome sequences are based on a simple aggregation of their individual components within intertemporal choice  CITATION __label__MISC
the independence assumption means that the value or utility of an outcome in one period is independent of outcomes in other periods  CITATION __label__MISC
because risk and delay might be psychologically equivalent, or at least analogous, and because similar psychological processes might underlie risk and intertemporal choice  CITATION , theoretical development in intertemporal choice has progressed steadily along a similar route as that of risky choice  CITATION __label__MISC
both lines of research have spawned a large number of variant models __label__MISC
although the functional forms differ, most theories assume a maximization principle; that is, people calculate the mathematical expectation of each outcome and add them together before choosing the option that maximizes overall value or utility __label__MISC
for example, research on risky decision making does not treat risky choice as limited to pure gains or pure losses but has been extended to include mixed outcomes involving both gains and losses __label__CONT
the well-known allais paradox  CITATION  contradicts the fundamental postulates of maximizing the expected utility of a risky option __label__MISC
the paradox presents a violation of the cancellation axiom, which asserts that, if two options have a common consequence under a particular event, the preference order of the options should be independent of the value of that consequence  CITATION __label__MISC
most models of intertemporal choice have not yet abandoned the additive assumption and the independence assumption __label__MISC
these two assumptions would lead to the cancellation axiom, which indicates that a preference between two sequences with elements in common does not depend on the nature of the common elements __label__MISC
table 1 illustrates an example of the multiple-dated outcomes problem, which would be used to test the cancellation axiom __label__MISC
the violation of cancellation would be observed if the preference orderings were different between problem i and problem i __label__MISC
however, if allais's proposition applies to intertemporal choice, we will eventually encounter an intertemporal version of the allais paradox __label__MISC
we first illustrate our point with a paradox that is an intertemporal-type violation of the cancellation axiom __label__AIMX
similar to research on risky choice, the traditional analysis of intertemporal choice takes the view that an individual behaves so as to maximize the discounted sum of all future utilities __label__MISC
the overall value of a mixed option, a = {x, t, x, t, }, denoted va, is simply the sum of these products __label__MISC
that is, va = sigma  ux ft __label__MISC
an option a will be preferred to an option b if and only if va  greater than  vb __label__MISC
however, a large body of empirical evidence demonstrates that people systematically violate this theory __label__MISC
this includes the common difference effect, the magnitude effect, the gain-loss asymmetry, the delay-speedup asymmetry, and so on  CITATION __label__MISC
this situation has led researchers to consider extensions and modifications of the du theory to reconcile it with the experimental data __label__MISC
this model suggests that the discount rate is not dynamically consistent but that the rate is higher between the present and near future and lower between the near and far distant future __label__MISC
however, these models focus on intertemporal choice between pairs of single-dated outcomes represented as pure gains or losses __label__MISC
when these models are applied to intertemporal choice between pairs of multiple-dated outcomes in mixed contexts, there is general agreement on the additive assumption and the independence assumption __label__MISC
with an apt transformation of the discounting rate, the additive assumption means that preferences for outcome sequences are based on a simple aggregation of their individual components within intertemporal choice  CITATION __label__MISC
the independence assumption means that the value or utility of an outcome in one period is independent of outcomes in other periods  CITATION __label__MISC
because risk and delay might be psychologically equivalent, or at least analogous, and because similar psychological processes might underlie risk and intertemporal choice  CITATION , theoretical development in intertemporal choice has progressed steadily along a similar route as that of risky choice  CITATION __label__MISC
both lines of research have spawned a large number of variant models __label__MISC
for example, research on risky decision making does not treat risky choice as limited to pure gains or pure losses but has been extended to include mixed outcomes involving both gains and losses __label__MISC
examples include the sign-dependent utility model  CITATION , the rank- and sign-dependent utility model  CITATION , and the transfer of attention exchange model  CITATION __label__MISC
the well-known allais paradox  CITATION  contradicts the fundamental postulates of maximizing the expected utility of a risky option __label__MISC
the paradox presents a violation of the cancellation axiom, which asserts that, if two options have a common consequence under a particular event, the preference order of the options should be independent of the value of that consequence  CITATION __label__MISC
since then, many new descriptive theories of risky choice have abandoned the maximization assumption  CITATION __label__MISC
most models of intertemporal choice have not yet abandoned the additive assumption and the independence assumption __label__MISC
these two assumptions would lead to the cancellation axiom, which indicates that a preference between two sequences with elements in common does not depend on the nature of the common elements __label__MISC
in problem i, the additive models predict that adding a common element x at time 2 to both option a and option b would not change the preference orderings __label__OWNX
however, if allais's proposition applies to intertemporal choice, we will eventually encounter an intertemporal version of the allais paradox __label__OWNX
we first illustrate our point with a paradox that is an intertemporal-type violation of the cancellation axiom __label__OWNX
similar to research on risky choice, the traditional analysis of intertemporal choice takes the view that an individual behaves so as to maximize the discounted sum of all future utilities __label__MISC
the well-known allais paradox contradicts the fundamental postulates of maximizing the expected value or utility of a risky option __label__MISC
we describe a violation of the law of diminishing marginal utility as well as an intertemporal version of the allais paradox __label__AIMX
in the field of intertemporal choice, the discounted-utility du theory proposed by paul samuelson in 1937 was presented not only as a valid normative standard but also as a descriptive theory of actual intertemporal choice behavior  CITATION __label__MISC
in its general form, the du theory proposes that the value of an option, x; t, is the product of its present utility, ux, and an exponential temporal discounting function, ft, where t is the time at which x is acquired __label__MISC
the overall value of a mixed option, a = {x, t, x, t, }, denoted va, is simply the sum of these products __label__MISC
however, a large body of empirical evidence demonstrates that people systematically violate this theory __label__CONT
this includes the common difference effect, the magnitude effect, the gain-loss asymmetry, the delay-speedup asymmetry, and so on  CITATION __label__MISC
this situation has led researchers to consider extensions and modifications of the du theory to reconcile it with the experimental data __label__MISC
the most prominent idea to account for these anomalies is the hyperbolic discounting model  CITATION __label__MISC
numerous theories have been developed by transforming the discount function to other forms, from one-parameter hyperbolic discounting  CITATION  to generalized hyperbolic discounting  CITATION , to proportional discounting  CITATION , and to quasi-hyperbolic discounting  CITATION __label__MISC
however, these models focus on intertemporal choice between pairs of single-dated outcomes represented as pure gains or losses __label__MISC
when these models are applied to intertemporal choice between pairs of multiple-dated outcomes in mixed contexts, there is general agreement on the additive assumption and the independence assumption __label__MISC
with an apt transformation of the discounting rate, the additive assumption means that preferences for outcome sequences are based on a simple aggregation of their individual components within intertemporal choice  CITATION __label__MISC
the independence assumption means that the value or utility of an outcome in one period is independent of outcomes in other periods  CITATION __label__MISC
because risk and delay might be psychologically equivalent, or at least analogous, and because similar psychological processes might underlie risk and intertemporal choice  CITATION , theoretical development in intertemporal choice has progressed steadily along a similar route as that of risky choice  CITATION __label__MISC
both lines of research have spawned a large number of variant models __label__MISC
although the functional forms differ, most theories assume a maximization principle; that is, people calculate the mathematical expectation of each outcome and add them together before choosing the option that maximizes overall value or utility __label__MISC
a minor difference is that the existing models of intertemporal choice are relatively underdeveloped and are less flexible in dealing with empirical challenges __label__MISC
the well-known allais paradox  CITATION  contradicts the fundamental postulates of maximizing the expected utility of a risky option __label__MISC
the paradox presents a violation of the cancellation axiom, which asserts that, if two options have a common consequence under a particular event, the preference order of the options should be independent of the value of that consequence  CITATION __label__MISC
most models of intertemporal choice have not yet abandoned the additive assumption and the independence assumption __label__CONT
these two assumptions would lead to the cancellation axiom, which indicates that a preference between two sequences with elements in common does not depend on the nature of the common elements __label__MISC
in problem i, the additive models predict that adding a common element x at time 2 to both option a and option b would not change the preference orderings __label__MISC
the violation of cancellation would be observed if the preference orderings were different between problem i and problem i __label__MISC
however, if allais's proposition applies to intertemporal choice, we will eventually encounter an intertemporal version of the allais paradox __label__MISC
we first illustrate our point with a paradox that is an intertemporal-type violation of the cancellation axiom __label__OWNX
this study was designed to assess sex-related differences in the selection of an appropriate strategy when facing novelty __label__OWNX
	a simple visuo-spatial task was used to investigate exploratory behavior as a specific response to novelty __label__OWNX
the exploration task was followed by a visual discrimination task  and the responses were analyzed using signal detection theory __label__OWNX
during exploration women selected a local searching strategy in which the metric distance between what is already known and what is unknown was reduced  whereas men adopted a global strategy based on an approximately uniform distribution of choices __label__OWNX
women's exploratory behavior gives rise to a notion of a secure base warranting a sense of safety while men's behavior does not appear to be influenced by risk __label__OWNX
this sex-related difference was interpreted as a difference in beliefs concerning the likelihood of uncertain events influencing risk evaluation __label__OWNX
males and females seem to differ in spatial abilities and styles  CITATION __label__MISC
generally  studies involving navigational problems showed that female cognitive style relies more on detailed information  while male style relies more on global information  CITATION __label__MISC
evolutionary mechanisms could potentially account for sex differences in spatial behavior __label__MISC
for example  these behavioral differences may be due to mating patterns that induced a selection of large-range navigation in males  CITATION __label__MISC
mating patterns or mating strategies are linked to the dynamics of reproduction and sexual selection  CITATION   and sexual selection is restricted to characteristics that influence mate choice and competition for mates __label__MISC
typically  males have to compete through extensive ranging for access to mates while females have to choose mating partners according to reproductive success  CITATION __label__MISC
another proposition  but exclusively directed at humans  suggested that the division of labor game hunting and plant gathering would have put greater selection pressure on females' spatial memory because females sustained gathering duties  CITATION __label__MISC
however  as argued by ecuyer-dab and robert  CITATION    the selection of male characteristics depends on females' choice for mates __label__MISC
in females  however  spatial cognition would have been primarily shaped by the natural selection of a strong concern for survival both of self and of offspring __label__MISC
this concern would have compelled them to favor low-risk strategies  like concentrating on proximal spatial cues  when coping with space-related problems __label__MISC
such focusing would have enabled secure navigation based on detailed landmark encoding  as well as  in certain species  regular feeding based on remembering the exact locations of potential resources  p  NUMBER __label__MISC
thus  the hypothesis of labor division would be a by-product of sexual selection and not the cause of sex differences in spatial behavior __label__MISC
in that context spatial skills play a crucial role since they increase reproductive success and the accessibility to food resource but  at the same time  multiply the risks of getting lost  being killed or consumed by other animals predation __label__MISC
experimental investigations of sex differences in spatial abilities yield apparently disparate results  CITATION __label__CONT
this might be partly due to the complexity of contemporary experimental designs  but also to a lack of investigations concerning decision-making processes involved in the selection of strategies __label__MISC
the current study investigates sex differences in basic behaviors like exploration  detection and discrimination involving the selection of strategies when coping with uncertainty __label__OWNX
following the above quotation from ecuyer-dab and robert's  the hypothesis is that women  compared to men  should favor low-risk strategies when coping with space-related problems __label__OWNX
to test this  i used a simple spontaneous two-dimensional exploratory task __label__OWNX
this choice relies on the fact that exploration is a natural behavior and that it is fundamental in acquiring spatial knowledge __label__OWNX
it seems to be based on driving factors such as curiosity  comfort or mastery over one's environment __label__MISC
moreover  it is commonly defined as serving to reduce uncertainty and thus allow coping with fear  CITATION __label__MISC
exploration is mainly characterized by a succession of progressions and stops  CITATION   and the selection of exploration could rely on its capacity to act as a regulator of uncertainty __label__MISC
indeed  progressions are based on decisions taken during stops  and stops correspond to choice points allowing decisions __label__MISC
in order to assess risk-taking  a classical visual discrimination task based on the stimuli observed during the exploration task was used __label__OWNX
this study was designed to assess sex-related differences in the selection of an appropriate strategy when facing novelty __label__AIMX
a simple visuo-spatial task was used to investigate exploratory behavior as a specific response to novelty __label__OWNX
during exploration women selected a local searching strategy in which the metric distance between what is already known and what is unknown was reduced  whereas men adopted a global strategy based on an approximately uniform distribution of choices __label__OWNX
women's exploratory behavior gives rise to a notion of a secure base warranting a sense of safety while men's behavior does not appear to be influenced by risk __label__OWNX
this sex-related difference was interpreted as a difference in beliefs concerning the likelihood of uncertain events influencing risk evaluation __label__OWNX
males and females seem to differ in spatial abilities and styles  CITATION __label__MISC
generally  studies involving navigational problems showed that female cognitive style relies more on detailed information  while male style relies more on global information  CITATION __label__MISC
for example  these behavioral differences may be due to mating patterns that induced a selection of large-range navigation in males  CITATION __label__MISC
mating patterns or mating strategies are linked to the dynamics of reproduction and sexual selection  CITATION   and sexual selection is restricted to characteristics that influence mate choice and competition for mates __label__MISC
typically  males have to compete through extensive ranging for access to mates while females have to choose mating partners according to reproductive success  CITATION __label__MISC
another proposition  but exclusively directed at humans  suggested that the division of labor game hunting and plant gathering would have put greater selection pressure on females' spatial memory because females sustained gathering duties  CITATION __label__MISC
however  as argued by ecuyer-dab and robert  CITATION    the selection of male characteristics depends on females' choice for mates __label__MISC
this concern would have compelled them to favor low-risk strategies  like concentrating on proximal spatial cues  when coping with space-related problems __label__MISC
such focusing would have enabled secure navigation based on detailed landmark encoding  as well as  in certain species  regular feeding based on remembering the exact locations of potential resources  p  NUMBER __label__MISC
thus  the hypothesis of labor division would be a by-product of sexual selection and not the cause of sex differences in spatial behavior __label__MISC
taken together  the literature seems to indicate that the key to understanding the evolution of behavioral sex differences relies on the relative costs and benefits of producing offspring  CITATION __label__MISC
this might be partly due to the complexity of contemporary experimental designs  but also to a lack of investigations concerning decision-making processes involved in the selection of strategies __label__MISC
the current study investigates sex differences in basic behaviors like exploration  detection and discrimination involving the selection of strategies when coping with uncertainty __label__AIMX
following the above quotation from ecuyer-dab and robert's  the hypothesis is that women  compared to men  should favor low-risk strategies when coping with space-related problems __label__AIMX
to test this  i used a simple spontaneous two-dimensional exploratory task __label__OWNX
this choice relies on the fact that exploration is a natural behavior and that it is fundamental in acquiring spatial knowledge __label__MISC
it seems to be based on driving factors such as curiosity  comfort or mastery over one's environment __label__MISC
moreover  it is commonly defined as serving to reduce uncertainty and thus allow coping with fear  CITATION __label__MISC
exploration is mainly characterized by a succession of progressions and stops  CITATION   and the selection of exploration could rely on its capacity to act as a regulator of uncertainty __label__MISC
indeed  progressions are based on decisions taken during stops  and stops correspond to choice points allowing decisions __label__MISC
voss  CITATION  refers to the exploration process as the generation and testing of hypotheses concerning the object's meaning and potential use __label__BASE
in order to assess risk-taking  a classical visual discrimination task based on the stimuli observed during the exploration task was used __label__OWNX
the results were analyzed with signal detection theory __label__OWNX
this study was designed to assess sex-related differences in the selection of an appropriate strategy when facing novelty __label__AIMX
a simple visuo-spatial task was used to investigate exploratory behavior as a specific response to novelty __label__OWNX
the exploration task was followed by a visual discrimination task  and the responses were analyzed using signal detection theory __label__OWNX
during exploration women selected a local searching strategy in which the metric distance between what is already known and what is unknown was reduced  whereas men adopted a global strategy based on an approximately uniform distribution of choices __label__OWNX
women's exploratory behavior gives rise to a notion of a secure base warranting a sense of safety while men's behavior does not appear to be influenced by risk __label__OWNX
this sex-related difference was interpreted as a difference in beliefs concerning the likelihood of uncertain events influencing risk evaluation __label__OWNX
males and females seem to differ in spatial abilities and styles  CITATION __label__MISC
generally  studies involving navigational problems showed that female cognitive style relies more on detailed information  while male style relies more on global information  CITATION __label__MISC
for example  these behavioral differences may be due to mating patterns that induced a selection of large-range navigation in males  CITATION __label__MISC
mating patterns or mating strategies are linked to the dynamics of reproduction and sexual selection  CITATION   and sexual selection is restricted to characteristics that influence mate choice and competition for mates __label__MISC
typically  males have to compete through extensive ranging for access to mates while females have to choose mating partners according to reproductive success  CITATION __label__MISC
another proposition  but exclusively directed at humans  suggested that the division of labor game hunting and plant gathering would have put greater selection pressure on females' spatial memory because females sustained gathering duties  CITATION __label__MISC
in females  however  spatial cognition would have been primarily shaped by the natural selection of a strong concern for survival both of self and of offspring __label__MISC
this concern would have compelled them to favor low-risk strategies  like concentrating on proximal spatial cues  when coping with space-related problems __label__MISC
thus  the hypothesis of labor division would be a by-product of sexual selection and not the cause of sex differences in spatial behavior __label__MISC
taken together  the literature seems to indicate that the key to understanding the evolution of behavioral sex differences relies on the relative costs and benefits of producing offspring  CITATION __label__MISC
in that context spatial skills play a crucial role since they increase reproductive success and the accessibility to food resource but  at the same time  multiply the risks of getting lost  being killed or consumed by other animals predation __label__MISC
experimental investigations of sex differences in spatial abilities yield apparently disparate results  CITATION __label__MISC
following the above quotation from ecuyer-dab and robert's  the hypothesis is that women  compared to men  should favor low-risk strategies when coping with space-related problems __label__OWNX
to test this  i used a simple spontaneous two-dimensional exploratory task __label__OWNX
this choice relies on the fact that exploration is a natural behavior and that it is fundamental in acquiring spatial knowledge __label__MISC
it seems to be based on driving factors such as curiosity  comfort or mastery over one's environment __label__MISC
moreover  it is commonly defined as serving to reduce uncertainty and thus allow coping with fear  CITATION __label__MISC
exploration is mainly characterized by a succession of progressions and stops  CITATION   and the selection of exploration could rely on its capacity to act as a regulator of uncertainty __label__MISC
indeed  progressions are based on decisions taken during stops  and stops correspond to choice points allowing decisions __label__MISC
voss  CITATION  refers to the exploration process as the generation and testing of hypotheses concerning the object's meaning and potential use __label__MISC
in order to assess risk-taking  a classical visual discrimination task based on the stimuli observed during the exploration task was used __label__OWNX
the results were analyzed with signal detection theory __label__OWNX
the paper extends research on fixed-pie perceptions by suggesting that disputants may prefer proposals that are perceived to be equally attractive to both parties i e , balanced rather than one-sided, because balanced agreements are seen as more likely to be successfully implemented __label__AIMX
we test our predictions using data on israeli support for the geneva accords, an agreement for a two state solution negotiated by unofficial delegations of israel and the palestinian authority in 2003 __label__OWNX
we show that implementation concerns create a demand among israelis for balance in the degree to which each side favors or opposes the agreement __label__OWNX
the effect of balance is noteworthy in that it creates considerable support for proposals even when a majority of israelis and palestinians oppose the deal __label__OWNX
normative models of bargaining and negotiation suggest that if there is potential for mutual benefit, conflicting parties should be able to achieve it  CITATION __label__MISC
descriptive accounts and empirical investigations of negotiation behavior  CITATION , however, suggest that a number of psychological barriers to conflict resolution are likely to make efficient deal making difficult  CITATION __label__CONT
the fixed-pie bias refers to the belief that any gain for one party will be associated with an equivalent loss to the other party __label__MISC
a large body of research finds that negotiators are susceptible to the fixed-pie bias prior to, during, and even after negotiations  CITATION __label__MISC
in the current paper we investigate and extend research on fixed pie bias in the context of protracted intergroup conflict __label__BASE
the paper extends research on fixed-pie perceptions by suggesting that disputants may prefer proposals that are perceived to be equally attractive to both parties i e , balanced rather than one-sided, because balanced agreements are seen as more likely to be successfully implemented __label__AIMX
we test our predictions using data on israeli support for the geneva accords, an agreement for a two state solution negotiated by unofficial delegations of israel and the palestinian authority in 2003 __label__OWNX
we show that implementation concerns create a demand among israelis for balance in the degree to which each side favors or opposes the agreement __label__AIMX
the effect of balance is noteworthy in that it creates considerable support for proposals even when a majority of israelis and palestinians oppose the deal __label__OWNX
descriptive accounts and empirical investigations of negotiation behavior  CITATION , however, suggest that a number of psychological barriers to conflict resolution are likely to make efficient deal making difficult  CITATION __label__CONT
for example, research on cognitive biases associated with egocentric perceptions suggests that negotiators and evaluators of negotiated agreements are likely to exhibit a "fixed-pie bias"  CITATION __label__MISC
the fixed-pie bias refers to the belief that any gain for one party will be associated with an equivalent loss to the other party __label__MISC
this belief is a "bias" when it persists even in contexts where there is a possibility of compatible interests or mutual benefit __label__CONT
in the current paper we investigate and extend research on fixed pie bias in the context of protracted intergroup conflict __label__AIMX
the paper extends research on fixed-pie perceptions by suggesting that disputants may prefer proposals that are perceived to be equally attractive to both parties i e , balanced rather than one-sided, because balanced agreements are seen as more likely to be successfully implemented __label__AIMX
we test our predictions using data on israeli support for the geneva accords, an agreement for a two state solution negotiated by unofficial delegations of israel and the palestinian authority in 2003 __label__OWNX
the results demonstrate that israelis are more likely to support agreements that are seen favorably by other israelis, but - contrary to fixed-pie predictions - israeli support for the accords does not diminish simply because a majority of palestinians favors rather than opposes the accords __label__OWNX
we show that implementation concerns create a demand among israelis for balance in the degree to which each side favors or opposes the agreement __label__OWNX
the effect of balance is noteworthy in that it creates considerable support for proposals even when a majority of israelis and palestinians oppose the deal __label__OWNX
for example, research on cognitive biases associated with egocentric perceptions suggests that negotiators and evaluators of negotiated agreements are likely to exhibit a "fixed-pie bias"  CITATION __label__MISC
the fixed-pie bias refers to the belief that any gain for one party will be associated with an equivalent loss to the other party __label__MISC
this belief is a "bias" when it persists even in contexts where there is a possibility of compatible interests or mutual benefit __label__MISC
we manipulated the likelihood that individuals would identify self-control conflict, and we measured their trait ability to implement self-control strategies __label__OWNX
our analysis reveals a positive and significant correlation between trait self-control and pro-social behavior in the treatment where we expected a relatively high likelihood of conflict identification-but not in the treatment where we expected a low likelihood __label__OWNX
the magnitude of the effect is of economic significance __label__OWNX
lured by temptation, individuals may find themselves acting against their better judgment __label__MISC
for example, the dieter faced with the opportunity to indulge in a delicious creamy cake may perceive a conflict between indulging and maintaining a good figure __label__MISC
the student may feel conflicted between the desire to go to the cinema and her better judgment to stay home and study __label__MISC
and, similarly, the fashionista might feel conflicted between the temptation to purchase new boots and her better judgment to maintain a responsible budget __label__MISC
perhaps less intuitively, but no less importantly, the question of pro-social versus selfish behavior may be understood in similar terms __label__MISC
this conceptualization may help reconcile conflicting notions in economics of selfish and pro-social motivations __label__MISC
that individuals should care much about their own self-interest seems almost tautological and requires little further exposition, but that individuals also should care about the interest of others-at the expense of that of their own-has attracted considerable attention  CITATION __label__MISC
for example, many individuals voluntarily contribute to charity or to public goods e g , recycling, and they pay their taxes despite low likelihood of punishment for failing to do so __label__MISC
nonetheless, one could imagine that even individuals of generally pro-social inclination on occasion may feel tempted to act selfishly and hence underreport income to the authorities __label__MISC
that is, pro-social preferences potentially fly in the face of basic urges for personal gain-or greed-and the individual may thus experience a self-control conflict between better judgment to act pro-socially and the temptation to act selfishly __label__MISC
a multitude of conceptualizations exist, many of which are complementary __label__MISC
willpower, then, represents the combined resources that the executive function-or the planner, in the parlance of thaler and shefrin  CITATION -brings to bear in a deliberate struggle against temptation  CITATION __label__MISC
such resources may include cognitive strategies to divert attention away from temptation  CITATION , strategies of pre-commitment  CITATION , or possibly the sheer strength of mind to hold back from the song of the sirens __label__MISC
our conceptualization of self-control mirrors these __label__MISC
only recently has the psychological literature started to explore how the question of pro-social versus selfish behavior relates to that of self-control __label__MISC
loewenstein  CITATION  suggests that selfish behavior may be motivated by visceral urges or drive-states, resembling cravings for relief from hunger, pain, and sexual deprivation __label__MISC
o'donoghue and loewenstein  CITATION  argue that such selfish urges may conflict with the "colder", more abstract preferences for altruism, as visceral urges for sweets may conflict with more abstract preferences for a fine figure or good health __label__MISC
at present, there is but indirect evidence for this idea __label__CONT
albrecht et al CITATION  report consistent results; individuals who choose between immediate and delayed rewards for themselves exhibit less patience and more affective involvement activation in the dopaminergic reward system than do individuals who make such choices for others-or for themselves in the future __label__MISC
that is, more "impatient" individuals contributed less to the public good than did "patient" ones __label__MISC
furthermore, burks et al CITATION  find that "short-term" patience-the  beta   in the  beta  -&#x3b4;  model-is positively associated with cooperative behavior in a sequential prisoner's dilemma __label__MISC
however, duffy and smith  CITATION  report no effect of cognitive load-a manipulation intended to deplete cognitive resources and thereby impair self-control-on outcomes across treatments in a repeated multi-player prisoner's dilemma __label__MISC
an emerging literature on the "default" response in games of trust and reciprocity lends further credence to the notion that altruistic responses require self-control __label__MISC
achtziger et al CITATION  subjected players in an ultimatum game to cognitive resource depletion, and show that depleted proposers made lower offers-they became less altruistic __label__MISC
moreover, depleted responders were more likely to reject offers that were unfair to themselves-they exhibited "altruistic punishment" __label__MISC
halali et al CITATION  report the same for responders, but with a different depletion task __label__MISC
using a trust game, knoch et al CITATION  subjected trustees' right lateral prefrontal cortex to transcranial magnetic stimulation, which reduces functioning in the targeted brain region __label__MISC
trustees, though cognizant that returning a share of the investments was both strategic and norm-compliant, were unable to do so under impaired executive functioning; self-control seems necessary to act on the better judgment to resist the temptation to keep the received investment entirely for oneself __label__MISC
one interpretation of their results is that the default behavior is to act selfishly and that pro-social behavior requires the successful resolution of a self-control conflict, which slows the response time __label__MISC
such successful resolution of conflict would require cognitive resources, but hauge et al CITATION  report no effect of cognitive load on players in one-shot dictator games __label__MISC
in this paper we attempt a more direct test of the hypothesis that pro-social versus selfish behavior may represent a self-control problem __label__AIMX
we employ a standard measure of pure pro-social behavior, the one-shot dictator game, which invokes neither concerns for strategy nor for reciprocity; and a well-grounded psychometric measure of self-control, the rosenbaum self-control schedule  CITATION __label__OWNX
further, we explore the conditions under which we expect an association between self-control and pro-social behavior __label__OWNX
in so doing, we rely on two conditions necessary for successfully exercising restraint in the face of temptation; myrseth and fishbach  CITATION  propose a two-stage model of self-control, which postulates that an individual in the face of temptation first identifies conflict or not between indulging and pursuing a higher-order goal and, second, that the individual next employs self-control strategies if and only if conflict was identified at the first stage see figure 1 __label__BASE
determinants of conflict identification in the face of temptation have been explored only recently __label__MISC
in some contexts, the question is almost trivial and identification of conflict virtually obvious __label__MISC
for example, the diabetic dieter probably knows that having even a single, tempting chocolate may incur major costs __label__MISC
however, the question of self-control conflict is more ambiguous for the non-diabetic dieter, who faces the same chocolate __label__MISC
having this one chocolate alone will not incur major costs, but doing so regularly might __label__MISC
similarly, the good citizen may find that a general failure to act generously would represent a major threat to his self-image, but being stingy on just a couple of occasions is a more ambiguous matter __label__MISC
myrseth and fishbach  CITATION  use the term epsilon cost temptation to denote tempting opportunities that incur nothing but trivial costs when consumed in small amounts, but potentially serious costs when consumed extensively __label__MISC
they argue that individuals identify self-control conflict in the face of epsilon cost temptation if and only if two conditions are met: a the focal consumption opportunity must be viewed in relation to multiple additional opportunities, and b the decision maker must assume that similar choices are made for each opportunity  CITATION __label__MISC
that is, considering the question of whether or not to have a delicious creamy cake will evoke self-control conflict in the dieter if the dining opportunity is viewed in relation to future opportunities for dessert consumption, but not if the dining opportunity is viewed in isolation, as a singular episode __label__MISC
similarly, the question of whether or not to be generous-to donate to a charitable organization-may elicit self-control conflict if the decision is viewed in relation to future decisions, but not if the decision is viewed in isolation __label__MISC
if viewed in relation to future decisions, the question of how much to donate on a single occasion may have bearing on the decision maker's self-image; donating now-and in the future-indicates a generous character, whereas keeping the money for oneself does not __label__MISC
however, if viewed in isolation, the question of how much to donate has little bearing on self-image; the present decision of how much to donate is considered only in light of immediate consequences, leaving self-image out of the equation __label__MISC
because a consistent self-image represents an important motivator for pro-social behavior  CITATION , we expect that individuals are more likely to identify self-control conflict between selfish and pro-social behavior if the allocation decision is seen in relation to future opportunities than if it is seen in isolation __label__MISC
they find that presenting a calendar displaying the current month, with a grid separating the dates, raised participants' subsequent consumption of potato chips relative to that of participants whom were presented a calendar without a grid __label__MISC
they argue that the gridded calendar activated an isolated versus interrelated frame of the choice opportunity; it made participants more likely to isolate the date in question and thus less likely to see the decision task in relation to similar future opportunities __label__MISC
consequently, the grid reduced the likelihood that participants would identify a conflict between the temptation to have chips and the better judgment to maintain a fine figure and good health __label__MISC
indeed, participants who viewed the gridded calendar reported experiencing less conflict during their decision to have chips or not than did those who viewed the non-gridded calendar __label__MISC
to explore our hypothesis that the problem of pro-social versus selfish behavior may represent one of self-control, we have applied the empirical strategy from myrseth and fishbach  CITATION  in the dictator game-a participant is granted an endowment and asked to split it between herself and a recipient  CITATION , and in our case the red cross featured as recipient  CITATION __label__OWNX
if pro-social versus selfish behavior could represent a self-control conflict, we would expect participants' trait self-control, as measured by rosenbaum's  CITATION  scale, to correlate positively with pro-social behavior for participants who have just previously viewed a calendar without a grid, but less so or not at all for participants who have viewed a calendar with __label__OWNX
in the case of low likelihood, the slope is expected to be weakly positive __label__OWNX
in the case of the higher likelihood, however, the slope is expected to be strictly greater than that in the case of low likelihood __label__OWNX
this means that for a given level of self-control, one might observe substantially different donation behavior depending on whether conflict was identified or not __label__OWNX
we test in the context of a dictator game the proposition that individuals may experience a self-control conflict between the temptation to act selfishly and the better judgment to act pro-socially __label__AIMX
our analysis reveals a positive and significant correlation between trait self-control and pro-social behavior in the treatment where we expected a relatively high likelihood of conflict identification-but not in the treatment where we expected a low likelihood __label__OWNX
the magnitude of the effect is of economic significance __label__MISC
we conclude that subtle cues might prove sufficient to alter individuals' perception of allocation opportunities, thereby prompting individuals to draw on their own cognitive resources to act pro-socially __label__OWNX
self-control failure, famously termed akrasia in plato's protagoras  CITATION , persists throughout domains of daily life and represents a central issue of both philosophy and modern-day social sciences __label__MISC
for example, the dieter faced with the opportunity to indulge in a delicious creamy cake may perceive a conflict between indulging and maintaining a good figure __label__MISC
the student may feel conflicted between the desire to go to the cinema and her better judgment to stay home and study __label__MISC
perhaps less intuitively, but no less importantly, the question of pro-social versus selfish behavior may be understood in similar terms __label__MISC
this conceptualization may help reconcile conflicting notions in economics of selfish and pro-social motivations __label__MISC
that individuals should care much about their own self-interest seems almost tautological and requires little further exposition, but that individuals also should care about the interest of others-at the expense of that of their own-has attracted considerable attention  CITATION __label__MISC
nonetheless, one could imagine that even individuals of generally pro-social inclination on occasion may feel tempted to act selfishly and hence underreport income to the authorities __label__MISC
that is, pro-social preferences potentially fly in the face of basic urges for personal gain-or greed-and the individual may thus experience a self-control conflict between better judgment to act pro-socially and the temptation to act selfishly __label__MISC
self-control-our capacity to overrule temptation-is no less complex than it is important __label__MISC
a multitude of conceptualizations exist, many of which are complementary __label__MISC
typically, and in line with classic ideas of the conflict between reason and passion, authors view self-control as a "cold" executive function that guides behavior in the face of "hot" impulses to act against better judgment  CITATION __label__MISC
willpower, then, represents the combined resources that the executive function-or the planner, in the parlance of thaler and shefrin  CITATION -brings to bear in a deliberate struggle against temptation  CITATION __label__MISC
such resources may include cognitive strategies to divert attention away from temptation  CITATION , strategies of pre-commitment  CITATION , or possibly the sheer strength of mind to hold back from the song of the sirens __label__MISC
our conceptualization of self-control mirrors these __label__OWNX
only recently has the psychological literature started to explore how the question of pro-social versus selfish behavior relates to that of self-control __label__MISC
loewenstein  CITATION  suggests that selfish behavior may be motivated by visceral urges or drive-states, resembling cravings for relief from hunger, pain, and sexual deprivation __label__MISC
at present, there is but indirect evidence for this idea __label__CONT
for example, pronin et al CITATION  show that decisions about others resemble decisions about "future selves", both classes of which contrast to decisions about less abstract "present selves" __label__MISC
albrecht et al CITATION  report consistent results; individuals who choose between immediate and delayed rewards for themselves exhibit less patience and more affective involvement activation in the dopaminergic reward system than do individuals who make such choices for others-or for themselves in the future __label__MISC
moreover, curry et al CITATION  find in a standard public goods game that individuals' discount rates are negatively associated with their contributions to the public good __label__MISC
arriving at similar results, fehr and leibbrandt  CITATION  report that patient vs impatient fishermen, whose time preferences were elicited in the lab, exhibited more cooperative behavior in a common resource problem and were in the field less likely to over-exploit the common pool resource __label__MISC
furthermore, burks et al CITATION  find that "short-term" patience-the  beta   in the  beta  -&#x3b4;  model-is positively associated with cooperative behavior in a sequential prisoner's dilemma __label__MISC
however, duffy and smith  CITATION  report no effect of cognitive load-a manipulation intended to deplete cognitive resources and thereby impair self-control-on outcomes across treatments in a repeated multi-player prisoner's dilemma __label__MISC
an emerging literature on the "default" response in games of trust and reciprocity lends further credence to the notion that altruistic responses require self-control __label__MISC
achtziger et al CITATION  subjected players in an ultimatum game to cognitive resource depletion, and show that depleted proposers made lower offers-they became less altruistic __label__MISC
moreover, depleted responders were more likely to reject offers that were unfair to themselves-they exhibited "altruistic punishment" __label__MISC
halali et al CITATION  report the same for responders, but with a different depletion task __label__MISC
crockett et al CITATION  subjected responders to acute tryptophan depletion-a procedure that temporarily reduces serotonin levels in the brain and thereby impairs self-control  CITATION ; reduced serotonin levels raised rejection rates and this reduction is positively correlated with impulsive choice in a delay-discounting task  CITATION __label__MISC
using a trust game, knoch et al CITATION  subjected trustees' right lateral prefrontal cortex to transcranial magnetic stimulation, which reduces functioning in the targeted brain region __label__MISC
trustees, though cognizant that returning a share of the investments was both strategic and norm-compliant, were unable to do so under impaired executive functioning; self-control seems necessary to act on the better judgment to resist the temptation to keep the received investment entirely for oneself __label__MISC
closest to our domain of inquiry, piovesan and wengstrom  CITATION  measured response times of participants in a repeated dictator game, lasting 24 periods __label__BASE
they find both across and within participants that lower response times are associated with more selfish choices __label__MISC
one interpretation of their results is that the default behavior is to act selfishly and that pro-social behavior requires the successful resolution of a self-control conflict, which slows the response time __label__MISC
such successful resolution of conflict would require cognitive resources, but hauge et al CITATION  report no effect of cognitive load on players in one-shot dictator games __label__MISC
in this paper we attempt a more direct test of the hypothesis that pro-social versus selfish behavior may represent a self-control problem __label__AIMX
we employ a standard measure of pure pro-social behavior, the one-shot dictator game, which invokes neither concerns for strategy nor for reciprocity; and a well-grounded psychometric measure of self-control, the rosenbaum self-control schedule  CITATION __label__OWNX
further, we explore the conditions under which we expect an association between self-control and pro-social behavior __label__OWNX
critically, self-control strategies are relevant to the decision to indulge only when the individual has identified self-control conflict __label__MISC
therefore, one strategy for investigating whether the problem of pro-social versus selfish behavior resembles one of self-control is to test whether the tendency to apply self-control strategies is positively associated with pro-social behavior when individuals have identified self-control conflict, but less so or not at all when individuals have not __label__MISC
determinants of conflict identification in the face of temptation have been explored only recently __label__MISC
for example, the diabetic dieter probably knows that having even a single, tempting chocolate may incur major costs __label__MISC
however, the question of self-control conflict is more ambiguous for the non-diabetic dieter, who faces the same chocolate __label__MISC
having this one chocolate alone will not incur major costs, but doing so regularly might __label__MISC
similarly, the good citizen may find that a general failure to act generously would represent a major threat to his self-image, but being stingy on just a couple of occasions is a more ambiguous matter __label__MISC
myrseth and fishbach  CITATION  use the term epsilon cost temptation to denote tempting opportunities that incur nothing but trivial costs when consumed in small amounts, but potentially serious costs when consumed extensively __label__MISC
they argue that individuals identify self-control conflict in the face of epsilon cost temptation if and only if two conditions are met: a the focal consumption opportunity must be viewed in relation to multiple additional opportunities, and b the decision maker must assume that similar choices are made for each opportunity  CITATION __label__MISC
that is, considering the question of whether or not to have a delicious creamy cake will evoke self-control conflict in the dieter if the dining opportunity is viewed in relation to future opportunities for dessert consumption, but not if the dining opportunity is viewed in isolation, as a singular episode __label__MISC
similarly, the question of whether or not to be generous-to donate to a charitable organization-may elicit self-control conflict if the decision is viewed in relation to future decisions, but not if the decision is viewed in isolation __label__MISC
if viewed in relation to future decisions, the question of how much to donate on a single occasion may have bearing on the decision maker's self-image; donating now-and in the future-indicates a generous character, whereas keeping the money for oneself does not __label__MISC
however, if viewed in isolation, the question of how much to donate has little bearing on self-image; the present decision of how much to donate is considered only in light of immediate consequences, leaving self-image out of the equation __label__MISC
because a consistent self-image represents an important motivator for pro-social behavior  CITATION , we expect that individuals are more likely to identify self-control conflict between selfish and pro-social behavior if the allocation decision is seen in relation to future opportunities than if it is seen in isolation __label__MISC
myrseth and fishbach  CITATION  show that subtle framing manipulations are sufficient to influence identification of self-control conflict in the face of epsilon cost temptation __label__MISC
they find that presenting a calendar displaying the current month, with a grid separating the dates, raised participants' subsequent consumption of potato chips relative to that of participants whom were presented a calendar without a grid __label__MISC
they argue that the gridded calendar activated an isolated versus interrelated frame of the choice opportunity; it made participants more likely to isolate the date in question and thus less likely to see the decision task in relation to similar future opportunities __label__MISC
consequently, the grid reduced the likelihood that participants would identify a conflict between the temptation to have chips and the better judgment to maintain a fine figure and good health __label__MISC
indeed, participants who viewed the gridded calendar reported experiencing less conflict during their decision to have chips or not than did those who viewed the non-gridded calendar __label__MISC
furthermore, participants' trait ability to implement self-control strategies, measured by rosenbaum's  CITATION  psychometric scale, was positively associated with chips consumption for those who viewed the calendar without the grid and who were more likely to identify conflict, but not for others who viewed the calendar with and who were less likely to identify conflict __label__MISC
to explore our hypothesis that the problem of pro-social versus selfish behavior may represent one of self-control, we have applied the empirical strategy from myrseth and fishbach  CITATION  in the dictator game-a participant is granted an endowment and asked to split it between herself and a recipient  CITATION , and in our case the red cross featured as recipient  CITATION __label__BASE
the game thus pits pro-social motivations against self-interest __label__OWNX
if pro-social versus selfish behavior could represent a self-control conflict, we would expect participants' trait self-control, as measured by rosenbaum's  CITATION  scale, to correlate positively with pro-social behavior for participants who have just previously viewed a calendar without a grid, but less so or not at all for participants who have viewed a calendar with __label__OWNX
the graph in figure 2 displays donation, as a function of level of self-control, for two different levels of identification likelihood __label__OWNX
in the case of low likelihood, the slope is expected to be weakly positive __label__OWNX
in the case of the higher likelihood, however, the slope is expected to be strictly greater than that in the case of low likelihood __label__OWNX
we manipulated the likelihood that individuals would identify self-control conflict, and we measured their trait ability to implement self-control strategies __label__OWNX
our analysis reveals a positive and significant correlation between trait self-control and pro-social behavior in the treatment where we expected a relatively high likelihood of conflict identification-but not in the treatment where we expected a low likelihood __label__OWNX
lured by temptation, individuals may find themselves acting against their better judgment __label__MISC
self-control failure, famously termed akrasia in plato's protagoras  CITATION , persists throughout domains of daily life and represents a central issue of both philosophy and modern-day social sciences __label__MISC
for example, the dieter faced with the opportunity to indulge in a delicious creamy cake may perceive a conflict between indulging and maintaining a good figure __label__MISC
the student may feel conflicted between the desire to go to the cinema and her better judgment to stay home and study __label__MISC
perhaps less intuitively, but no less importantly, the question of pro-social versus selfish behavior may be understood in similar terms __label__MISC
this conceptualization may help reconcile conflicting notions in economics of selfish and pro-social motivations __label__MISC
that individuals should care much about their own self-interest seems almost tautological and requires little further exposition, but that individuals also should care about the interest of others-at the expense of that of their own-has attracted considerable attention  CITATION __label__MISC
for example, many individuals voluntarily contribute to charity or to public goods e g , recycling, and they pay their taxes despite low likelihood of punishment for failing to do so __label__MISC
that is, pro-social preferences potentially fly in the face of basic urges for personal gain-or greed-and the individual may thus experience a self-control conflict between better judgment to act pro-socially and the temptation to act selfishly __label__MISC
a multitude of conceptualizations exist, many of which are complementary __label__MISC
willpower, then, represents the combined resources that the executive function-or the planner, in the parlance of thaler and shefrin  CITATION -brings to bear in a deliberate struggle against temptation  CITATION __label__MISC
such resources may include cognitive strategies to divert attention away from temptation  CITATION , strategies of pre-commitment  CITATION , or possibly the sheer strength of mind to hold back from the song of the sirens __label__MISC
our conceptualization of self-control mirrors these __label__OWNX
only recently has the psychological literature started to explore how the question of pro-social versus selfish behavior relates to that of self-control __label__MISC
o'donoghue and loewenstein  CITATION  argue that such selfish urges may conflict with the "colder", more abstract preferences for altruism, as visceral urges for sweets may conflict with more abstract preferences for a fine figure or good health __label__MISC
at present, there is but indirect evidence for this idea __label__MISC
for example, pronin et al CITATION  show that decisions about others resemble decisions about "future selves", both classes of which contrast to decisions about less abstract "present selves" __label__MISC
albrecht et al CITATION  report consistent results; individuals who choose between immediate and delayed rewards for themselves exhibit less patience and more affective involvement activation in the dopaminergic reward system than do individuals who make such choices for others-or for themselves in the future __label__MISC
moreover, curry et al CITATION  find in a standard public goods game that individuals' discount rates are negatively associated with their contributions to the public good __label__MISC
that is, more "impatient" individuals contributed less to the public good than did "patient" ones __label__MISC
arriving at similar results, fehr and leibbrandt  CITATION  report that patient vs impatient fishermen, whose time preferences were elicited in the lab, exhibited more cooperative behavior in a common resource problem and were in the field less likely to over-exploit the common pool resource __label__MISC
furthermore, burks et al CITATION  find that "short-term" patience-the  beta   in the  beta  -&#x3b4;  model-is positively associated with cooperative behavior in a sequential prisoner's dilemma __label__MISC
however, duffy and smith  CITATION  report no effect of cognitive load-a manipulation intended to deplete cognitive resources and thereby impair self-control-on outcomes across treatments in a repeated multi-player prisoner's dilemma __label__MISC
an emerging literature on the "default" response in games of trust and reciprocity lends further credence to the notion that altruistic responses require self-control __label__MISC
halali et al CITATION  report the same for responders, but with a different depletion task __label__MISC
crockett et al CITATION  subjected responders to acute tryptophan depletion-a procedure that temporarily reduces serotonin levels in the brain and thereby impairs self-control  CITATION ; reduced serotonin levels raised rejection rates and this reduction is positively correlated with impulsive choice in a delay-discounting task  CITATION __label__MISC
using a trust game, knoch et al CITATION  subjected trustees' right lateral prefrontal cortex to transcranial magnetic stimulation, which reduces functioning in the targeted brain region __label__MISC
trustees, though cognizant that returning a share of the investments was both strategic and norm-compliant, were unable to do so under impaired executive functioning; self-control seems necessary to act on the better judgment to resist the temptation to keep the received investment entirely for oneself __label__MISC
they find both across and within participants that lower response times are associated with more selfish choices __label__MISC
one interpretation of their results is that the default behavior is to act selfishly and that pro-social behavior requires the successful resolution of a self-control conflict, which slows the response time __label__MISC
such successful resolution of conflict would require cognitive resources, but hauge et al CITATION  report no effect of cognitive load on players in one-shot dictator games __label__MISC
in this paper we attempt a more direct test of the hypothesis that pro-social versus selfish behavior may represent a self-control problem __label__AIMX
we employ a standard measure of pure pro-social behavior, the one-shot dictator game, which invokes neither concerns for strategy nor for reciprocity; and a well-grounded psychometric measure of self-control, the rosenbaum self-control schedule  CITATION __label__OWNX
in so doing, we rely on two conditions necessary for successfully exercising restraint in the face of temptation; myrseth and fishbach  CITATION  propose a two-stage model of self-control, which postulates that an individual in the face of temptation first identifies conflict or not between indulging and pursuing a higher-order goal and, second, that the individual next employs self-control strategies if and only if conflict was identified at the first stage see figure 1 __label__BASE
critically, self-control strategies are relevant to the decision to indulge only when the individual has identified self-control conflict __label__MISC
therefore, one strategy for investigating whether the problem of pro-social versus selfish behavior resembles one of self-control is to test whether the tendency to apply self-control strategies is positively associated with pro-social behavior when individuals have identified self-control conflict, but less so or not at all when individuals have not __label__MISC
determinants of conflict identification in the face of temptation have been explored only recently __label__MISC
in some contexts, the question is almost trivial and identification of conflict virtually obvious __label__MISC
for example, the diabetic dieter probably knows that having even a single, tempting chocolate may incur major costs __label__MISC
however, the question of self-control conflict is more ambiguous for the non-diabetic dieter, who faces the same chocolate __label__MISC
having this one chocolate alone will not incur major costs, but doing so regularly might __label__MISC
similarly, the good citizen may find that a general failure to act generously would represent a major threat to his self-image, but being stingy on just a couple of occasions is a more ambiguous matter __label__MISC
myrseth and fishbach  CITATION  use the term epsilon cost temptation to denote tempting opportunities that incur nothing but trivial costs when consumed in small amounts, but potentially serious costs when consumed extensively __label__MISC
they argue that individuals identify self-control conflict in the face of epsilon cost temptation if and only if two conditions are met: a the focal consumption opportunity must be viewed in relation to multiple additional opportunities, and b the decision maker must assume that similar choices are made for each opportunity  CITATION __label__MISC
that is, considering the question of whether or not to have a delicious creamy cake will evoke self-control conflict in the dieter if the dining opportunity is viewed in relation to future opportunities for dessert consumption, but not if the dining opportunity is viewed in isolation, as a singular episode __label__MISC
similarly, the question of whether or not to be generous-to donate to a charitable organization-may elicit self-control conflict if the decision is viewed in relation to future decisions, but not if the decision is viewed in isolation __label__MISC
however, if viewed in isolation, the question of how much to donate has little bearing on self-image; the present decision of how much to donate is considered only in light of immediate consequences, leaving self-image out of the equation __label__MISC
because a consistent self-image represents an important motivator for pro-social behavior  CITATION , we expect that individuals are more likely to identify self-control conflict between selfish and pro-social behavior if the allocation decision is seen in relation to future opportunities than if it is seen in isolation __label__OWNX
myrseth and fishbach  CITATION  show that subtle framing manipulations are sufficient to influence identification of self-control conflict in the face of epsilon cost temptation __label__MISC
they argue that the gridded calendar activated an isolated versus interrelated frame of the choice opportunity; it made participants more likely to isolate the date in question and thus less likely to see the decision task in relation to similar future opportunities __label__MISC
consequently, the grid reduced the likelihood that participants would identify a conflict between the temptation to have chips and the better judgment to maintain a fine figure and good health __label__MISC
furthermore, participants' trait ability to implement self-control strategies, measured by rosenbaum's  CITATION  psychometric scale, was positively associated with chips consumption for those who viewed the calendar without the grid and who were more likely to identify conflict, but not for others who viewed the calendar with and who were less likely to identify conflict __label__MISC
to explore our hypothesis that the problem of pro-social versus selfish behavior may represent one of self-control, we have applied the empirical strategy from myrseth and fishbach  CITATION  in the dictator game-a participant is granted an endowment and asked to split it between herself and a recipient  CITATION , and in our case the red cross featured as recipient  CITATION __label__BASE
the game thus pits pro-social motivations against self-interest __label__OWNX
if pro-social versus selfish behavior could represent a self-control conflict, we would expect participants' trait self-control, as measured by rosenbaum's  CITATION  scale, to correlate positively with pro-social behavior for participants who have just previously viewed a calendar without a grid, but less so or not at all for participants who have viewed a calendar with __label__OWNX
the graph in figure 2 displays donation, as a function of level of self-control, for two different levels of identification likelihood __label__OWNX
in the case of low likelihood, the slope is expected to be weakly positive __label__OWNX
in the case of the higher likelihood, however, the slope is expected to be strictly greater than that in the case of low likelihood __label__OWNX
this means that for a given level of self-control, one might observe substantially different donation behavior depending on whether conflict was identified or not __label__OWNX
prospect theory editing operation, by which a decision maker's reference point is determined, can have important effects on the disutility of the test __label__MISC--the
the basis of the prospect theory value function, this paper develops two approaches to reducing disutility by directing the decision maker's attention to either actual past or expected future losses that result in shifted reference points __label__AIMX--on
providing a graphical description of the approaches and a mathematical proof of the direction of their effect on judgment, we briefly illustrate the potential value of these approaches with examples from qualitative research on prostate cancer treatment decisions __label__OWNX--after
preventative health decisions, such as the decision to undergo an invasive screening test or treatment, people may be deterred from selecting the test because its disutility relative to not testing is greater than the utility associated with prevention of possible disease __label__MISC--in
prospect theory editing operation  CITATION , by which a decision maker's reference point is determined, can have important impacts on the perceived disutility of the test __label__MISC--the
work of rothman, salovey, and colleagues on message framing has tested prospect theory predictions of how the description of test outcomes as gains or losses as well as the conceptualization of the purpose of the test as preventative vs diagnostic and the consequent perception of whether the test is "safe" or "risky" can affect test rates  CITATION __label__MISC--the
message framing theories predict that when a procedure is perceived as risky e g , cancer screening tests may cause a patient to find out that they have cancer, loss-framed messages will promote testing more strongly than gain-framed messages, because people favor risky prospects over sure prospects in the domain of losses __label__MISC--specifically,
the other hand, when a procedure is perceived as safe e g , sunscreen prevents sunburn and skin cancer, gain-framed messages are predicted to be more effective because people prefer sure prospects to risky prospects in the domain of gains __label__MISC--on
public health intervention studies have examined message framing and generally found evidence favoring the predictions  CITATION __label__MISC--several
the basis of the prospect theory value function, this paper develops two approaches to reducing perceived disutility by directing the decision maker's attention to either actual past or expected future losses that can serve as reference points and are not consequences of the test itself __label__AIMX--on
approaches thus differ from message framing, which focuses on how the test outcomes are described and manipulates gain and loss framing __label__CONT--these
instead derive the potential impact of directly refocusing the decision maker's reference point __label__OWNX--we
preventative health decisions, such as the decision to undergo an invasive screening test or treatment, people may be deterred from selecting the test because its perceived disutility relative to not testing is greater than the utility associated with prevention of possible disease __label__MISC--in
prospect theory editing operation, by which a decision maker's reference point is determined, can have important effects on the disutility of the test __label__MISC--the
the basis of the prospect theory value function, this paper develops two approaches to reducing disutility by directing the decision maker's attention to either actual past or expected future losses that result in shifted reference points __label__AIMX--on
providing a graphical description of the approaches and a mathematical proof of the direction of their effect on judgment, we briefly illustrate the potential value of these approaches with examples from qualitative research on prostate cancer treatment decisions __label__OWNX--after
preventative health decisions, such as the decision to undergo an invasive screening test or treatment, people may be deterred from selecting the test because its disutility relative to not testing is greater than the utility associated with prevention of possible disease __label__MISC--in
example, people may feel that the anticipated disutility of a colonoscopy for colorectal cancer screening is great enough relative to the expected utilty of prevention of possible colorectal cancer to dissuade them from seeking colonoscopy __label__MISC--for
prospect theory editing operation  CITATION , by which a decision maker's reference point is determined, can have important impacts on the perceived disutility of the test __label__MISC--the
work of rothman, salovey, and colleagues on message framing has tested prospect theory predictions of how the description of test outcomes as gains or losses as well as the conceptualization of the purpose of the test as preventative vs diagnostic and the consequent perception of whether the test is "safe" or "risky" can affect test rates  CITATION __label__MISC--the
message framing theories predict that when a procedure is perceived as risky e g , cancer screening tests may cause a patient to find out that they have cancer, loss-framed messages will promote testing more strongly than gain-framed messages, because people favor risky prospects over sure prospects in the domain of losses __label__MISC--specifically,
the other hand, when a procedure is perceived as safe e g , sunscreen prevents sunburn and skin cancer, gain-framed messages are predicted to be more effective because people prefer sure prospects to risky prospects in the domain of gains __label__MISC--on
public health intervention studies have examined message framing and generally found evidence favoring the predictions  CITATION __label__MISC--several
the basis of the prospect theory value function, this paper develops two approaches to reducing perceived disutility by directing the decision maker's attention to either actual past or expected future losses that can serve as reference points and are not consequences of the test itself __label__AIMX--on
instead derive the potential impact of directly refocusing the decision maker's reference point __label__OWNX--we
in preventative health decisions, such as the decision to undergo an invasive screening test or treatment, people may be deterred from selecting the test because its perceived disutility relative to not testing is greater than the utility associated with prevention of possible disease __label__MISC
in preventative health decisions, such as the decision to undergo an invasive screening test or treatment, people may be deterred from selecting the test because its disutility relative to not testing is greater than the utility associated with prevention of possible disease __label__MISC
for example, people may feel that the anticipated disutility of a colonoscopy for colorectal cancer screening is great enough relative to the expected utilty of prevention of possible colorectal cancer to dissuade them from seeking colonoscopy __label__MISC
the prospect theory editing operation  CITATION , by which a decision maker's reference point is determined, can have important impacts on the perceived disutility of the test __label__MISC
the work of rothman, salovey, and colleagues on message framing has tested prospect theory predictions of how the description of test outcomes as gains or losses as well as the conceptualization of the purpose of the test as preventative vs diagnostic and the consequent perception of whether the test is "safe" or "risky" can affect test rates  CITATION __label__MISC
specifically, message framing theories predict that when a procedure is perceived as risky e g , cancer screening tests may cause a patient to find out that they have cancer, loss-framed messages will promote testing more strongly than gain-framed messages, because people favor risky prospects over sure prospects in the domain of losses __label__MISC
on the other hand, when a procedure is perceived as safe e g , sunscreen prevents sunburn and skin cancer, gain-framed messages are predicted to be more effective because people prefer sure prospects to risky prospects in the domain of gains __label__MISC
these approaches thus differ from message framing, which focuses on how the test outcomes are described and manipulates gain and loss framing __label__CONT
we instead derive the potential impact of directly refocusing the decision maker's reference point __label__OWNX
previous tests of cumulative prospect theory cpt and of the priority heuristic ph found evidence contradicting these two models of risky decision making. __label__MISC
however, those tests were criticized because they had characteristics that might "trigger" use of other heuristics. __label__CONT
this paper presents new tests that avoid those characteristics. __label__AIMX
expected values of the gambles are nearly equal in each choice. __label__OWNX
in addition, if a person followed expected value ev, expected utility eu, cpt, or ph in these tests, she would shift her preferences in the same direction as shifts in ev or eu __label__OWNX
new tests of probability-consequence interaction were also conducted __label__OWNX
strong interactions were observed, contrary to ph __label__OWNX
this paper compares three models that attempt to describe risky decision making __label__AIMX
these models are cumulative prospect theory cpt  CITATION , birnbaum's  CITATION  transfer of attention exchange model tax, and the priority heuristic ph of brandstatter, gigerenzer, and hertwig  CITATION __label__AIMX
the ph model is based on the idea that people compare one attribute at a time, such as the minimum prizes __label__MISC
in addition, the similarity model of rubinstein  CITATION  as modified by leland  CITATION  is also relevant to these studies, although these studies were not designed to test that model __label__BASE
birnbaum  CITATION  reviewed a number of critical tests that refute any rank dependent utility rdu model  CITATION  including rank and sign-dependent utility  CITATION , cpt, and expected utility eu __label__MISC
birnbaum  CITATION  noted that many of the same tests that refute cpt also contradict the priority heuristic __label__MISC
some of these choices included cases where 90% or more of the participants satisfied stochastic dominance but the priority heuristic predicts indifference __label__MISC
in other choices, significantly more than half of the participants about 70% of undergraduates violated stochastic dominance, but the priority heuristic predicts that people should satisfy it __label__MISC
brandstatter, gigerenzer, and hertwig  CITATION  responded that properties of these choices may have induced people to use other heuristics drawn from a person's "adaptive toolbox __label__MISC
presumably, decision makers first decide what rule to use, then they either apply that rule or choose to use another rule __label__MISC
the mechanism that decides what rule to use has not yet been specified; it is described instead with lists of "triggering conditions," which are estimated from data like parameters __label__CONT
in addition, brandstatter et al CITATION  argued that certain choices reviewed by birnbaum  CITATION  used gambles that differed in expected value ev __label__MISC
brandstatter et al CITATION  presented a figure to show that the priority heuristic is not accurate when expected values evs differ, which led them to suppose that two strategies are at work, one for "easy" choices that differ in ev and one for "harder" choices where evs are nearly equal __label__CONT
brandstatter et al consider ev ratio as a proxy for the "difficulty" of a choice, but do not necessarily hold that people actually compute ratios of ev __label__MISC
they argued that the priority heuristic is accurate for "difficult" choices in which evs are nearly equal __label__MISC
to account for the results, brandstatter et al noted that birnbaum and navarrete  CITATION  used many choices in which both gambles of a choice had the same probability distribution and in some choices two branches had the same probability __label__MISC
ph was not accurate for such choices, so brandstatter, et al CITATION  theorized that people use a "toting up" heuristic for choices in which two branches had the same probability __label__CONT
in some of the choices in birnbaum and navarrete  CITATION , there was a common probability-consequence branch in both choices, which was theorized to trigger editing rules and other heuristics that were called up to account for the failures of the priority heuristic __label__MISC
the arguments of brandstatter et al CITATION  might also provide excuses for previous failures of cpt as well __label__CONT
this paper devises a new type of test that avoids the exceptions stated above __label__AIMX
in these tests, one alternative does not stochastically dominate the other, there are no common probability-consequence branches, probabilities of the consequences are not equal, and expected values are nearly equal __label__OWNX
in addition, unlike previous tests, the new tests use shifts in expected value and expected utility to "help" predictions of ph and cpt __label__CONT
that is, expected value and expected utility are both manipulated such that, if a person shifts his or her judgments in the same direction as the changes in eu or ev, his or her choices will appear consistent with ph and cpt __label__OWNX
however, the choices are designed so that the tax model with parameters typical of previous research predicts that people will shift their choices in the opposite direction of ev, eu, cpt, and ph __label__OWNX
previous tests of cumulative prospect theory cpt and of the priority heuristic ph found evidence contradicting these two models of risky decision making. __label__MISC
however, those tests were criticized because they had characteristics that might "trigger" use of other heuristics. __label__CONT
expected values of the gambles are nearly equal in each choice. __label__OWNX
in addition, if a person followed expected value ev, expected utility eu, cpt, or ph in these tests, she would shift her preferences in the same direction as shifts in ev or eu __label__OWNX
in contrast, the transfer of attention exchange model tax and a similarity model predict that people will reverse preferences in the opposite direction __label__OWNX
results contradict the ph, even when ph is modified to include a preliminary similarity evaluation using the ph parameters __label__OWNX
new tests of probability-consequence interaction were also conducted __label__OWNX
strong interactions were observed, contrary to ph __label__OWNX
these results add to the growing bodies of evidence showing that neither cpt nor ph is an accurate description of risky decision making __label__OWNX
this paper compares three models that attempt to describe risky decision making __label__AIMX
these models are cumulative prospect theory cpt  CITATION , birnbaum's  CITATION  transfer of attention exchange model tax, and the priority heuristic ph of brandstatter, gigerenzer, and hertwig  CITATION __label__AIMX
the ph model is based on the idea that people compare one attribute at a time, such as the minimum prizes __label__MISC
birnbaum  CITATION  noted that many of the same tests that refute cpt also contradict the priority heuristic __label__MISC
for example, the priority heuristic predicted fewer than half of the modal choices analyzed by birnbaum  CITATION , by birnbaum  CITATION , and by birnbaum and navarrete  CITATION __label__MISC
some of these choices included cases where 90% or more of the participants satisfied stochastic dominance but the priority heuristic predicts indifference __label__MISC
in other choices, significantly more than half of the participants about 70% of undergraduates violated stochastic dominance, but the priority heuristic predicts that people should satisfy it __label__MISC
brandstatter, gigerenzer, and hertwig  CITATION  responded that properties of these choices may have induced people to use other heuristics drawn from a person's "adaptive toolbox __label__MISC
presumably, decision makers first decide what rule to use, then they either apply that rule or choose to use another rule __label__MISC
the mechanism that decides what rule to use has not yet been specified; it is described instead with lists of "triggering conditions," which are estimated from data like parameters __label__CONT
brandstatter et al CITATION  concluded that the priority heuristic does not apply when there is a stochastic dominance relation in the choice __label__MISC
brandstatter et al CITATION  presented a figure to show that the priority heuristic is not accurate when expected values evs differ, which led them to suppose that two strategies are at work, one for "easy" choices that differ in ev and one for "harder" choices where evs are nearly equal __label__CONT
from the data, brandstatter et al CITATION  estimated that, when the ratio of ev exceeds 2, people act as if they choose the gamble with the higher ev __label__MISC
brandstatter et al consider ev ratio as a proxy for the "difficulty" of a choice, but do not necessarily hold that people actually compute ratios of ev __label__MISC
they argued that the priority heuristic is accurate for "difficult" choices in which evs are nearly equal __label__MISC
however, birnbaum  CITATION  noted that ev ratios in birnbaum and navarrete  CITATION  had been inside the region where ph is supposed to apply; in that study, the priority heuristic failed to reproduce even half of the modal choices correctly __label__CONT
to account for the results, brandstatter et al noted that birnbaum and navarrete  CITATION  used many choices in which both gambles of a choice had the same probability distribution and in some choices two branches had the same probability __label__MISC
ph was not accurate for such choices, so brandstatter, et al CITATION  theorized that people use a "toting up" heuristic for choices in which two branches had the same probability __label__CONT
in some of the choices in birnbaum and navarrete  CITATION , there was a common probability-consequence branch in both choices, which was theorized to trigger editing rules and other heuristics that were called up to account for the failures of the priority heuristic __label__MISC
the arguments of brandstatter et al CITATION  might also provide excuses for previous failures of cpt as well __label__CONT
this paper devises a new type of test that avoids the exceptions stated above __label__AIMX
in these tests, one alternative does not stochastically dominate the other, there are no common probability-consequence branches, probabilities of the consequences are not equal, and expected values are nearly equal __label__OWNX
in addition, unlike previous tests, the new tests use shifts in expected value and expected utility to "help" predictions of ph and cpt __label__CONT
that is, expected value and expected utility are both manipulated such that, if a person shifts his or her judgments in the same direction as the changes in eu or ev, his or her choices will appear consistent with ph and cpt __label__OWNX
however, the choices are designed so that the tax model with parameters typical of previous research predicts that people will shift their choices in the opposite direction of ev, eu, cpt, and ph __label__OWNX
previous tests of cumulative prospect theory cpt and of the priority heuristic ph found evidence contradicting these two models of risky decision making __label__MISC
however, those tests were criticized because they had characteristics that might "trigger" use of other heuristics __label__MISC
this paper presents new tests that avoid those characteristics __label__AIMX
expected values of the gambles are nearly equal in each choice __label__OWNX
in addition, if a person followed expected value ev, expected utility eu, cpt, or ph in these tests, she would shift her preferences in the same direction as shifts in ev or eu __label__OWNX
results contradict the ph, even when ph is modified to include a preliminary similarity evaluation using the ph parameters __label__CONT
new tests of probability-consequence interaction were also conducted __label__OWNX
strong interactions were observed, contrary to ph __label__OWNX
these results add to the growing bodies of evidence showing that neither cpt nor ph is an accurate description of risky decision making __label__OWNX
this paper compares three models that attempt to describe risky decision making __label__AIMX
these models are cumulative prospect theory cpt  CITATION , birnbaum's  CITATION  transfer of attention exchange model tax, and the priority heuristic ph of brandstatter, gigerenzer, and hertwig  CITATION __label__MISC
the ph model is based on the idea that people compare one attribute at a time, such as the minimum prizes __label__MISC
in addition, the similarity model of rubinstein  CITATION  as modified by leland  CITATION  is also relevant to these studies, although these studies were not designed to test that model __label__MISC
birnbaum  CITATION  reviewed a number of critical tests that refute any rank dependent utility rdu model  CITATION  including rank and sign-dependent utility  CITATION , cpt, and expected utility eu __label__MISC
birnbaum  CITATION  noted that many of the same tests that refute cpt also contradict the priority heuristic __label__MISC
for example, the priority heuristic predicted fewer than half of the modal choices analyzed by birnbaum  CITATION , by birnbaum  CITATION , and by birnbaum and navarrete  CITATION __label__MISC
some of these choices included cases where 90% or more of the participants satisfied stochastic dominance but the priority heuristic predicts indifference __label__MISC
in other choices, significantly more than half of the participants about 70% of undergraduates violated stochastic dominance, but the priority heuristic predicts that people should satisfy it __label__MISC
brandstatter, gigerenzer, and hertwig  CITATION  responded that properties of these choices may have induced people to use other heuristics drawn from a person's "adaptive toolbox" __label__MISC
presumably, decision makers first decide what rule to use, then they either apply that rule or choose to use another rule __label__MISC
the mechanism that decides what rule to use has not yet been specified; it is described instead with lists of "triggering conditions," which are estimated from data like parameters __label__MISC
brandstatter et al CITATION  concluded that the priority heuristic does not apply when there is a stochastic dominance relation in the choice __label__MISC
in addition, brandstatter et al CITATION  argued that certain choices reviewed by birnbaum  CITATION  used gambles that differed in expected value ev __label__MISC
brandstatter et al CITATION  presented a figure to show that the priority heuristic is not accurate when expected values evs differ, which led them to suppose that two strategies are at work, one for "easy" choices that differ in ev and one for "harder" choices where evs are nearly equal __label__MISC
from the data, brandstatter et al CITATION  estimated that, when the ratio of ev exceeds 2, people act as if they choose the gamble with the higher ev __label__MISC
they argued that the priority heuristic is accurate for "difficult" choices in which evs are nearly equal __label__MISC
brandstatter et al CITATION  replicated part of that study and their results confirmed that the priority heuristic reproduced fewer than half of the modal choices that they chose for replication  CITATION __label__MISC
to account for the results, brandstatter et al noted that birnbaum and navarrete  CITATION  used many choices in which both gambles of a choice had the same probability distribution and in some choices two branches had the same probability __label__MISC
in some of the choices in birnbaum and navarrete  CITATION , there was a common probability-consequence branch in both choices, which was theorized to trigger editing rules and other heuristics that were called up to account for the failures of the priority heuristic __label__MISC
this paper devises a new type of test that avoids the exceptions stated above __label__AIMX
in addition, unlike previous tests, the new tests use shifts in expected value and expected utility to "help" predictions of ph and cpt __label__CONT
that is, expected value and expected utility are both manipulated such that, if a person shifts his or her judgments in the same direction as the changes in eu or ev, his or her choices will appear consistent with ph and cpt __label__OWNX
however, the choices are designed so that the tax model with parameters typical of previous research predicts that people will shift their choices in the opposite direction of ev, eu, cpt, and ph __label__OWNX
this paper extends previous research showing that experienced difficulty of recall can influence evaluative judgments CITATION to a field study of university students rating a course __label__AIMX
students completed a mid-course evaluation form in which they were asked to list either  NUMBER  ways in which the course could be improved a relatively easy task or  NUMBER  ways in which the course could be improved a relatively difficult task __label__OWNX
an internal analysis suggests that the number of critiques solicited provides a frame against which accessibility of instances is evaluated __label__OWNX
the paper concludes with a discussion of implications of the present results and possible directions for future research __label__OWNX
this process has generally been demonstrated by asking participants to assess the relative likelihood of two categories in which instances of the first category are more difficult to recall than instances of the second category  despite the fact that instances of the first category are more common in the world __label__MISC
for instance  kahneman and tversky  CITATION  found that most people think the letter r more often appears in english words as the first letter than the third letter  presumably because the first letter provides a better cue for recalling instances of words than does the third letter __label__MISC
in fact  it turns out that r appears more often as the third than first letter in english words __label__MISC
schwarz et al CITATION  observed that the classic studies demonstrating the availability heuristic failed to distinguish an interpretation based on ease of retrieval from an alternative interpretation based on content of retrieval in which an event is judged more common when a larger number of examples come to mind __label__MISC
to tease apart these accounts  schwarz et al CITATION  asked participants in one   study to list either  NUMBER  or  NUMBER  examples of assertive or unassertive behavior that they have exhibited and then rate themselves on their overall degree of assertiveness __label__MISC
thus  an abundance of data supports the original interpretation of the availability heuristic  categories are judged to be more common when instances more easily come to mind  even when a smaller absolute number of instances are generated __label__MISC
this program has been extended from frequency-based judgments to  evaluative judgments of such targets as public transportation  CITATION   luxury automobiles  CITATION   and one's own childhood  CITATION __label__MISC
for instance  winkielman and schwarz  CITATION  asked participants to recall either  NUMBER  childhood events an easy task or  NUMBER  childhood events a difficult task __label__MISC
some participants were then led to believe that memories from pleasant periods tend to fade  while others were led to believe that memories from unpleasant periods tend to fade __label__MISC
when later asked to evaluate their childhood  participants believed that pleasant memories fade rated their childhood more favorably when they completed the difficult task  NUMBER  events than the easy task  NUMBER  events  participants who believed that unpleasant memories fade rated their childhood more favorably when they completed the easy rather than difficult task __label__MISC
previous studies of the availability heuristic using the paradigm of schwarz et al CITATION  have turned up impressive and robust results __label__MISC
however  these demonstrations have been restricted primarily to laboratory surveys in which task of recalling examples then making an overall assessment may seem somewhat artificial to participants and the responses of little consequence __label__MISC
hence  ratings of respondents may be especially susceptible to superficial cues-such as the accessibility of instances-when mapping their beliefs and attitudes onto an unfamiliar response scale __label__MISC
the present investigation overcomes these limitations through a  field study  of students evaluating a course __label__OWNX
first  evaluations are a normal facet of most university courses in which students are commonly asked to list specific suggestions and also provide a global assessment __label__MISC
moreover  course evaluations are consequential  as they can influence future course offerings and course staffing  promotion and tenure decisions  and provide information to future prospective students of the target course __label__MISC
second  students at universities quickly become familiar with standard course evaluation scales and how ratings are distributed across classes  often relying on these scores in choosing among elective courses __label__MISC
the study of course evaluations is also interesting in its own right __label__MISC
a number of recent papers have questioned the validity of these ratings  and a lively debate appeared some years ago in the american psychologist  CITATION __label__MISC
thus far  questions of discriminant validity have mainly focused on the correlation between teaching ratings and apparently irrelevant factors such as the students' expected grades or the course workload __label__MISC
to date there have been few published investigations of the relationship between the design of course feedback forms and summary course evaluations __label__MISC
the present study attempts to answer the following provocative question  can one paradoxically obtain higher course ratings by soliciting a greater number of critical comments from students __label__AIMX
this paper extends previous research showing that experienced difficulty of recall can influence evaluative judgments CITATION to a field study of university students rating a course __label__BASE
respondents who had been asked for  NUMBER  critical comments subsequently rated the course more favorably than respondents who had been asked for  NUMBER  critical comments __label__OWNX
an internal analysis suggests that the number of critiques solicited provides a frame against which accessibility of instances is evaluated __label__OWNX
the paper concludes with a discussion of implications of the present results and possible directions for future research __label__OWNX
according to tversky and kahneman's  CITATION  availability heuristic  people sometimes judge the frequency of events in the world by the ease with which examples come to mind __label__MISC
for instance  kahneman and tversky  CITATION  found that most people think the letter r more often appears in english words as the first letter than the third letter  presumably because the first letter provides a better cue for recalling instances of words than does the third letter __label__MISC
in fact  it turns out that r appears more often as the third than first letter in english words __label__MISC
schwarz et al CITATION  observed that the classic studies demonstrating the availability heuristic failed to distinguish an interpretation based on ease of retrieval from an alternative interpretation based on content of retrieval in which an event is judged more common when a larger number of examples come to mind __label__MISC
to tease apart these accounts  schwarz et al CITATION  asked participants in one   study to list either  NUMBER  or  NUMBER  examples of assertive or unassertive behavior that they have exhibited and then rate themselves on their overall degree of assertiveness __label__MISC
participants rated themselves as more assertive after they had listed  NUMBER  examples of assertive behavior a relatively easy task rather than  NUMBER  examples a relatively difficult task  similarly  they rated themselves as less assertive i e   more unassertive after they had listed  NUMBER  rather than  NUMBER  examples of unassertive behavior __label__MISC
similar patterns of results have been observed in many other studies of frequency-related judgments  including the rate at which a particular letter occurs in various positions of words  CITATION   the quality of one's own memory  CITATION   the frequency of one's own past behaviors  CITATION   one's susceptibility to heart disease  CITATION  and one's susceptibility to sexual assault  CITATION __label__MISC
for a review of this literature see schwarz  CITATION __label__MISC
thus  an abundance of data supports the original interpretation of the availability heuristic  categories are judged to be more common when instances more easily come to mind  even when a smaller absolute number of instances are generated __label__MISC
this program has been extended from frequency-based judgments to  evaluative judgments of such targets as public transportation  CITATION   luxury automobiles  CITATION   and one's own childhood  CITATION __label__MISC
for instance  winkielman and schwarz  CITATION  asked participants to recall either  NUMBER  childhood events an easy task or  NUMBER  childhood events a difficult task __label__MISC
some participants were then led to believe that memories from pleasant periods tend to fade  while others were led to believe that memories from unpleasant periods tend to fade __label__MISC
when later asked to evaluate their childhood  participants believed that pleasant memories fade rated their childhood more favorably when they completed the difficult task  NUMBER  events than the easy task  NUMBER  events  participants who believed that unpleasant memories fade rated their childhood more favorably when they completed the easy rather than difficult task __label__MISC
previous studies of the availability heuristic using the paradigm of schwarz et al CITATION  have turned up impressive and robust results __label__MISC
however  these demonstrations have been restricted primarily to laboratory surveys in which task of recalling examples then making an overall assessment may seem somewhat artificial to participants and the responses of little consequence __label__CONT
more important  most participants in previous studies presumably had little prior experience with the particular likert scale that served as the dependent measure e g   most had never before rated their childhood or public transportation on a  NUMBER -point scale __label__MISC
hence  ratings of respondents may be especially susceptible to superficial cues-such as the accessibility of instances-when mapping their beliefs and attitudes onto an unfamiliar response scale __label__CONT
the present investigation overcomes these limitations through a  field study  of students evaluating a course __label__AIMX
first  evaluations are a normal facet of most university courses in which students are commonly asked to list specific suggestions and also provide a global assessment __label__OWNX
moreover  course evaluations are consequential  as they can influence future course offerings and course staffing  promotion and tenure decisions  and provide information to future prospective students of the target course __label__OWNX
second  students at universities quickly become familiar with standard course evaluation scales and how ratings are distributed across classes  often relying on these scores in choosing among elective courses __label__OWNX
the study of course evaluations is also interesting in its own right __label__OWNX
a number of recent papers have questioned the validity of these ratings  and a lively debate appeared some years ago in the american psychologist  CITATION __label__OWNX
thus far  questions of discriminant validity have mainly focused on the correlation between teaching ratings and apparently irrelevant factors such as the students' expected grades or the course workload __label__OWNX
to date there have been few published investigations of the relationship between the design of course feedback forms and summary course evaluations __label__MISC
the present study attempts to answer the following provocative question  can one paradoxically obtain higher course ratings by soliciting a greater number of critical comments from students __label__OWNX
this paper extends previous research showing that experienced difficulty of recall can influence evaluative judgments CITATION to a field study of university students rating a course __label__AIMX
students completed a mid-course evaluation form in which they were asked to list either  NUMBER  ways in which the course could be improved a relatively easy task or  NUMBER  ways in which the course could be improved a relatively difficult task __label__OWNX
respondents who had been asked for  NUMBER  critical comments subsequently rated the course more favorably than respondents who had been asked for  NUMBER  critical comments __label__OWNX
an internal analysis suggests that the number of critiques solicited provides a frame against which accessibility of instances is evaluated __label__OWNX
the paper concludes with a discussion of implications of the present results and possible directions for future research __label__OWNX
according to tversky and kahneman's  CITATION  availability heuristic  people sometimes judge the frequency of events in the world by the ease with which examples come to mind __label__MISC
for instance  kahneman and tversky  CITATION  found that most people think the letter r more often appears in english words as the first letter than the third letter  presumably because the first letter provides a better cue for recalling instances of words than does the third letter __label__MISC
in fact  it turns out that r appears more often as the third than first letter in english words __label__MISC
schwarz et al CITATION  observed that the classic studies demonstrating the availability heuristic failed to distinguish an interpretation based on ease of retrieval from an alternative interpretation based on content of retrieval in which an event is judged more common when a larger number of examples come to mind __label__MISC
to tease apart these accounts  schwarz et al CITATION  asked participants in one   study to list either  NUMBER  or  NUMBER  examples of assertive or unassertive behavior that they have exhibited and then rate themselves on their overall degree of assertiveness __label__MISC
similar patterns of results have been observed in many other studies of frequency-related judgments  including the rate at which a particular letter occurs in various positions of words  CITATION   the quality of one's own memory  CITATION   the frequency of one's own past behaviors  CITATION   one's susceptibility to heart disease  CITATION  and one's susceptibility to sexual assault  CITATION __label__MISC
thus  an abundance of data supports the original interpretation of the availability heuristic  categories are judged to be more common when instances more easily come to mind  even when a smaller absolute number of instances are generated __label__MISC
this program has been extended from frequency-based judgments to  evaluative judgments of such targets as public transportation  CITATION   luxury automobiles  CITATION   and one's own childhood  CITATION __label__MISC
for instance  winkielman and schwarz  CITATION  asked participants to recall either  NUMBER  childhood events an easy task or  NUMBER  childhood events a difficult task __label__MISC
some participants were then led to believe that memories from pleasant periods tend to fade  while others were led to believe that memories from unpleasant periods tend to fade __label__MISC
when later asked to evaluate their childhood  participants believed that pleasant memories fade rated their childhood more favorably when they completed the difficult task  NUMBER  events than the easy task  NUMBER  events  participants who believed that unpleasant memories fade rated their childhood more favorably when they completed the easy rather than difficult task __label__MISC
previous studies of the availability heuristic using the paradigm of schwarz et al CITATION  have turned up impressive and robust results __label__MISC
hence  ratings of respondents may be especially susceptible to superficial cues-such as the accessibility of instances-when mapping their beliefs and attitudes onto an unfamiliar response scale __label__MISC
first  evaluations are a normal facet of most university courses in which students are commonly asked to list specific suggestions and also provide a global assessment __label__MISC
moreover  course evaluations are consequential  as they can influence future course offerings and course staffing  promotion and tenure decisions  and provide information to future prospective students of the target course __label__MISC
second  students at universities quickly become familiar with standard course evaluation scales and how ratings are distributed across classes  often relying on these scores in choosing among elective courses __label__MISC
the study of course evaluations is also interesting in its own right __label__MISC
a number of recent papers have questioned the validity of these ratings  and a lively debate appeared some years ago in the american psychologist  CITATION __label__MISC
to date there have been few published investigations of the relationship between the design of course feedback forms and summary course evaluations __label__MISC
the present study attempts to answer the following provocative question  can one paradoxically obtain higher course ratings by soliciting a greater number of critical comments from students __label__AIMX
feelings of anger in response to norm violations are assumed to motivate third-party sanctions, yet there is only sparse and indirect support for this idea __label__MISC
we investigated the impact of both anger and guilt feelings on third-party sanctions __label__AIMX
in two studies both emotions were independently manipulated __label__OWNX
results show that anger and guilt independently constitute sufficient but not necessary causes of punishment __label__OWNX
low levels of punishment are observed only when neither emotion is elicited __label__OWNX
they stand up for their friends if someone speaks ill about them in their absence __label__MISC
they do not tolerate a colleague being bullied at work __label__MISC
they boycott consumer products that are produced using child labor __label__MISC
some even come to the aid of a stranger who is being physically harassed, in spite of obvious personal danger __label__MISC
however, punishing norm-violations is costly in terms of time and energy __label__MISC
it may even impose physical risks __label__MISC
punishing injustice is therefore considered to be a moral act, particularly when it is performed on behalf of others  CITATION __label__MISC
this begs the question of what incites third-party sanctions, as they usually oppose self-interest __label__AIMX
feelings of anger in response to norm violations are assumed to motivate third-party sanctions, yet there is only sparse and indirect support for this idea __label__CONT
we investigated the impact of both anger and guilt feelings on third-party sanctions __label__OWNX
in two studies both emotions were independently manipulated __label__OWNX
results show that anger and guilt independently constitute sufficient but not necessary causes of punishment __label__OWNX
we discuss the implications of these findings for the functions of altruistic sanctions __label__AIMX
people often defend the interests of others __label__MISC
they stand up for their friends if someone speaks ill about them in their absence __label__MISC
they do not tolerate a colleague being bullied at work __label__MISC
they boycott consumer products that are produced using child labor __label__MISC
however, punishing norm-violations is costly in terms of time and energy __label__MISC
it may even impose physical risks __label__MISC
punishing injustice is therefore considered to be a moral act, particularly when it is performed on behalf of others  CITATION __label__MISC
this begs the question of what incites third-party sanctions, as they usually oppose self-interest __label__AIMX
third-party punishment has recently received attention as an explanation for human altruism __label__MISC
feelings of anger in response to norm violations are assumed to motivate third-party sanctions, yet there is only sparse and indirect support for this idea __label__CONT
we investigated the impact of both anger and guilt feelings on third-party sanctions __label__AIMX
in two studies both emotions were independently manipulated __label__OWNX
results show that anger and guilt independently constitute sufficient but not necessary causes of punishment __label__OWNX
we discuss the implications of these findings for the functions of altruistic sanctions __label__OWNX
people often defend the interests of others __label__MISC
they stand up for their friends if someone speaks ill about them in their absence __label__MISC
they do not tolerate a colleague being bullied at work __label__MISC
they boycott consumer products that are produced using child labor __label__MISC
some even come to the aid of a stranger who is being physically harassed, in spite of obvious personal danger __label__MISC
in general, people retaliate against injustice even if they are not directly victimized __label__MISC
sanctioning of norm-violations is vital for prosocial behavior to be sustained  CITATION __label__MISC
this begs the question of what incites third-party sanctions, as they usually oppose self-interest __label__MISC
participants initially showed robust sces, but they also showed a significant reduction in bias after only one round of feedback __label__OWNX
when resources are at a premium, it is optimal to enter into competitive environments in which we are certain to fare well and to avoid those in which we are doomed to fail __label__MISC
however, when people evaluate their likelihood of success in competitions, they are subject to a robust bias: a competitor should consider the strengths and weaknesses of the self and the other competitors  CITATION , but people often give too much weight to evidence related to their own strengths and weaknesses and too little weight to such evidence about the competitor  CITATION __label__MISC
this egocentrism results in overoptimism when the circumstances of the competition are favorable, such as when competitors in a trivia game learn that the questions will be from an easy category-even though they'll be easy for everyone  CITATION __label__MISC
egocentrism also results in overpessimism when the circumstances are unfavorable e g , a difficult trivia category __label__MISC
this phenomenon of being more optimistic when shared competitive circumstances are favorable than when they are not has been dubbed the shared-circumstance effect  CITATION , and it has been replicated across a variety of settings e g , general knowledge tasks, card games, athletic competitions __label__MISC
in most previous studies on the sce, participants were presented with novel, non-repeated competitive situations __label__MISC
for example, when a tennis tournament is played during a string of windy days, players can have several opportunities to observe how the weather affects themselves and their competitors __label__MISC
to examine whether egocentrism and sces persist in repeated-play contexts, rose and windschitl  CITATION  had pairs of participants compete against each other in multiple rounds of a trivia contest that involved easy and hard categories __label__MISC
in each round, participants estimated their likelihood of beating their competitor, answered trivia questions, and received feedback about who won __label__MISC
in initial rounds, there were robust sces; participants were much more optimistic about winning easy categories than hard ones __label__MISC
if they encountered the same hard and easy categories across rounds, the participants learned from feedback __label__MISC
that is, the sce shrank-but slowly-across six rounds with the same categories __label__MISC
the sce for that round dramatically and fully rebounded; it was every bit as large as observed for round 1 __label__MISC
these results provide a bleak view of how well people can learn from feedback and avoid sces __label__MISC
CITATION are people's abilities to learn to avoid sces-based on feedback-really as bleak as this prior research might suggest __label__MISC
we argue that some shared circumstances are more transparently shared than others, and this may affect how readily people learn to avoid the bias that creates sces-and how easily they can transfer this learning to a slightly new set of shared circumstances __label__AIMX
by transparently shared, we are referring to how obvious it is that a circumstance that is helpful or hindering to the self will affect others in largely the same way __label__OWNX
in the present study, we examined the influence of repeated feedback on sces __label__OWNX
however, unlike past research, we used a competition in which the difficulty of the shared circumstance relative to competitions, for example, involving easy and hard trivia categories is more transparently shared __label__CONT
in a multi-round paradigm, participants competed in object-tossing competitions __label__OWNX
in each round, two competitors each had 8 throws per object-attempting to land the object inside a target area __label__OWNX
there was always one easy-to-aim object e g , a beanbag and one hard-to-aim object e g , a paper plate, which constituted our shared-circumstance manipulation __label__OWNX
full feedback was given during and after each round, and predictions were solicited before each round and also before a final round with novel objects __label__OWNX
we suspected that a tossing competition, rather than a trivia competition, would produce less bleak results about the debiasing of sces through repeated play __label__OWNX
in the case of trivia, watching one's competitor fail to answer trivia questions doesn't give any insight about why the category is difficult for that person __label__MISC
also, knowing that one's competitor struggled on a difficult category does not provide obvious information about why he or she might struggle on another difficult category __label__MISC
however, in the case of throwing, watching a competitor fail when tossing an object probably illuminates the relevance of specific shared, situational circumstances i e , the properties of the specific objects as well as a more general awareness of the relevance that object properties have on throwing success-for anyone __label__MISC
for example, seeing a paper plate fly unpredictably will likely give an observer a clear impression that the object will fly unpredictably regardless of who is throwing it __label__MISC
for participants, this enhances the appreciation that one's struggles are not primarily due to personal characteristics but to properties of the tossed objects; this would then be useful in mitigating egocentrism and sces, even when new objects are introduced __label__MISC
consequently, we expected that, even though participants might reveal a robust sce at round 1 prior to any feedback or observations regarding their competitor, they would show a pronounced learning effect after the feedback and observations of round 1 __label__OWNX
that is, they would show significantly reduced sces starting immediately after round 1 __label__OWNX
when judging their likelihood of success in competitive tasks, people tend to be overoptimistic for easy tasks and overpessimistic for hard tasks the shared circumstance effect; sce __label__MISC
previous research has shown that feedback and experience from repeated-play competitions has a limited impact on sces __label__MISC
pairs of participants competed in, made predictions about, and received feedback on, multiple rounds of a throwing task involving both easy- and hard-to-aim objects __label__OWNX
participants initially showed robust sces, but they also showed a significant reduction in bias after only one round of feedback __label__OWNX
these and other results support a more positive view than suggested from past research on the potential for sces to be debiased through outcome feedback __label__OWNX
competition abounds in everyday life, where we contend with others for top grades, jobs, trophies, and mates __label__MISC
this egocentrism results in overoptimism when the circumstances of the competition are favorable, such as when competitors in a trivia game learn that the questions will be from an easy category-even though they'll be easy for everyone  CITATION __label__MISC
egocentrism also results in overpessimism when the circumstances are unfavorable e g , a difficult trivia category __label__MISC
this phenomenon of being more optimistic when shared competitive circumstances are favorable than when they are not has been dubbed the shared-circumstance effect  CITATION , and it has been replicated across a variety of settings e g , general knowledge tasks, card games, athletic competitions __label__MISC
in most previous studies on the sce, participants were presented with novel, non-repeated competitive situations __label__MISC
these situations did not allow people to learn from past experiences or from feedback within the immediate competitive context __label__MISC
for example, when a tennis tournament is played during a string of windy days, players can have several opportunities to observe how the weather affects themselves and their competitors __label__MISC
to examine whether egocentrism and sces persist in repeated-play contexts, rose and windschitl  CITATION  had pairs of participants compete against each other in multiple rounds of a trivia contest that involved easy and hard categories __label__MISC
in each round, participants estimated their likelihood of beating their competitor, answered trivia questions, and received feedback about who won __label__MISC
in initial rounds, there were robust sces; participants were much more optimistic about winning easy categories than hard ones __label__MISC
if they encountered the same hard and easy categories across rounds, the participants learned from feedback __label__MISC
that is, the sce shrank-but slowly-across six rounds with the same categories __label__MISC
the sce was never eliminated, even after six rounds __label__MISC
also, for a seventh round, participants were told there would be new categories __label__MISC
the sce for that round dramatically and fully rebounded; it was every bit as large as observed for round 1 __label__MISC
these results provide a bleak view of how well people can learn from feedback and avoid sces __label__MISC
moreover, results from a study by moore and cain  CITATION , which also used repeated plays with feedback, suggest an even bleaker view __label__MISC
those researchers also used easy and difficult quizzes as shared-circumstance manipulations, but found virtually no reduction in sces after numerous rounds with feedback __label__MISC
CITATION are people's abilities to learn to avoid sces-based on feedback-really as bleak as this prior research might suggest __label__MISC
we argue that some shared circumstances are more transparently shared than others, and this may affect how readily people learn to avoid the bias that creates sces-and how easily they can transfer this learning to a slightly new set of shared circumstances __label__AIMX
by transparently shared, we are referring to how obvious it is that a circumstance that is helpful or hindering to the self will affect others in largely the same way __label__OWNX
in the present study, we examined the influence of repeated feedback on sces __label__OWNX
however, unlike past research, we used a competition in which the difficulty of the shared circumstance relative to competitions, for example, involving easy and hard trivia categories is more transparently shared __label__OWNX
in a multi-round paradigm, participants competed in object-tossing competitions __label__OWNX
in each round, two competitors each had 8 throws per object-attempting to land the object inside a target area __label__OWNX
there was always one easy-to-aim object e g , a beanbag and one hard-to-aim object e g , a paper plate, which constituted our shared-circumstance manipulation __label__OWNX
full feedback was given during and after each round, and predictions were solicited before each round and also before a final round with novel objects __label__OWNX
we suspected that a tossing competition, rather than a trivia competition, would produce less bleak results about the debiasing of sces through repeated play __label__OWNX
in the case of trivia, watching one's competitor fail to answer trivia questions doesn't give any insight about why the category is difficult for that person __label__OWNX
however, in the case of throwing, watching a competitor fail when tossing an object probably illuminates the relevance of specific shared, situational circumstances i e , the properties of the specific objects as well as a more general awareness of the relevance that object properties have on throwing success-for anyone __label__OWNX
for example, seeing a paper plate fly unpredictably will likely give an observer a clear impression that the object will fly unpredictably regardless of who is throwing it __label__OWNX
for participants, this enhances the appreciation that one's struggles are not primarily due to personal characteristics but to properties of the tossed objects; this would then be useful in mitigating egocentrism and sces, even when new objects are introduced __label__OWNX
consequently, we expected that, even though participants might reveal a robust sce at round 1 prior to any feedback or observations regarding their competitor, they would show a pronounced learning effect after the feedback and observations of round 1 __label__OWNX
that is, they would show significantly reduced sces starting immediately after round 1 __label__OWNX
we also expected that this learning would be generally transferable __label__OWNX
when judging their likelihood of success in competitive tasks, people tend to be overoptimistic for easy tasks and overpessimistic for hard tasks the shared circumstance effect; sce __label__MISC
previous research has shown that feedback and experience from repeated-play competitions has a limited impact on sces __label__MISC
however, in this paper, we suggest that competitive situations, in which the shared difficulty or easiness of the task is more transparent, will be more amenable to debiasing via repeated play __label__AIMX
pairs of participants competed in, made predictions about, and received feedback on, multiple rounds of a throwing task involving both easy- and hard-to-aim objects __label__OWNX
participants initially showed robust sces, but they also showed a significant reduction in bias after only one round of feedback __label__OWNX
these and other results support a more positive view than suggested from past research on the potential for sces to be debiased through outcome feedback __label__OWNX
competition abounds in everyday life, where we contend with others for top grades, jobs, trophies, and mates __label__MISC
when resources are at a premium, it is optimal to enter into competitive environments in which we are certain to fare well and to avoid those in which we are doomed to fail __label__MISC
this egocentrism results in overoptimism when the circumstances of the competition are favorable, such as when competitors in a trivia game learn that the questions will be from an easy category-even though they'll be easy for everyone  CITATION __label__MISC
egocentrism also results in overpessimism when the circumstances are unfavorable e g , a difficult trivia category __label__MISC
in most previous studies on the sce, participants were presented with novel, non-repeated competitive situations __label__MISC
these situations did not allow people to learn from past experiences or from feedback within the immediate competitive context __label__MISC
however, in everyday contexts there are often opportunities to learn how a shared circumstance tends to affect the self, others, and outcomes __label__MISC
for example, when a tennis tournament is played during a string of windy days, players can have several opportunities to observe how the weather affects themselves and their competitors __label__MISC
to examine whether egocentrism and sces persist in repeated-play contexts, rose and windschitl  CITATION  had pairs of participants compete against each other in multiple rounds of a trivia contest that involved easy and hard categories __label__MISC
in each round, participants estimated their likelihood of beating their competitor, answered trivia questions, and received feedback about who won __label__MISC
in initial rounds, there were robust sces; participants were much more optimistic about winning easy categories than hard ones __label__MISC
if they encountered the same hard and easy categories across rounds, the participants learned from feedback __label__MISC
that is, the sce shrank-but slowly-across six rounds with the same categories __label__MISC
the sce was never eliminated, even after six rounds __label__MISC
also, for a seventh round, participants were told there would be new categories __label__MISC
the sce for that round dramatically and fully rebounded; it was every bit as large as observed for round 1 __label__MISC
these results provide a bleak view of how well people can learn from feedback and avoid sces __label__MISC
moreover, results from a study by moore and cain  CITATION , which also used repeated plays with feedback, suggest an even bleaker view __label__MISC
those researchers also used easy and difficult quizzes as shared-circumstance manipulations, but found virtually no reduction in sces after numerous rounds with feedback CITATION __label__MISC
are people's abilities to learn to avoid sces-based on feedback-really as bleak as this prior research might suggest __label__MISC
we argue that some shared circumstances are more transparently shared than others, and this may affect how readily people learn to avoid the bias that creates sces-and how easily they can transfer this learning to a slightly new set of shared circumstances __label__AIMX
by transparently shared, we are referring to how obvious it is that a circumstance that is helpful or hindering to the self will affect others in largely the same way __label__OWNX
in the present study, we examined the influence of repeated feedback on sces __label__AIMX
in a multi-round paradigm, participants competed in object-tossing competitions __label__OWNX
in each round, two competitors each had 8 throws per object-attempting to land the object inside a target area __label__OWNX
there was always one easy-to-aim object e g , a beanbag and one hard-to-aim object e g , a paper plate, which constituted our shared-circumstance manipulation __label__OWNX
full feedback was given during and after each round, and predictions were solicited before each round and also before a final round with novel objects __label__OWNX
we suspected that a tossing competition, rather than a trivia competition, would produce less bleak results about the debiasing of sces through repeated play __label__OWNX
also, knowing that one's competitor struggled on a difficult category does not provide obvious information about why he or she might struggle on another difficult category __label__MISC
however, in the case of throwing, watching a competitor fail when tossing an object probably illuminates the relevance of specific shared, situational circumstances i e , the properties of the specific objects as well as a more general awareness of the relevance that object properties have on throwing success-for anyone __label__MISC
for example, seeing a paper plate fly unpredictably will likely give an observer a clear impression that the object will fly unpredictably regardless of who is throwing it __label__MISC
that is, they would show significantly reduced sces starting immediately after round 1 __label__OWNX
we also expected that this learning would be generally transferable __label__OWNX
previous research on anchoring has shown this heuristic to be a very robust psychological phenomenon ubiquitous across many domains of human judgment and decision-making __label__MISC
despite the prevalence of anchoring effects  researchers have only recently begun to investigate the underlying factors responsible for how and in what ways a person is susceptible to them __label__CONT
this paper examines how one such factor  the big-five personality trait of openness-to-experience  influences the effect of previously presented anchors on participants' judgments __label__AIMX
our findings indicate that participants high in openness-to-experience were significantly more influenced by anchoring cues relative to participants low in this trait __label__OWNX
the anchoring effect  CITATION  refers to the adjustment of one's assessment  higher or lower  based upon previously presented external information or an  anchor __label__MISC
the anchoring heuristic appears to be prevalent throughout human decision processes and has been shown to reliably influence judgments in a variety of domains including probability estimates  CITATION   negotiation  CITATION   legal judgments  CITATION   and general knowledge  CITATION __label__MISC
further  anchoring effects appear viable across most situations for both novices and experts  CITATION  and seem to be effective under conditions of monetary incentives  CITATION  and in real-world settings  CITATION __label__MISC
anchoring thus appears to be a very robust psychological phenomenon __label__MISC
however  not all individuals may be equally influenced by anchoring cues __label__MISC
tversky and kahneman  CITATION  pointed to the important role of  personal characteristics  of the decision maker in risky choice situations __label__MISC
later work by stanovich and west  CITATION  suggested that intellectual traits influence decision making and consequential choice preference __label__MISC
recently  individual differences have been found in numerical reliance  CITATION   ambiguity  CITATION   preference for actions or inactions  CITATION  and the optimistic bias  CITATION __label__MISC
the big-five personality traits  CITATION  have proven to be important individual difference factors for understanding decision choices __label__MISC
further  attesting to the importance of individual differences  levin and hart  CITATION  demonstrated that individual differences in preference appear to originate at a very early age __label__MISC
taken together  these findings suggest that the impact of individual difference factors on decision-making is both profound and pervasive __label__MISC
in the last couple of decades the five-factor model of personality has become the most widely tested and well-regarded personality trait model __label__MISC
a great deal of research has supported this model's validity and reliability  CITATION __label__MISC
while most research has agreed on the nature of the first four factors  the nature of the fifth factor has been controversial  a controversy predominately based upon whether a lexical approach  derived from language frequency within the lexicon of a particular language  CITATION   or a questionnaire approach  CITATION  should be used to measure it __label__CONT
individuals scoring high on this dimension are more open to new ideas  CITATION  and motivated to seek variety and external experience __label__MISC
individuals scoring low tend to be less inclined to consider alternative opinions and are more steadfast in their own beliefs  CITATION  making them more likely to rely upon information that is familiar and conventional  CITATION __label__MISC
a fundamental aspect of the anchoring effect is that individuals are sensitive to information which they have experienced __label__MISC
specifically  as research has shown  the openness trait reflects individual propensities to  adjust  one's beliefs  CITATION  and to consider external information  CITATION __label__MISC
therefore  based upon the nature of the openness-to-experience trait and the processes involved in the anchoring effect  we hypothesize that individual differences in openness-to-experience will influence susceptibility to anchoring effects __label__OWNX
to test this hypothesis  we first measured individual levels of the personality trait of openness-to-experience __label__OWNX
we then provided participants with an anchoring task involving either the mississippi river study  NUMBER  or african nations in the un study  NUMBER __label__OWNX
previous research on anchoring has shown this heuristic to be a very robust psychological phenomenon ubiquitous across many domains of human judgment and decision-making. __label__MISC
despite the prevalence of anchoring effects  researchers have only recently begun to investigate the underlying factors responsible for how and in what ways a person is susceptible to them. __label__MISC
this paper examines how one such factor  the big-five personality trait of openness-to-experience  influences the effect of previously presented anchors on participants' judgments. __label__AIMX
our findings indicate that participants high in openness-to-experience were significantly more influenced by anchoring cues relative to participants low in this trait. __label__OWNX
these findings were consistent across two different types of anchoring tasks providing convergent evidence for our hypothesis __label__OWNX
the anchoring effect  CITATION  refers to the adjustment of one's assessment  higher or lower  based upon previously presented external information or an  anchor. __label__MISC
the anchoring heuristic appears to be prevalent throughout human decision processes and has been shown to reliably influence judgments in a variety of domains including probability estimates  CITATION   negotiation  CITATION   legal judgments  CITATION   and general knowledge  CITATION. __label__MISC
further  anchoring effects appear viable across most situations for both novices and experts  CITATION  and seem to be effective under conditions of monetary incentives  CITATION  and in real-world settings  CITATION. __label__MISC
anchoring thus appears to be a very robust psychological phenomenon. __label__MISC
however  not all individuals may be equally influenced by anchoring cues. __label__MISC
identification of factors that influence how and in what ways a person is susceptible to this heuristic should further the understanding of the process. __label__MISC
one avenue of approach is to investigate the role of individual difference factors. __label__MISC
tversky and kahneman  CITATION  pointed to the important role of  personal characteristics  of the decision maker in risky choice situations. __label__MISC
later work by stanovich and west  CITATION  suggested that intellectual traits influence decision making and consequential choice preference. __label__MISC
recently  individual differences have been found in numerical reliance  CITATION   ambiguity  CITATION   preference for actions or inactions  CITATION  and the optimistic bias  CITATION. __label__MISC
the big-five personality traits  CITATION  have proven to be important individual difference factors for understanding decision choices. __label__MISC
further  attesting to the importance of individual differences  levin and hart  CITATION  demonstrated that individual differences in preference appear to originate at a very early age. __label__MISC
the purpose of the current study is to investigate how one individual difference factor may influence the strength of the anchoring effect. __label__AIMX
specifically  we are interested in how individual differences in the personality trait of openness-to-experience influences anchoring effects. __label__AIMX
in the last couple of decades the five-factor model of personality has become the most widely tested and well-regarded personality trait model. __label__MISC
while most research has agreed on the nature of the first four factors  the nature of the fifth factor has been controversial; a controversy predominately based upon whether a lexical approach  derived from language frequency within the lexicon of a particular language  CITATION   or a questionnaire approach  CITATION  should be used to measure it. __label__MISC
the fifth factor is often labeled openness-to-experience  which refers to a propensity to adjust beliefs and behaviors when exposed to new types of information or ideas  CITATION. __label__MISC
individuals scoring high on this dimension are more open to new ideas  CITATION  and motivated to seek variety and external experience. __label__MISC
individuals scoring low tend to be less inclined to consider alternative opinions and are more steadfast in their own beliefs  CITATION  making them more likely to rely upon information that is familiar and conventional  CITATION. __label__MISC
a fundamental aspect of the anchoring effect is that individuals are sensitive to information which they have experienced. __label__MISC
this change in judgment  which is based upon external cues  seems particularly relevant and related to the openness-to-experience personality trait. __label__MISC
specifically  as research has shown  the openness trait reflects individual propensities to  adjust  one's beliefs  CITATION  and to consider external information  CITATION. __label__MISC
therefore  based upon the nature of the openness-to-experience trait and the processes involved in the anchoring effect we hypothesize that individual differences in openness-to-experience will influence susceptibility to anchoring effects. __label__AIMX
specifically  we hypothesize that the judgments of those individuals high in this trait will be more influenced by previously presented anchors whereas those individuals low in this trait will be less influenced by the anchor. __label__AIMX
to test this hypothesis  we first measured individual levels of the personality trait of openness-to-experience. __label__OWNX
we then provided participants with an anchoring task involving either the mississippi river study  NUMBER  or african nations in the un study  NUMBER __label__OWNX
despite the prevalence of anchoring effects  researchers have only recently begun to investigate the underlying factors responsible for how and in what ways a person is susceptible to them __label__MISC
this paper examines how one such factor  the big-five personality trait of openness-to-experience  influences the effect of previously presented anchors on participants' judgments __label__AIMX
our findings indicate that participants high in openness-to-experience were significantly more influenced by anchoring cues relative to participants low in this trait __label__OWNX
these findings were consistent across two different types of anchoring tasks providing convergent evidence for our hypothesis __label__OWNX
the anchoring effect  CITATION  refers to the adjustment of one's assessment  higher or lower  based upon previously presented external information or an  anchor __label__MISC
the anchoring heuristic appears to be prevalent throughout human decision processes and has been shown to reliably influence judgments in a variety of domains including probability estimates  CITATION   negotiation  CITATION   legal judgments  CITATION   and general knowledge  CITATION __label__MISC
further  anchoring effects appear viable across most situations for both novices and experts  CITATION  and seem to be effective under conditions of monetary incentives  CITATION  and in real-world settings  CITATION __label__MISC
anchoring thus appears to be a very robust psychological phenomenon __label__MISC
however  not all individuals may be equally influenced by anchoring cues __label__MISC
identification of factors that influence how and in what ways a person is susceptible to this heuristic should further the understanding of the process __label__MISC
later work by stanovich and west  CITATION  suggested that intellectual traits influence decision making and consequential choice preference __label__MISC
recently  individual differences have been found in numerical reliance  CITATION   ambiguity  CITATION   preference for actions or inactions  CITATION  and the optimistic bias  CITATION __label__MISC
the big-five personality traits  CITATION  have proven to be important individual difference factors for understanding decision choices __label__MISC
taken together  these findings suggest that the impact of individual difference factors on decision-making is both profound and pervasive __label__MISC
the purpose of the current study is to investigate how one individual difference factor may influence the strength of the anchoring effect __label__AIMX
in the last couple of decades the five-factor model of personality has become the most widely tested and well-regarded personality trait model __label__MISC
a great deal of research has supported this model's validity and reliability  CITATION __label__MISC
while most research has agreed on the nature of the first four factors  the nature of the fifth factor has been controversial  a controversy predominately based upon whether a lexical approach  derived from language frequency within the lexicon of a particular language  CITATION   or a questionnaire approach  CITATION  should be used to measure it __label__MISC
individuals scoring high on this dimension are more open to new ideas  CITATION  and motivated to seek variety and external experience __label__MISC
individuals scoring low tend to be less inclined to consider alternative opinions and are more steadfast in their own beliefs  CITATION  making them more likely to rely upon information that is familiar and conventional  CITATION __label__MISC
this change in judgment  which is based upon external cues  seems particularly relevant and related to the openness-to-experience personality trait __label__MISC
therefore  based upon the nature of the openness-to-experience trait and the processes involved in the anchoring effect  we hypothesize that individual differences in openness-to-experience will influence susceptibility to anchoring effects __label__OWNX
to test this hypothesis  we first measured individual levels of the personality trait of openness-to-experience __label__OWNX
we then provided participants with an anchoring task involving either the mississippi river study  NUMBER  or african nations in the un study  NUMBER __label__OWNX
Expansion of polyglutamine tracts in proteins results in protein aggregation and is associated with cell death in at least nine neurodegenerative diseases. __label__MISC
Disease age of onset is correlated with the polyQ insert length above a critical value of 35 40 glutamines. __label__MISC
The aggregation kinetics of isolated polyQ peptides in vitro also shows a similar critical-length dependence. __label__MISC
Here, using computer simulations of isolated polyQ peptides, we show that a mechanism of aggregation is the conformational transition in a single polyQ peptide chain from random coil to a parallel -helix. __label__AIMX
This transition occurs selectively in peptides longer than 37 glutamines. __label__MISC
In the -helices observed in simulations, all residues adopt -strand backbone dihedral angles, and the polypeptide chain coils around a central helical axis with 18.5 2 residues per turn. __label__OWNX
We also find that mutant polyQ peptides with proline-glycine inserts show formation of antiparallel -hairpins in their ground state, in agreement with experiments. __label__OWNX
The lower stability of mutant -helices explains their lower aggregation rates compared to wild type. __label__OWNX
Our results provide a molecular mechanism for polyQ-mediated aggregation. __label__OWNX
Intranuclear inclusion bodies containing polyQ aggregates have been found in vitro CITATION, CITATION, in cell cultures, animal models, and affected patients CITATION, CITATION. __label__MISC
The aggregates are known to have a characteristic amyloid topology CITATION. __label__MISC
The inhibition of oligomerization by the azo-dye Congo red, or by the Hsp70/Hsp40 chaperone system, exerts marked protective effects in vivo and in vitro CITATION, CITATION. __label__MISC
Aggregation and disease are observed if the number of glutamines in the expansion, n, exceeds a critical value, n C CITATION. __label__MISC
The nearly universal existence of this criticality in all polyQ-related diseases suggests that when the polyQ insert length exceeds a critical value, a pathological change, largely independent of the host protein, occurs in the polyQ insert itself. __label__MISC
Therefore, isolated polyQ peptides have been used as model systems for studying polyQ aggregation CITATION, CITATION, CITATION, and it is known that: The nuclear uptake of polyQ peptide aggregates prepared in vitro is cytotoxic in cell cultures CITATION, isolated polyQ peptides have in vitro aggregation properties similar to the corresponding full-length proteins containing the polyQ insert CITATION, CITATION, peptide aggregation follows a nucleated mechanism showing characteristic lag and growth phases CITATION, CITATION, and the glutamine tract-length dependence of the lag-time interval correlates well with the age of onset of disease CITATION. __label__MISC
Longer peptides have progressively smaller lag times of aggregation, and a correspondingly early age of onset of the disease CITATION . __label__MISC
Unaggregated polyQ peptides form random coil structures, whereas aggregates are composed of amyloid-like -strands CITATION. __label__MISC
The conversion of random coil to -strand occurs in an individual polyQ chain CITATION, and fibril formation occurs by addition of other polyQ chains to these monomeric -strand nuclei. __label__MISC
Therefore, the conformational dynamics of an individual polyQ chain determines both its aggregation mechanism and the structure of the final aggregates. __label__MISC
Expansion of polyglutamine tracts in proteins results in protein aggregation and is associated with cell death in at least nine neurodegenerative diseases. __label__MISC
The aggregation kinetics of isolated polyQ peptides in vitro also shows a similar critical-length dependence. __label__MISC
While recent experimental work has provided considerable insights into polyQ aggregation, the molecular mechanism of aggregation is not well understood. __label__MISC
This transition occurs selectively in peptides longer than 37 glutamines. __label__OWNX
In the -helices observed in simulations, all residues adopt -strand backbone dihedral angles, and the polypeptide chain coils around a central helical axis with 18.5 2 residues per turn. __label__OWNX
We also find that mutant polyQ peptides with proline-glycine inserts show formation of antiparallel -hairpins in their ground state, in agreement with experiments. __label__OWNX
The lower stability of mutant -helices explains their lower aggregation rates compared to wild type. __label__OWNX
Intranuclear inclusion bodies containing polyQ aggregates have been found in vitro CITATION, CITATION, in cell cultures, animal models, and affected patients CITATION, CITATION. __label__MISC
The aggregates are known to have a characteristic amyloid topology CITATION. __label__MISC
The inhibition of oligomerization by the azo-dye Congo red, or by the Hsp70/Hsp40 chaperone system, exerts marked protective effects in vivo and in vitro CITATION, CITATION. __label__MISC
Aggregation and disease are observed if the number of glutamines in the expansion, n, exceeds a critical value, n C CITATION. __label__MISC
The nearly universal existence of this criticality in all polyQ-related diseases suggests that when the polyQ insert length exceeds a critical value, a pathological change, largely independent of the host protein, occurs in the polyQ insert itself. __label__MISC
Therefore, isolated polyQ peptides have been used as model systems for studying polyQ aggregation CITATION, CITATION, CITATION, and it is known that: The nuclear uptake of polyQ peptide aggregates prepared in vitro is cytotoxic in cell cultures CITATION, isolated polyQ peptides have in vitro aggregation properties similar to the corresponding full-length proteins containing the polyQ insert CITATION, CITATION, peptide aggregation follows a nucleated mechanism showing characteristic lag and growth phases CITATION, CITATION, and the glutamine tract-length dependence of the lag-time interval correlates well with the age of onset of disease CITATION. __label__MISC
Peptides of subcritical lengths have long lag times of aggregation and a corresponding age of onset later than the typical life span of a person. __label__MISC
Longer peptides have progressively smaller lag times of aggregation, and a correspondingly early age of onset of the disease CITATION . __label__MISC
Unaggregated polyQ peptides form random coil structures, whereas aggregates are composed of amyloid-like -strands CITATION. __label__MISC
The conversion of random coil to -strand occurs in an individual polyQ chain CITATION, and fibril formation occurs by addition of other polyQ chains to these monomeric -strand nuclei. __label__MISC
Therefore, the conformational dynamics of an individual polyQ chain determines both its aggregation mechanism and the structure of the final aggregates. __label__MISC
The details of the conformational dynamics of polyQ and the length dependence of the dynamics are not well understood CITATION . __label__MISC
Expansion of polyglutamine tracts in proteins results in protein aggregation and is associated with cell death in at least nine neurodegenerative diseases. __label__MISC
Disease age of onset is correlated with the polyQ insert length above a critical value of 35 40 glutamines. __label__MISC
The aggregation kinetics of isolated polyQ peptides in vitro also shows a similar critical-length dependence. __label__MISC
While recent experimental work has provided considerable insights into polyQ aggregation, the molecular mechanism of aggregation is not well understood. __label__CONT
Here, using computer simulations of isolated polyQ peptides, we show that a mechanism of aggregation is the conformational transition in a single polyQ peptide chain from random coil to a parallel -helix. __label__AIMX
This transition occurs selectively in peptides longer than 37 glutamines. __label__OWNX
In the -helices observed in simulations, all residues adopt -strand backbone dihedral angles, and the polypeptide chain coils around a central helical axis with 18.5 2 residues per turn. __label__OWNX
We also find that mutant polyQ peptides with proline-glycine inserts show formation of antiparallel -hairpins in their ground state, in agreement with experiments. __label__OWNX
The lower stability of mutant -helices explains their lower aggregation rates compared to wild type. __label__OWNX
Our results provide a molecular mechanism for polyQ-mediated aggregation. __label__OWNX
The appearance of polyglutamine -containing aggregates CITATION CITATION is a hallmark of disease progression in all diseases in which CAG-expansions occur in genes CITATION. __label__MISC
Intranuclear inclusion bodies containing polyQ aggregates have been found in vitro CITATION, CITATION, in cell cultures, animal models, and affected patients CITATION, CITATION. __label__MISC
The inhibition of oligomerization by the azo-dye Congo red, or by the Hsp70/Hsp40 chaperone system, exerts marked protective effects in vivo and in vitro CITATION, CITATION. __label__MISC
The nearly universal existence of this criticality in all polyQ-related diseases suggests that when the polyQ insert length exceeds a critical value, a pathological change, largely independent of the host protein, occurs in the polyQ insert itself. __label__MISC
Peptides of subcritical lengths have long lag times of aggregation and a corresponding age of onset later than the typical life span of a person. __label__MISC
Longer peptides have progressively smaller lag times of aggregation, and a correspondingly early age of onset of the disease CITATION . __label__MISC
The conversion of random coil to -strand occurs in an individual polyQ chain CITATION, and fibril formation occurs by addition of other polyQ chains to these monomeric -strand nuclei. __label__MISC
Therefore, the conformational dynamics of an individual polyQ chain determines both its aggregation mechanism and the structure of the final aggregates. __label__MISC
The details of the conformational dynamics of polyQ and the length dependence of the dynamics are not well understood CITATION . __label__CONT
A new theoretical survey of proteins' resistance to constant speed stretching is performed for a set of 17 134 proteins as described by a structure-based model. __label__AIMX
Our previous studies have dealt with 7510 proteins of no more than 150 amino acids. __label__MISC
The proteins are ranked according to the strength of the resistance. __label__MISC
Most of the predicted top-strength proteins have not yet been studied experimentally. __label__MISC
Architectures and folds which are likely to yield large forces are identified. __label__MISC
New types of potent force clamps are discovered. __label__MISC
An effective energy parameter of the model is estimated by comparing the theoretical data on characteristic forces to the corresponding experimental values combined with an extrapolation of the theoretical data to the experimental pulling speeds. __label__MISC
These studies provide guidance for future experiments on single molecule manipulation and should lead to selection of proteins for applications. __label__MISC
A new class of proteins, involving cystein slipknots, is identified as one that is expected to lead to the strongest force clamps known. __label__MISC
Atomic force microscopy, optical tweezers, and other tools of nanotechnology have enabled induction and monitoring of large conformational changes in biomolecules. __label__MISC
Such studies are performed to assess structure of the biomolecules, their elastic properties, and ability to act as nanomachines in a cell. __label__MISC
Stretching studies of proteins CITATION are of a particular current interest and they have been performed for under a hundred of systems. __label__MISC
They are limited by of order 100 ns time scales and thus require using unrealistically large constant pulling speeds. __label__CONT
However, they often elucidate the nature of the force clamp the region responsible for the largest force of resistance to pulling, FORMULA. __label__MISC
All of the experimental and all-atom simulational studies address merely a tiny fraction of proteins that are stored in the Protein Data Bank CITATION. __label__MISC
Thus it appears worthwhile to consider a large set of proteins and determine their FORMULA within an approximate model that allows for fast and yet reasonably accurate calculations. __label__MISC
Structure-based models of proteins, as pioneered by Go and his collaborators CITATION and used in several implementations CITATION CITATION, seem to be suited to this task especially well since they are defined in terms of the native structures away from which stretching is imposed. __label__MISC
There are many ways, all phenomenological, to construct a structure-based model of a protein. __label__MISC
504 of possible variants are enumerated and 62 are studied in details in ref. CITATION. __label__MISC
The variants differ by the choice of effective potentials, nature of the local backbone stiffness, energy-related parameters, and of the coarse-grained degrees of freedom. __label__MISC
Comparing FORMULA to the corresponding experimental values in 36 available cases selects several optimal models CITATION. __label__MISC
Among them, there is one which is very simple and which describes a protein in terms of its FORMULA atoms, as labeled by the sequential index FORMULA. __label__MISC
The contact map is determined by assigning the van der Waals spheres to the heavy atoms and by checking whether spheres belonging to different amino acids overlap in the native state CITATION, CITATION. __label__MISC
Non-native contacts are considered repulsive. __label__MISC
Application of this criterion frequently selects the FORMULA contacts as native. __label__MISC
If the contact map includes these contacts the resulting model will be denoted here as FORMULA. __label__MISC
Thus the FORMULA couplings should better be removed from the contact map . __label__MISC
The survey to determine FORMULA in 7510 model proteins with the number of amino acids, FORMULA, not exceeding 150 and 239 longer proteins has been accomplished twice. __label__MISC
First within the FORMULA model CITATION and soon afterwords within the FORMULA model CITATION. __label__MISC
The two surveys are compared in more details in refs. CITATION, CITATION. __label__MISC
The results differ, particularly when it comes to ranking of the proteins according to the value of FORMULA, but they mutually provide the error bars on the findings. __label__MISC
They both agree, however, on predicting that there are many proteins whose strength should be considerably larger than the frequently studied benchmark the sarcomere protein titin. __label__MISC
Near the top of the list, there is the scaffoldin protein c7A which has been recently measured to have FORMULA of about 480 pN CITATION. __label__MISC
Other findings include establishing correlations with the CATH hierarchical classification scheme CITATION, CITATION, such as that there are no strong FORMULA proteins, and identification of several types of the force clamps. __label__MISC
The large forces most commonly originate in parallel FORMULA that are sheared CITATION. __label__MISC
However, there are also clamps with antiparallel FORMULA, unstructured strands, and other kinds. __label__MISC
Here, we present results of still another survey which is based on a download of December 18, 2008 which contains 54 807 structure files and leads to 17 134 acceptable structures with FORMULA not exceeding 250. __label__MISC
These structures are then analyzed through simulations based on the FORMULA model. __label__MISC
The numerical code has been improved to allow for acceleration of calculations by a factor of 2. __label__MISC
The 190 structures with the top values of FORMULA in units of FORMULA are shown in Table 1 and Table S1 of the SI, together with the values of titin and ubiquitin to provide a scale. __label__MISC
As argued in the Materials and Methods section section, the unit of force, FORMULA, is now estimated to be of order 110 pN. __label__MISC
All of the corresponding proteins are predicted to be much stronger than titin and none but two of them have been studied experimentally yet. __label__MISC
One of them involves a cysteine slipknot and is found to be operational in all of the 13 top strength proteins. __label__OWNX
In this motif, a slip-loop is pulled out of a cysteine knot-loop. __label__OWNX
The two mechanisms are similar in spirit since both involve dragging of the backbone. __label__OWNX
However, in the CSK case, two fragments of the backbone are participating. __label__OWNX
The previous surveys did not relate to the SCOP scheme. __label__OWNX
A general observation, however, is that each such group of structures may also include examples of proteins that unravel easily. __label__MISC
The dynamics of a protein are very sensitive to mechanical details that are largely captured by the contact map and not just by the appearance of a structure. __label__MISC
On the other hand, if one were to look for mechanically strong proteins then the architectures and folds identified by us should provide a good starting point. __label__MISC
We also study the dependence of FORMULA on the pulling velocity and characterize the dependence on FORMULA through distributions of the forces. __label__OWNX
The current third survey has been performed within the same FORMULA model as the second survey CITATION. __label__MISC
However, we reuse and extend it here because the editors of Biophysical Journal retracted the second survey CITATION. __label__BASE
All of the values of FORMULA are deposited at the website LINK and can by accessed by through the PDB structure code. __label__OWNX
A new theoretical survey of proteins' resistance to constant speed stretching is performed for a set of 17 134 proteins as described by a structure-based model. __label__AIMX
Our previous studies have dealt with 7510 proteins of no more than 150 amino acids. __label__MISC
Most of the predicted top-strength proteins have not yet been studied experimentally. __label__MISC
They involve disulphide bridges and, in particular, cysteine slipknots. __label__MISC
An effective energy parameter of the model is estimated by comparing the theoretical data on characteristic forces to the corresponding experimental values combined with an extrapolation of the theoretical data to the experimental pulling speeds. __label__MISC
A new class of proteins, involving cystein slipknots, is identified as one that is expected to lead to the strongest force clamps known. __label__MISC
This class is characterized through molecular dynamics simulations. __label__MISC
Atomic force microscopy, optical tweezers, and other tools of nanotechnology have enabled induction and monitoring of large conformational changes in biomolecules. __label__MISC
Interpretation of some of these experiments has been helped by all-atom simulations, such as reported in refs. CITATION, CITATION. __label__MISC
They are limited by of order 100 ns time scales and thus require using unrealistically large constant pulling speeds. __label__CONT
However, they often elucidate the nature of the force clamp the region responsible for the largest force of resistance to pulling, FORMULA. __label__MISC
Structure-based models of proteins, as pioneered by Go and his collaborators CITATION and used in several implementations CITATION CITATION, seem to be suited to this task especially well since they are defined in terms of the native structures away from which stretching is imposed. __label__MISC
There are many ways, all phenomenological, to construct a structure-based model of a protein. __label__MISC
504 of possible variants are enumerated and 62 are studied in details in ref. CITATION. __label__MISC
The variants differ by the choice of effective potentials, nature of the local backbone stiffness, energy-related parameters, and of the coarse-grained degrees of freedom. __label__MISC
Comparing FORMULA to the corresponding experimental values in 36 available cases selects several optimal models CITATION. __label__MISC
Among them, there is one which is very simple and which describes a protein in terms of its FORMULA atoms, as labeled by the sequential index FORMULA. __label__MISC
This model is denoted by FORMULA which stands for, respectively, the Lennard-Jones native contact potentials, local backbone stiffness represented by harmonic terms that favor the native values of local chiralities, the contact map in which there are no FORMULA contacts, and the amplitude of the Lennard-Jones potential, FORMULA, is uniform. __label__MISC
The contact map is determined by assigning the van der Waals spheres to the heavy atoms and by checking whether spheres belonging to different amino acids overlap in the native state CITATION, CITATION. __label__MISC
If they do, a contact is declared as native. __label__MISC
Non-native contacts are considered repulsive. __label__MISC
If the contact map includes these contacts the resulting model will be denoted here as FORMULA. __label__MISC
On average, it performs worse than FORMULA because the FORMULA contacts usually correspond to the weak van der Waals couplings as can be demonstrated in a sample of proteins by using a software CITATION which analyses atomic configurations from the chemical perspective on molecular bonds. __label__MISC
Thus the FORMULA couplings should better be removed from the contact map . __label__MISC
First within the FORMULA model CITATION and soon afterwords within the FORMULA model CITATION. __label__MISC
The first survey also comes with many details of the methodology whereas the second just presents the outcomes. __label__MISC
The two surveys are compared in more details in refs. CITATION, CITATION. __label__MISC
Near the top of the list, there is the scaffoldin protein c7A which has been recently measured to have FORMULA of about 480 pN CITATION. __label__MISC
However, there are also clamps with antiparallel FORMULA, unstructured strands, and other kinds. __label__MISC
The two surveys have been based on the structure download made on July 26, 2005 when the PDB comprised 29 385 entries. __label__MISC
Many of them correspond to nucleic acids, complexes with nucleic acids and with other proteins, carbohydrates, or come with incomplete files and hence the much smaller number of proteins that could be used in the molecular dynamics studies. __label__MISC
Here, we present results of still another survey which is based on a download of December 18, 2008 which contains 54 807 structure files and leads to 17 134 acceptable structures with FORMULA not exceeding 250. __label__MISC
The numerical code has been improved to allow for acceleration of calculations by a factor of 2. __label__MISC
The 190 structures with the top values of FORMULA in units of FORMULA are shown in Table 1 and Table S1 of the SI, together with the values of titin and ubiquitin to provide a scale. __label__MISC
As argued in the Materials and Methods section section, the unit of force, FORMULA, is now estimated to be of order 110 pN. __label__MISC
All of the corresponding proteins are predicted to be much stronger than titin and none but two of them have been studied experimentally yet. __label__MISC
In addition to the types of force clamps identified before, we have discovered two new mechanisms of sturdiness. __label__OWNX
One of them involves a cysteine slipknot and is found to be operational in all of the 13 top strength proteins. __label__OWNX
In this motif, a slip-loop is pulled out of a cysteine knot-loop. __label__OWNX
Another involves dragging of a single fragment of the main chain across a cysteine knot-loop. __label__OWNX
The two mechanisms are similar in spirit since both involve dragging of the backbone. __label__OWNX
However, in the CSK case, two fragments of the backbone are participating. __label__OWNX
We make a more systematic identification of the CATH-classified architectures that are linked to mechanical strength and then analyze correlations of the data to the SCOP-based grouping CITATION CITATION. __label__AIMX
The previous surveys did not relate to the SCOP scheme. __label__OWNX
We identify the CATH-based architectures and SCOP-based folds that are associated with the occurrence of a strong resistance to pulling. __label__OWNX
The dynamics of a protein are very sensitive to mechanical details that are largely captured by the contact map and not just by the appearance of a structure. __label__MISC
We also study the dependence of FORMULA on the pulling velocity and characterize the dependence on FORMULA through distributions of the forces. __label__OWNX
The current third survey has been performed within the same FORMULA model as the second survey CITATION. __label__MISC
However, we reuse and extend it here because the editors of Biophysical Journal retracted the second survey CITATION. __label__BASE
All of the values of FORMULA are deposited at the website LINK and can by accessed by through the PDB structure code. __label__OWNX
The proteins selected have no gaps in their structure determination and consist of no more than 250 amino acids. __label__OWNX
Our previous studies have dealt with 7510 proteins of no more than 150 amino acids. __label__MISC
The proteins are ranked according to the strength of the resistance. __label__OWNX
They involve disulphide bridges and, in particular, cysteine slipknots. __label__OWNX
An effective energy parameter of the model is estimated by comparing the theoretical data on characteristic forces to the corresponding experimental values combined with an extrapolation of the theoretical data to the experimental pulling speeds. __label__OWNX
These studies provide guidance for future experiments on single molecule manipulation and should lead to selection of proteins for applications. __label__OWNX
A new class of proteins, involving cystein slipknots, is identified as one that is expected to lead to the strongest force clamps known. __label__OWNX
This class is characterized through molecular dynamics simulations. __label__OWNX
Atomic force microscopy, optical tweezers, and other tools of nanotechnology have enabled induction and monitoring of large conformational changes in biomolecules. __label__MISC
Such studies are performed to assess structure of the biomolecules, their elastic properties, and ability to act as nanomachines in a cell. __label__MISC
Stretching studies of proteins CITATION are of a particular current interest and they have been performed for under a hundred of systems. __label__MISC
They are limited by of order 100 ns time scales and thus require using unrealistically large constant pulling speeds. __label__CONT
However, they often elucidate the nature of the force clamp the region responsible for the largest force of resistance to pulling, FORMULA. __label__MISC
All of the experimental and all-atom simulational studies address merely a tiny fraction of proteins that are stored in the Protein Data Bank CITATION. __label__CONT
Thus it appears worthwhile to consider a large set of proteins and determine their FORMULA within an approximate model that allows for fast and yet reasonably accurate calculations. __label__MISC
There are many ways, all phenomenological, to construct a structure-based model of a protein. __label__MISC
504 of possible variants are enumerated and 62 are studied in details in ref. CITATION. __label__MISC
The variants differ by the choice of effective potentials, nature of the local backbone stiffness, energy-related parameters, and of the coarse-grained degrees of freedom. __label__MISC
The most crucial choice relates to making a decision about which interactions between amino acids count as native contacts. __label__MISC
Comparing FORMULA to the corresponding experimental values in 36 available cases selects several optimal models CITATION. __label__MISC
Among them, there is one which is very simple and which describes a protein in terms of its FORMULA atoms, as labeled by the sequential index FORMULA. __label__MISC
This model is denoted by FORMULA which stands for, respectively, the Lennard-Jones native contact potentials, local backbone stiffness represented by harmonic terms that favor the native values of local chiralities, the contact map in which there are no FORMULA contacts, and the amplitude of the Lennard-Jones potential, FORMULA, is uniform. __label__MISC
The contact map is determined by assigning the van der Waals spheres to the heavy atoms and by checking whether spheres belonging to different amino acids overlap in the native state CITATION, CITATION. __label__MISC
If they do, a contact is declared as native. __label__MISC
Non-native contacts are considered repulsive. __label__MISC
Application of this criterion frequently selects the FORMULA contacts as native. __label__MISC
If the contact map includes these contacts the resulting model will be denoted here as FORMULA. __label__MISC
Thus the FORMULA couplings should better be removed from the contact map . __label__MISC
The survey to determine FORMULA in 7510 model proteins with the number of amino acids, FORMULA, not exceeding 150 and 239 longer proteins has been accomplished twice. __label__MISC
First within the FORMULA model CITATION and soon afterwords within the FORMULA model CITATION. __label__MISC
The first survey also comes with many details of the methodology whereas the second just presents the outcomes. __label__MISC
The two surveys are compared in more details in refs. CITATION, CITATION. __label__MISC
The results differ, particularly when it comes to ranking of the proteins according to the value of FORMULA, but they mutually provide the error bars on the findings. __label__MISC
They both agree, however, on predicting that there are many proteins whose strength should be considerably larger than the frequently studied benchmark the sarcomere protein titin. __label__MISC
Other findings include establishing correlations with the CATH hierarchical classification scheme CITATION, CITATION, such as that there are no strong FORMULA proteins, and identification of several types of the force clamps. __label__MISC
The large forces most commonly originate in parallel FORMULA that are sheared CITATION. __label__MISC
The two surveys have been based on the structure download made on July 26, 2005 when the PDB comprised 29 385 entries. __label__MISC
Many of them correspond to nucleic acids, complexes with nucleic acids and with other proteins, carbohydrates, or come with incomplete files and hence the much smaller number of proteins that could be used in the molecular dynamics studies. __label__MISC
Here, we present results of still another survey which is based on a download of December 18, 2008 which contains 54 807 structure files and leads to 17 134 acceptable structures with FORMULA not exceeding 250. __label__AIMX
These structures are then analyzed through simulations based on the FORMULA model. __label__OWNX
The numerical code has been improved to allow for acceleration of calculations by a factor of 2. __label__OWNX
As argued in the Materials and Methods section section, the unit of force, FORMULA, is now estimated to be of order 110 pN. __label__OWNX
All of the corresponding proteins are predicted to be much stronger than titin and none but two of them have been studied experimentally yet. __label__OWNX
In addition to the types of force clamps identified before, we have discovered two new mechanisms of sturdiness. __label__OWNX
One of them involves a cysteine slipknot and is found to be operational in all of the 13 top strength proteins. __label__OWNX
In this motif, a slip-loop is pulled out of a cysteine knot-loop. __label__OWNX
Another involves dragging of a single fragment of the main chain across a cysteine knot-loop. __label__OWNX
The two mechanisms are similar in spirit since both involve dragging of the backbone. __label__OWNX
However, in the CSK case, two fragments of the backbone are participating. __label__OWNX
We make a more systematic identification of the CATH-classified architectures that are linked to mechanical strength and then analyze correlations of the data to the SCOP-based grouping CITATION CITATION. __label__OWNX
The previous surveys did not relate to the SCOP scheme. __label__CONT
A general observation, however, is that each such group of structures may also include examples of proteins that unravel easily. __label__OWNX
The dynamics of a protein are very sensitive to mechanical details that are largely captured by the contact map and not just by the appearance of a structure. __label__OWNX
On the other hand, if one were to look for mechanically strong proteins then the architectures and folds identified by us should provide a good starting point. __label__OWNX
We also study the dependence of FORMULA on the pulling velocity and characterize the dependence on FORMULA through distributions of the forces. __label__OWNX
The current third survey has been performed within the same FORMULA model as the second survey CITATION. __label__MISC
However, we reuse and extend it here because the editors of Biophysical Journal retracted the second survey CITATION. __label__BASE
All of the values of FORMULA are deposited at the website LINK and can by accessed by through the PDB structure code. __label__OWNX
Here we use a stochastic simulation model for viral dynamics to investigate how the timing and duration of the induction phase of induction maintenance therapies might be optimized. __label__AIMX
Our model suggests that under a variety of biologically plausible conditions, 6 10 mo of induction therapy are needed to achieve durable suppression and maximize the probability of eradicating viruses resistant to the maintenance regimen. __label__OWNX
For induction regimens of more limited duration, a delayed-induction or -intensification period initiated sometime after the start of maintenance therapy appears to be optimal. __label__OWNX
The optimal delay length depends on the fitness of resistant viruses and the rate at which target-cell populations recover after therapy is initiated. __label__OWNX
These observations have implications for both the timing and the kinds of drugs selected for induction maintenance and therapy-intensification strategies. __label__OWNX
In therapy-naive patients without clinically apparent resistance mutations, triple-drug therapy with two nucleoside analog reverse transcriptase inhibitors and a protease inhibitor or a non-nucleoside reverse transcriptase inhibitor is standard CITATION. __label__MISC
In these patients, treatment success rates, defined as viral load 50 copies/ml at 48 wk, range from 70 percent to 80 percent 85 percent. __label__MISC
However, in patients with previous regimen failure requiring salvage therapy, response rates are usually considerably lower CITATION CITATION, and it is frequently not possible to assemble a three-drug regimen with uncompromised activity against all viral strains present. __label__MISC
In these individuals, treatment failure often occurs after an initial period of response to a new regimen, and is usually associated with the appearance of multiply drug-resistant viral strains. __label__MISC
This has led to attempts to treat highly experienced patients with various deep salvage regimens consisting of four, five, or six individual drugs CITATION CITATION. __label__MISC
The need to minimize drug resistance while reducing treatment-related toxicities has engendered an interest in induction maintenance strategies, in which a period of intensified antiretroviral therapy is followed by a simplified long-term regimen CITATION CITATION. __label__MISC
Most such trials have yielded higher failure rates in the treatment group than in controls receiving conventional therapy. __label__CONT
One weakness of existing studies has been that induction therapy consisted of standard three-drug antiretroviral therapy regimens in common clinical use at the time of the study, under conditions now recognized to permit subclinical viral replication CITATION, CITATION. __label__CONT
However, two recent studies have shown the apparent effectiveness of induction therapy for 48 wk followed by maintenance therapy with atazanavir CITATION or lopinvir/ritonavir CITATION, CITATION, and this has led to new optimism concerning IM approaches. __label__MISC
To explore this hypothesis quantitatively, we constructed a detailed computer simulation model of the dynamics of sensitive and resistant viruses during a hypothetical IM regimen. __label__OWNX
We show that the timing and duration of induction therapy relative to maintenance therapy can affect the probability that viruses resistant to the maintenance regimen will be eradicated in ways that are somewhat counterintuitive. __label__OWNX
Under biologically plausible conditions, we find that 6 10 mo of induction therapy are required to maximize the probability of eradicating these resistant viruses. __label__OWNX
For shorter induction periods, we find that it is optimal to use a delayed-induction regimen administered several days to weeks after the start of the intended long-term maintenance therapy. __label__OWNX
The tradeoff between the need to suppress drug-resistant viruses and the problem of treatment toxicity has led to the development of various drug-sparing HIV-1 treatment strategies. __label__MISC
Here we use a stochastic simulation model for viral dynamics to investigate how the timing and duration of the induction phase of induction maintenance therapies might be optimized. __label__AIMX
Our model suggests that under a variety of biologically plausible conditions, 6 10 mo of induction therapy are needed to achieve durable suppression and maximize the probability of eradicating viruses resistant to the maintenance regimen. __label__OWNX
For induction regimens of more limited duration, a delayed-induction or -intensification period initiated sometime after the start of maintenance therapy appears to be optimal. __label__OWNX
The optimal delay length depends on the fitness of resistant viruses and the rate at which target-cell populations recover after therapy is initiated. __label__OWNX
The failure of antiretroviral therapies to completely suppress viral replication in some patients represents a major difficulty in the management of HIV infection. __label__MISC
In therapy-naive patients without clinically apparent resistance mutations, triple-drug therapy with two nucleoside analog reverse transcriptase inhibitors and a protease inhibitor or a non-nucleoside reverse transcriptase inhibitor is standard CITATION. __label__MISC
In these individuals, treatment failure often occurs after an initial period of response to a new regimen, and is usually associated with the appearance of multiply drug-resistant viral strains. __label__MISC
This has led to attempts to treat highly experienced patients with various deep salvage regimens consisting of four, five, or six individual drugs CITATION CITATION. __label__MISC
These patients are particularly vulnerable to the many drug interactions CITATION and adverse metabolic, hematologic, neurologic, cardiovascular, and gastrointestinal side effects that complicate HIV therapy and seriously undermine the success of clinical management CITATION CITATION . __label__MISC
Failure typically occurs during maintenance therapy, and has been attributed to poor regimen adherence CITATION and recrudescence of resistance mutations present before institution of induction therapy CITATION. __label__MISC
One weakness of existing studies has been that induction therapy consisted of standard three-drug antiretroviral therapy regimens in common clinical use at the time of the study, under conditions now recognized to permit subclinical viral replication CITATION, CITATION. __label__CONT
Moreover, in these early studies, the induction phase only lasted between 3 to 6 mo, which may be insufficient. __label__CONT
However, two recent studies have shown the apparent effectiveness of induction therapy for 48 wk followed by maintenance therapy with atazanavir CITATION or lopinvir/ritonavir CITATION, CITATION, and this has led to new optimism concerning IM approaches. __label__MISC
We have hypothesized that a longer period of a highly suppressive induction therapy that is appropriately timed relative to the start of maintenance therapy may allow minority resistant variants to decay below a stochastic extinction threshold, allowing for successful long-term treatment with simpler and better-tolerated regimens. __label__OWNX
To explore this hypothesis quantitatively, we constructed a detailed computer simulation model of the dynamics of sensitive and resistant viruses during a hypothetical IM regimen. __label__AIMX
We show that the timing and duration of induction therapy relative to maintenance therapy can affect the probability that viruses resistant to the maintenance regimen will be eradicated in ways that are somewhat counterintuitive. __label__OWNX
Under biologically plausible conditions, we find that 6 10 mo of induction therapy are required to maximize the probability of eradicating these resistant viruses. __label__OWNX
The tradeoff between the need to suppress drug-resistant viruses and the problem of treatment toxicity has led to the development of various drug-sparing HIV-1 treatment strategies. __label__MISC
Here we use a stochastic simulation model for viral dynamics to investigate how the timing and duration of the induction phase of induction maintenance therapies might be optimized. __label__AIMX
Our model suggests that under a variety of biologically plausible conditions, 6 10 mo of induction therapy are needed to achieve durable suppression and maximize the probability of eradicating viruses resistant to the maintenance regimen. __label__OWNX
The optimal delay length depends on the fitness of resistant viruses and the rate at which target-cell populations recover after therapy is initiated. __label__OWNX
These observations have implications for both the timing and the kinds of drugs selected for induction maintenance and therapy-intensification strategies. __label__OWNX
The failure of antiretroviral therapies to completely suppress viral replication in some patients represents a major difficulty in the management of HIV infection. __label__MISC
In therapy-naive patients without clinically apparent resistance mutations, triple-drug therapy with two nucleoside analog reverse transcriptase inhibitors and a protease inhibitor or a non-nucleoside reverse transcriptase inhibitor is standard CITATION. __label__MISC
In these patients, treatment success rates, defined as viral load 50 copies/ml at 48 wk, range from 70 percent to 80 percent 85 percent. __label__MISC
This has led to attempts to treat highly experienced patients with various deep salvage regimens consisting of four, five, or six individual drugs CITATION CITATION. __label__MISC
These patients are particularly vulnerable to the many drug interactions CITATION and adverse metabolic, hematologic, neurologic, cardiovascular, and gastrointestinal side effects that complicate HIV therapy and seriously undermine the success of clinical management CITATION CITATION . __label__MISC
The need to minimize drug resistance while reducing treatment-related toxicities has engendered an interest in induction maintenance strategies, in which a period of intensified antiretroviral therapy is followed by a simplified long-term regimen CITATION CITATION. __label__MISC
One weakness of existing studies has been that induction therapy consisted of standard three-drug antiretroviral therapy regimens in common clinical use at the time of the study, under conditions now recognized to permit subclinical viral replication CITATION, CITATION. __label__CONT
Moreover, in these early studies, the induction phase only lasted between 3 to 6 mo, which may be insufficient. __label__CONT
However, two recent studies have shown the apparent effectiveness of induction therapy for 48 wk followed by maintenance therapy with atazanavir CITATION or lopinvir/ritonavir CITATION, CITATION, and this has led to new optimism concerning IM approaches. __label__MISC
We have hypothesized that a longer period of a highly suppressive induction therapy that is appropriately timed relative to the start of maintenance therapy may allow minority resistant variants to decay below a stochastic extinction threshold, allowing for successful long-term treatment with simpler and better-tolerated regimens. __label__OWNX
To explore this hypothesis quantitatively, we constructed a detailed computer simulation model of the dynamics of sensitive and resistant viruses during a hypothetical IM regimen. __label__AIMX
We show that the timing and duration of induction therapy relative to maintenance therapy can affect the probability that viruses resistant to the maintenance regimen will be eradicated in ways that are somewhat counterintuitive. __label__OWNX
Under biologically plausible conditions, we find that 6 10 mo of induction therapy are required to maximize the probability of eradicating these resistant viruses. __label__OWNX
For shorter induction periods, we find that it is optimal to use a delayed-induction regimen administered several days to weeks after the start of the intended long-term maintenance therapy. __label__OWNX
The influence of lipid molecules on the aggregation of a highly amyloidogenic segment of human islet amyloid polypeptide, hIAPP20 29, and the corresponding sequence from rat has been studied by all-atom replica exchange molecular dynamics simulations with explicit solvent model. __label__MISC
hIAPP20 29 fragments aggregate into partially ordered -sheet oligomers and then undergo large conformational reorganization and convert into parallel/antiparallel -sheet oligomers in mixed in-register and out-of-register patterns. __label__MISC
Our study provides the atomic resolution descriptions of the catalytic function of lipid molecules on the aggregation of IAPP peptides. __label__AIMX
A range of human diseases including Alzheimer's disease, Parkinson's disease, the spongiform encephalopathy and type 2 diabetes mellitus is associated with amyloid deposits of normally soluble proteins or peptides CITATION CITATION. __label__MISC
In T2DM, the main protein component of fibrillar protein deposits in the pancreatic islets of langerhans has been identified as a 37-residue hormone referred to as islet amyloid polypeptide or amylin CITATION, which is synthesized in -cells of the pancreas and cosecreted with insulin CITATION, CITATION. __label__MISC
There are convincing evidences that the toxicity of amyloid related diseases may be caused by the soluble intermediate oligomers instead of mature fibrils CITATION CITATION, and the interaction between lipid bilayer and these soluble oligomer CITATION CITATION. __label__MISC
Moreover, up to 10 percent components in amyloid deposits from patient tissues were lipid molecules, indicating that the lipids can be uptaken from membranes and then wrapped into fibrillar amyloid CITATION CITATION. __label__MISC
There is, however, missing information about how individual lipid molecule involving in the peptide aggregation process. __label__CONT
It will then be beneficial to understand the molecular details of how single lipid molecule influences the assembly process of amyloidogenic peptides which is the main focus of the current study. __label__AIMX
Besides the external factors, such as lipid bilayer, pH value, the sequences of peptide themselves have great effects on the aggregation behaviors. __label__MISC
The rIAPP differs from hIAPP in six amino acids and five of them are clustered in a short decapeptide, which is considered to be strongly amyloidogenic and forms similar unbranched fibrils itself to the full-length hIAPP CITATION, CITATION. __label__MISC
The three proline substitutions in rIAPP20 29 are believed to be highly responsible for the lacking of the amyloidogenic property of the segment or full-length peptide CITATION. __label__MISC
Although rIAPP has been intensively applied in experimental research acting as a potential peptide inhibitor for peptide aggregation CITATION, CITATION, the molecular mechanism of its resistance to amyloid is still not crystal clear. __label__CONT
Here, the aggregation of rIAPP20 29 segments is subjected to the same simulation condition as hIAPP20 29 to explore the non-amyloidogenic properties of the peptide and meanwhile to evaluate the simulation results as a negative control. __label__MISC
Thus, the computational approaches have been employed to complement experimental investigations to gain the insight into the aggregation mechanisms CITATION CITATION. __label__MISC
Santini et al. performed ART-OPEP simulations on trimer of A 16 22 by treating side chains as a bead and solvent implicitly CITATION. __label__MISC
A novel mechanism for single -strand to surmount unnatural registry without dissociation, referred to as reptation was proposed before experimental characterization CITATION. __label__MISC
Cheon et al. used ProFASi package to reduce the bonded potential energy to include torsional angles only and treated hydrogen bonds explicitly CITATION. __label__MISC
They were able to carry out two series of 100 Monte Carlo simulations on 20 copies of two fragments A 16 22 and A 25 35. __label__MISC
In these studies, simulations were usually started with randomly oriented, extended or random-coiled peptides which underwent ab initio folding to form -sheet oligomers. __label__MISC
Albeit simplified models allow studying large-scale systems CITATION or observing more events in limited simulation time CITATION, all-atom explicit solvent models can reproduce amyloid aggregation in aqueous environment more accurately and supply more information on sidechain contacts CITATION. __label__MISC
Nguyen et al. prolonged a series of conventional MD simulations to 300 ns on A 16 22 of 3 6 oligomer size with explicit solvent CITATION. __label__MISC
The extensive simulations were able to probe the interpeptide sidechain contacts and large conformational fluctuations upon monomer addition to preformed -sheet oligomers in a dock-lock mechanism. __label__MISC
In our studies, an enhanced-sampling method, replica exchange molecular dynamics CITATION was implemented CITATION, and all water and peptide atoms are treated explicitly by applying OPLS-AA force field CITATION. __label__OWNX
The four copies of amyloidogenic segment hIAPP20 29 and an extra dioleoylphosphatidylcholine lipid molecule were initially set in extended conformation and dispersed in simulation boxes. __label__OWNX
The formation of -sheet containing tetramers, was observed within 100 ns ab initio REMD folding simulations. __label__OWNX
The acquirement of abundant intermediate states suggested two possible -sheet transition pathways. __label__OWNX
Simulation of four hIAPP peptides without lipid molecule was also performed. __label__OWNX
Nonamyloidogenic rat IAPP segments were studied as a negative control with the aim of understanding the inhibitory effect of three proline substitutions. __label__OWNX
The influence of lipid molecules on the aggregation of a highly amyloidogenic segment of human islet amyloid polypeptide, hIAPP20 29, and the corresponding sequence from rat has been studied by all-atom replica exchange molecular dynamics simulations with explicit solvent model. __label__MISC
hIAPP20 29 fragments aggregate into partially ordered -sheet oligomers and then undergo large conformational reorganization and convert into parallel/antiparallel -sheet oligomers in mixed in-register and out-of-register patterns. __label__MISC
The hydrophobic interaction between lipid tails and residues at positions 23 25 is found to stabilize the ordered -sheet structure, indicating a catalysis role of lipid molecules in hIAPP20 29 self-assembly. __label__MISC
The rat IAPP variants with three proline residues maintain unstructured micelle-like oligomers, which is consistent with non-amyloidogenic behavior observed in experimental studies. __label__MISC
Our study provides the atomic resolution descriptions of the catalytic function of lipid molecules on the aggregation of IAPP peptides. __label__AIMX
In T2DM, the main protein component of fibrillar protein deposits in the pancreatic islets of langerhans has been identified as a 37-residue hormone referred to as islet amyloid polypeptide or amylin CITATION, which is synthesized in -cells of the pancreas and cosecreted with insulin CITATION, CITATION. __label__MISC
There are convincing evidences that the toxicity of amyloid related diseases may be caused by the soluble intermediate oligomers instead of mature fibrils CITATION CITATION, and the interaction between lipid bilayer and these soluble oligomer CITATION CITATION. __label__MISC
Moreover, up to 10 percent components in amyloid deposits from patient tissues were lipid molecules, indicating that the lipids can be uptaken from membranes and then wrapped into fibrillar amyloid CITATION CITATION. __label__MISC
Most studies so far treated the lipid bilayer as a template to exert its influences on the conformation and aggregation properties of peptides CITATION CITATION. __label__MISC
There is, however, missing information about how individual lipid molecule involving in the peptide aggregation process. __label__MISC
It will then be beneficial to understand the molecular details of how single lipid molecule influences the assembly process of amyloidogenic peptides which is the main focus of the current study. __label__OWNX
Besides the external factors, such as lipid bilayer, pH value, the sequences of peptide themselves have great effects on the aggregation behaviors. __label__MISC
Several other species such as non-human primates CITATION, cats CITATION, raccoons CITATION, and rodent species can produce IAPP, but the primary sequence of IAPP varies slightly among species. __label__MISC
The rIAPP differs from hIAPP in six amino acids and five of them are clustered in a short decapeptide, which is considered to be strongly amyloidogenic and forms similar unbranched fibrils itself to the full-length hIAPP CITATION, CITATION. __label__MISC
The three proline substitutions in rIAPP20 29 are believed to be highly responsible for the lacking of the amyloidogenic property of the segment or full-length peptide CITATION. __label__MISC
Although rIAPP has been intensively applied in experimental research acting as a potential peptide inhibitor for peptide aggregation CITATION, CITATION, the molecular mechanism of its resistance to amyloid is still not crystal clear. __label__MISC
Here, the aggregation of rIAPP20 29 segments is subjected to the same simulation condition as hIAPP20 29 to explore the non-amyloidogenic properties of the peptide and meanwhile to evaluate the simulation results as a negative control. __label__MISC
Due to the metastable and short-lived nature of soluble pre-fibril oligomers at the early steps of fibril formation, experimental data are usually difficult to obtain CITATION, CITATION. __label__MISC
Thus, the computational approaches have been employed to complement experimental investigations to gain the insight into the aggregation mechanisms CITATION CITATION. __label__MISC
Considering multiple copies of peptides needed due to the self-assembly nature of amyloid formation, various simplified representations of molecular systems using implicit solvent models were preferred rather than all-atom models. __label__MISC
Santini et al. performed ART-OPEP simulations on trimer of A 16 22 by treating side chains as a bead and solvent implicitly CITATION. __label__MISC
Cheon et al. used ProFASi package to reduce the bonded potential energy to include torsional angles only and treated hydrogen bonds explicitly CITATION. __label__MISC
They were able to carry out two series of 100 Monte Carlo simulations on 20 copies of two fragments A 16 22 and A 25 35. __label__MISC
They observed early-stage events and obtained an atomic-detailed description of nucleated conformational conversion CITATION model for amyloid aggregation. __label__MISC
In these studies, simulations were usually started with randomly oriented, extended or random-coiled peptides which underwent ab initio folding to form -sheet oligomers. __label__MISC
Albeit simplified models allow studying large-scale systems CITATION or observing more events in limited simulation time CITATION, all-atom explicit solvent models can reproduce amyloid aggregation in aqueous environment more accurately and supply more information on sidechain contacts CITATION. __label__MISC
Nguyen et al. prolonged a series of conventional MD simulations to 300 ns on A 16 22 of 3 6 oligomer size with explicit solvent CITATION. __label__MISC
The extensive simulations were able to probe the interpeptide sidechain contacts and large conformational fluctuations upon monomer addition to preformed -sheet oligomers in a dock-lock mechanism. __label__MISC
In our studies, an enhanced-sampling method, replica exchange molecular dynamics CITATION was implemented CITATION, and all water and peptide atoms are treated explicitly by applying OPLS-AA force field CITATION. __label__OWNX
The four copies of amyloidogenic segment hIAPP20 29 and an extra dioleoylphosphatidylcholine lipid molecule were initially set in extended conformation and dispersed in simulation boxes. __label__OWNX
The formation of -sheet containing tetramers, was observed within 100 ns ab initio REMD folding simulations. __label__OWNX
Simulation of four hIAPP peptides without lipid molecule was also performed. __label__OWNX
Nonamyloidogenic rat IAPP segments were studied as a negative control with the aim of understanding the inhibitory effect of three proline substitutions. __label__OWNX
The influence of lipid molecules on the aggregation of a highly amyloidogenic segment of human islet amyloid polypeptide, hIAPP20 29, and the corresponding sequence from rat has been studied by all-atom replica exchange molecular dynamics simulations with explicit solvent model. __label__MISC
hIAPP20 29 fragments aggregate into partially ordered -sheet oligomers and then undergo large conformational reorganization and convert into parallel/antiparallel -sheet oligomers in mixed in-register and out-of-register patterns. __label__MISC
The hydrophobic interaction between lipid tails and residues at positions 23 25 is found to stabilize the ordered -sheet structure, indicating a catalysis role of lipid molecules in hIAPP20 29 self-assembly. __label__MISC
The rat IAPP variants with three proline residues maintain unstructured micelle-like oligomers, which is consistent with non-amyloidogenic behavior observed in experimental studies. __label__MISC
Our study provides the atomic resolution descriptions of the catalytic function of lipid molecules on the aggregation of IAPP peptides. __label__AIMX
A range of human diseases including Alzheimer's disease, Parkinson's disease, the spongiform encephalopathy and type 2 diabetes mellitus is associated with amyloid deposits of normally soluble proteins or peptides CITATION CITATION. __label__MISC
There are convincing evidences that the toxicity of amyloid related diseases may be caused by the soluble intermediate oligomers instead of mature fibrils CITATION CITATION, and the interaction between lipid bilayer and these soluble oligomer CITATION CITATION. __label__MISC
For example, channel-like annular structures of oligomers of several amyloidogenic peptides have been observed on the lipid membrane CITATION, CITATION, and have been studied by molecular dynamics simulations as well CITATION, CITATION. __label__MISC
Most studies so far treated the lipid bilayer as a template to exert its influences on the conformation and aggregation properties of peptides CITATION CITATION. __label__MISC
It will then be beneficial to understand the molecular details of how single lipid molecule influences the assembly process of amyloidogenic peptides which is the main focus of the current study. __label__AIMX
Besides the external factors, such as lipid bilayer, pH value, the sequences of peptide themselves have great effects on the aggregation behaviors. __label__MISC
Several other species such as non-human primates CITATION, cats CITATION, raccoons CITATION, and rodent species can produce IAPP, but the primary sequence of IAPP varies slightly among species. __label__MISC
Importantly, IAPP from rodent species, such as rat/mouse IAPP lose capacities of aggregating into amyloid fibrils CITATION, but transgenic mouse models that express human IAPP develop islet deposits CITATION. __label__MISC
The rIAPP differs from hIAPP in six amino acids and five of them are clustered in a short decapeptide, which is considered to be strongly amyloidogenic and forms similar unbranched fibrils itself to the full-length hIAPP CITATION, CITATION. __label__MISC
The three proline substitutions in rIAPP20 29 are believed to be highly responsible for the lacking of the amyloidogenic property of the segment or full-length peptide CITATION. __label__MISC
Although rIAPP has been intensively applied in experimental research acting as a potential peptide inhibitor for peptide aggregation CITATION, CITATION, the molecular mechanism of its resistance to amyloid is still not crystal clear. __label__CONT
Due to the metastable and short-lived nature of soluble pre-fibril oligomers at the early steps of fibril formation, experimental data are usually difficult to obtain CITATION, CITATION. __label__MISC
Thus, the computational approaches have been employed to complement experimental investigations to gain the insight into the aggregation mechanisms CITATION CITATION. __label__OWNX
Considering multiple copies of peptides needed due to the self-assembly nature of amyloid formation, various simplified representations of molecular systems using implicit solvent models were preferred rather than all-atom models. __label__OWNX
Santini et al. performed ART-OPEP simulations on trimer of A 16 22 by treating side chains as a bead and solvent implicitly CITATION. __label__MISC
A novel mechanism for single -strand to surmount unnatural registry without dissociation, referred to as reptation was proposed before experimental characterization CITATION. __label__MISC
Cheon et al. used ProFASi package to reduce the bonded potential energy to include torsional angles only and treated hydrogen bonds explicitly CITATION. __label__MISC
They observed early-stage events and obtained an atomic-detailed description of nucleated conformational conversion CITATION model for amyloid aggregation. __label__MISC
Albeit simplified models allow studying large-scale systems CITATION or observing more events in limited simulation time CITATION, all-atom explicit solvent models can reproduce amyloid aggregation in aqueous environment more accurately and supply more information on sidechain contacts CITATION. __label__MISC
Nguyen et al. prolonged a series of conventional MD simulations to 300 ns on A 16 22 of 3 6 oligomer size with explicit solvent CITATION. __label__MISC
The extensive simulations were able to probe the interpeptide sidechain contacts and large conformational fluctuations upon monomer addition to preformed -sheet oligomers in a dock-lock mechanism. __label__MISC
In our studies, an enhanced-sampling method, replica exchange molecular dynamics CITATION was implemented CITATION, and all water and peptide atoms are treated explicitly by applying OPLS-AA force field CITATION. __label__OWNX
The formation of -sheet containing tetramers, was observed within 100 ns ab initio REMD folding simulations. __label__OWNX
Simulation of four hIAPP peptides without lipid molecule was also performed. __label__OWNX
Nonamyloidogenic rat IAPP segments were studied as a negative control with the aim of understanding the inhibitory effect of three proline substitutions. __label__OWNX
Numerous psychophysical experiments found that humans preferably rely on a narrow band of spatial frequencies for recognition of face identity. __label__MISC
A recently conducted theoretical study by the author suggests that this frequency preference reflects an adaptation of the brain's face processing machinery to this specific stimulus class. __label__OWNX
The purpose of the present study is to examine this property in greater detail and to specifically elucidate the implication of internal face features. __label__OWNX
To this end, I parameterized Gabor filters to match the spatial receptive field of contrast sensitive neurons in the primary visual cortex. __label__OWNX
Filter responses to a large number of face images were computed, aligned for internal face features, and response-equalized. __label__OWNX
The results demonstrate that the frequency preference is caused by internal face features. __label__OWNX
Thus, the psychophysically observed human frequency bias for face processing seems to be specifically caused by the intrinsic spatial frequency content of internal face features. __label__OWNX
Taking advantage of these statistical regularities contributes to an optimal encoding of sensory signals in neuronal responses, in the sense that the code conveys the highest information with respect to specific constraints CITATION CITATION. __label__MISC
Among the various constraints which were formulated we find, for example, keeping metabolic energy consumption as low as possible CITATION CITATION, or keeping total wiring length between processing units at a minimum CITATION, or maximizing the suppression of spatio-temporal redundancy in the input signal CITATION, CITATION CITATION . __label__MISC
As for visual stimuli, natural images reveal a conspicuous statistical regularity that comes as an approximately linear decrease of their amplitude spectra as a function of spatial frequency CITATION CITATION. __label__MISC
This means that pairs of luminance values are strongly correlated CITATION, and this property could be exploited for gain controlling of visual neurons. __label__MISC
According to this response equalization hypothesis, gain should thus be incremented with increasing spatial frequency, such that the distribution of response amplitudes of frequency-tuned neurons to a typical natural image is flat. __label__MISC
An argument in favor of employing response equalization is that it would lead to an improvement of information transmission from one neuronal stage to another, because the output of one stage would match the limited dynamic range of a second one CITATION . __label__MISC
The present article builds upon previously reported results for whitened amplitude spectra of face images CITATION : the whitened spectra reveal a spatial frequency maximum at 10 15 cycles per face, but only if external face features are suppressed. __label__AIMX
The predicted frequency maximum nevertheless agrees well with numerous psychophysical experiments, which found that face identity is preferably processed in a narrow band of spatial frequencies from 8 to 16 cycles per face CITATION CITATION . __label__BASE
Despite of it all, the results presented in CITATION indicate that the maxima in the amplitude spectra are caused by the compound effect of horizontally oriented internal face features. __label__MISC
Quantitatively, the maxima thus occur in units of cycles per face height, whereas most psychophysical studies instead measure their results in terms of cycles per face width. __label__MISC
Furthermore, although a clear enhancement of horizontal amplitudes could be observed in the spectra, horizontal amplitudes showed a somewhat noisy dependence on spatial frequency. __label__MISC
Both effects are a consequence of that face features were not considered individually, what causes a mixing of the spatial frequency content of individual face features in the spectra. __label__MISC
The mixing leads to averaging-out effects such that any possible enhancement of spectral amplitudes at other than the horizontal orientation goes unnoticed, but also may cause interference effects which lead to the mentioned noisy dependence of amplitudes on spatial frequency. __label__MISC
The present study addresses the two issues by means of an extensive analysis of face images by means of Gabor filters. __label__OWNX
The filters were thereby parameterized to match the spatial receptive field of band-limited, oriented and contrast sensitive neurons in the primary visual cortex CITATION CITATION. __label__OWNX
Great care has been taken to guarantee the correct alignment of filter responses with respect to the position of internal face features prior to their averaging. __label__OWNX
Doing so permits to precisely elucidate how the frequency dependence of Gabor responses is related to each of the four internal face features. __label__OWNX
The resulting graphs of whitened Gabor amplitudes versus spatial frequency are smooth and reveal distinct maxima at nearly all orientations. __label__OWNX
The most stable maxima, however, are observed at horizontal feature orientations in the first place, but also at vertical orientations. __label__OWNX
This observation holds true for all of the internal face features. __label__OWNX
Numerous psychophysical experiments found that humans preferably rely on a narrow band of spatial frequencies for recognition of face identity. __label__MISC
To this end, I parameterized Gabor filters to match the spatial receptive field of contrast sensitive neurons in the primary visual cortex. __label__OWNX
The results demonstrate that the frequency preference is caused by internal face features. __label__OWNX
In the brain, the structure of neuronal circuits for processing sensory information matches the statistical properties of the sensory signals CITATION. __label__MISC
Taking advantage of these statistical regularities contributes to an optimal encoding of sensory signals in neuronal responses, in the sense that the code conveys the highest information with respect to specific constraints CITATION CITATION. __label__MISC
Among the various constraints which were formulated we find, for example, keeping metabolic energy consumption as low as possible CITATION CITATION, or keeping total wiring length between processing units at a minimum CITATION, or maximizing the suppression of spatio-temporal redundancy in the input signal CITATION, CITATION CITATION . __label__MISC
As for visual stimuli, natural images reveal a conspicuous statistical regularity that comes as an approximately linear decrease of their amplitude spectra as a function of spatial frequency CITATION CITATION. __label__MISC
Then, visual neurons would have equal sensitivities or response amplitudes independent of their spatial frequency preference CITATION. __label__MISC
According to this response equalization hypothesis, gain should thus be incremented with increasing spatial frequency, such that the distribution of response amplitudes of frequency-tuned neurons to a typical natural image is flat. __label__MISC
An argument in favor of employing response equalization is that it would lead to an improvement of information transmission from one neuronal stage to another, because the output of one stage would match the limited dynamic range of a second one CITATION . __label__MISC
The predicted frequency maximum nevertheless agrees well with numerous psychophysical experiments, which found that face identity is preferably processed in a narrow band of spatial frequencies from 8 to 16 cycles per face CITATION CITATION . __label__MISC
Despite of it all, the results presented in CITATION indicate that the maxima in the amplitude spectra are caused by the compound effect of horizontally oriented internal face features. __label__MISC
Quantitatively, the maxima thus occur in units of cycles per face height, whereas most psychophysical studies instead measure their results in terms of cycles per face width. __label__MISC
Furthermore, although a clear enhancement of horizontal amplitudes could be observed in the spectra, horizontal amplitudes showed a somewhat noisy dependence on spatial frequency. __label__MISC
Both effects are a consequence of that face features were not considered individually, what causes a mixing of the spatial frequency content of individual face features in the spectra. __label__MISC
The mixing leads to averaging-out effects such that any possible enhancement of spectral amplitudes at other than the horizontal orientation goes unnoticed, but also may cause interference effects which lead to the mentioned noisy dependence of amplitudes on spatial frequency. __label__MISC
The present study addresses the two issues by means of an extensive analysis of face images by means of Gabor filters. __label__AIMX
Great care has been taken to guarantee the correct alignment of filter responses with respect to the position of internal face features prior to their averaging. __label__OWNX
The resulting graphs of whitened Gabor amplitudes versus spatial frequency are smooth and reveal distinct maxima at nearly all orientations. __label__OWNX
The most stable maxima, however, are observed at horizontal feature orientations in the first place, but also at vertical orientations. __label__OWNX
This observation holds true for all of the internal face features. __label__OWNX
The present study therefore shows how the individual internal face features contribute to the psychophysically observed frequency preference, and proposes concrete mechanisms of how higher amplitudes of whitened cell responses at an early level could possibly lead to the psychophysically measured effects. __label__OWNX
Numerous psychophysical experiments found that humans preferably rely on a narrow band of spatial frequencies for recognition of face identity. __label__MISC
A recently conducted theoretical study by the author suggests that this frequency preference reflects an adaptation of the brain's face processing machinery to this specific stimulus class. __label__MISC
To this end, I parameterized Gabor filters to match the spatial receptive field of contrast sensitive neurons in the primary visual cortex. __label__OWNX
Filter responses to a large number of face images were computed, aligned for internal face features, and response-equalized. __label__OWNX
The results demonstrate that the frequency preference is caused by internal face features. __label__OWNX
Thus, the psychophysically observed human frequency bias for face processing seems to be specifically caused by the intrinsic spatial frequency content of internal face features. __label__OWNX
In the brain, the structure of neuronal circuits for processing sensory information matches the statistical properties of the sensory signals CITATION. __label__MISC
Taking advantage of these statistical regularities contributes to an optimal encoding of sensory signals in neuronal responses, in the sense that the code conveys the highest information with respect to specific constraints CITATION CITATION. __label__MISC
Among the various constraints which were formulated we find, for example, keeping metabolic energy consumption as low as possible CITATION CITATION, or keeping total wiring length between processing units at a minimum CITATION, or maximizing the suppression of spatio-temporal redundancy in the input signal CITATION, CITATION CITATION . __label__OWNX
As for visual stimuli, natural images reveal a conspicuous statistical regularity that comes as an approximately linear decrease of their amplitude spectra as a function of spatial frequency CITATION CITATION. __label__MISC
This means that pairs of luminance values are strongly correlated CITATION, and this property could be exploited for gain controlling of visual neurons. __label__MISC
According to this response equalization hypothesis, gain should thus be incremented with increasing spatial frequency, such that the distribution of response amplitudes of frequency-tuned neurons to a typical natural image is flat. __label__MISC
An argument in favor of employing response equalization is that it would lead to an improvement of information transmission from one neuronal stage to another, because the output of one stage would match the limited dynamic range of a second one CITATION . __label__MISC
The present article builds upon previously reported results for whitened amplitude spectra of face images CITATION : the whitened spectra reveal a spatial frequency maximum at 10 15 cycles per face, but only if external face features are suppressed. __label__BASE
The predicted frequency maximum nevertheless agrees well with numerous psychophysical experiments, which found that face identity is preferably processed in a narrow band of spatial frequencies from 8 to 16 cycles per face CITATION CITATION . __label__MISC
Despite of it all, the results presented in CITATION indicate that the maxima in the amplitude spectra are caused by the compound effect of horizontally oriented internal face features. __label__MISC
Quantitatively, the maxima thus occur in units of cycles per face height, whereas most psychophysical studies instead measure their results in terms of cycles per face width. __label__MISC
Furthermore, although a clear enhancement of horizontal amplitudes could be observed in the spectra, horizontal amplitudes showed a somewhat noisy dependence on spatial frequency. __label__MISC
Both effects are a consequence of that face features were not considered individually, what causes a mixing of the spatial frequency content of individual face features in the spectra. __label__MISC
The mixing leads to averaging-out effects such that any possible enhancement of spectral amplitudes at other than the horizontal orientation goes unnoticed, but also may cause interference effects which lead to the mentioned noisy dependence of amplitudes on spatial frequency. __label__MISC
The present study addresses the two issues by means of an extensive analysis of face images by means of Gabor filters. __label__AIMX
Great care has been taken to guarantee the correct alignment of filter responses with respect to the position of internal face features prior to their averaging. __label__OWNX
Doing so permits to precisely elucidate how the frequency dependence of Gabor responses is related to each of the four internal face features. __label__MISC
The resulting graphs of whitened Gabor amplitudes versus spatial frequency are smooth and reveal distinct maxima at nearly all orientations. __label__OWNX
The most stable maxima, however, are observed at horizontal feature orientations in the first place, but also at vertical orientations. __label__OWNX
This observation holds true for all of the internal face features. __label__OWNX
The firing rate of single neurons in the mammalian hippocampus has been demonstrated to encode for a range of spatial and non-spatial stimuli. __label__MISC
It has also been demonstrated that phase of firing, with respect to the theta oscillation that dominates the hippocampal EEG during stereotype learning behaviour, correlates with an animal's spatial location. __label__MISC
These findings have led to the hypothesis that the hippocampus operates using a dual coding system. __label__MISC
We demonstrate that this plasticity rule can generate both symmetric and asymmetric connections between neurons that fire at concurrent or successive theta phase, respectively, and subsequently produce both pattern completion and sequence prediction from partial cues. __label__AIMX
This unifies previously disparate auto- and hetero-associative network models of hippocampal function and provides them with a firmer basis in modern neurobiology. __label__BASE
Furthermore, the encoding and reactivation of activity in mutually exciting Hebbian cell assemblies demonstrated here is believed to represent a fundamental mechanism of cognitive processing in the brain. __label__OWNX
The hippocampus and surrounding medial temporal lobe are implicated in declarative memory function in humans and other mammals CITATION. __label__MISC
Electrophysiology studies in a range of species have demonstrated that the activity of single pyramidal cells within this region can encode for the presence of both spatial and non-spatial stimuli CITATION. __label__MISC
The majority of empirical investigation has focussed on place cells neurons whose firing rate is directly correlated with an animal's spatial location within the corresponding place field CITATION. __label__MISC
Subsequent research has identified similar single cell responses to a variety of non-spatial cues including odour CITATION, complex visual images CITATION, CITATION, CITATION, running speed CITATION and the concept of a bed or nest CITATION. __label__MISC
It has also been demonstrated that the exact timing of place cell discharge, relative to the theta oscillation which dominates the hippocampal EEG during learning, correlates with distance travelled through a place field CITATION, CITATION, CITATION CITATION. __label__MISC
These findings have led to the hypothesis that the hippocampus operates using a dual rate and temporal coding system CITATION, CITATION. __label__MISC
Here we present a spiking neural network model which utilises a dual coding system in order to encode and recall both symmetric and asymmetric connections between neurons that exhibit repeated synchronous and asynchronous firing patterns respectively. __label__OWNX
The postulated mnemonic function of the hippocampus has been extensively modelled using recurrent neural networks, and this approach is supported by empirical data CITATION CITATION. __label__MISC
The biological correlate of these models is widely believed to be the CA3 region, which exhibits dense recurrent connectivity and wherein synaptic plasticity can be easily and reliably induced. __label__MISC
Pharmacological and genetic knockout studies have demonstrated that NMDAr-dependent synaptic plasticity in CA3 is critical for the rapid encoding of novel information, and synaptic output from CA3 critical for its retrieval CITATION, CITATION. __label__MISC
Recurrent neural network models of hippocampal mnemonic function have generally utilised rate-coded Hebbian learning rules to generate reciprocal associations between neurons with concurrently elevated firing rates CITATION, CITATION. __label__MISC
Hypothetically, this corresponds to the presence of either multiple stimuli or multiple overlapping place fields encountered at a single location CITATION CITATION. __label__MISC
The hippocampus is also implicated in sequence learning, and temporally asymmetric plasticity rules have subsequently been employed in recurrent network models to generate hetero-associative connections between neurons that fire with repeated temporal correlation CITATION CITATION. __label__MISC
Hypothetically, this corresponds to a sequence of place fields being traversed or stimuli being encountered on a behavioural timescale CITATION. __label__MISC
Importantly, previous computational models of hetero-associative learning have typically encoded each successive stage of a learned sequence with the activity of a single neuron, while empirical studies estimate that place fields are typically encoded by an ensemble of several hundred place cells CITATION, CITATION CITATION. __label__MISC
No computational model has thus far integrated auto- and hetero- associative learning in order to simultaneously generate both bi-directional and asymmetric connections between neurons that are active at the same and successive theta phases respectively using a single temporally asymmetric synaptic plasticity rule. __label__CONT
It is not yet clear if rate-coded auto-associative network models of hippocampal mnemonic function are compatible with STDP or theta coded neural dynamics. __label__MISC
Here, we examine the synaptic dynamics generated by several different STDP rules in a spiking recurrent neural network model of CA3 during the encoding of temporal, rate and dual coded activity patterns created by a phenomenological model of phase precession. __label__AIMX
We demonstrate that under certain conditions - the STDP rule can generate both bi-directional connections between neurons which burst at concurrent theta phase and asymmetric connections between neurons which fire at consecutive theta phase. __label__OWNX
Interestingly, these neural dynamics are reminiscent of sharp wave ripple activity observed in vivo CITATION CITATION. __label__OWNX
These findings demonstrate that STDP and theta coded neural dynamics are compatible with rate-coded auto-associative network models of hippocampal function. __label__OWNX
It has also been demonstrated that phase of firing, with respect to the theta oscillation that dominates the hippocampal EEG during stereotype learning behaviour, correlates with an animal's spatial location. __label__MISC
To investigate the phenomenon of dual coding in the hippocampus, we examine a spiking recurrent network model with theta coded neural dynamics and an STDP rule that mediates rate-coded Hebbian learning when pre- and post-synaptic firing is stochastic. __label__OWNX
We demonstrate that this plasticity rule can generate both symmetric and asymmetric connections between neurons that fire at concurrent or successive theta phase, respectively, and subsequently produce both pattern completion and sequence prediction from partial cues. __label__AIMX
This unifies previously disparate auto- and hetero-associative network models of hippocampal function and provides them with a firmer basis in modern neurobiology. __label__BASE
Furthermore, the encoding and reactivation of activity in mutually exciting Hebbian cell assemblies demonstrated here is believed to represent a fundamental mechanism of cognitive processing in the brain. __label__OWNX
The hippocampus and surrounding medial temporal lobe are implicated in declarative memory function in humans and other mammals CITATION. __label__MISC
Electrophysiology studies in a range of species have demonstrated that the activity of single pyramidal cells within this region can encode for the presence of both spatial and non-spatial stimuli CITATION. __label__MISC
The majority of empirical investigation has focussed on place cells neurons whose firing rate is directly correlated with an animal's spatial location within the corresponding place field CITATION. __label__MISC
Subsequent research has identified similar single cell responses to a variety of non-spatial cues including odour CITATION, complex visual images CITATION, CITATION, CITATION, running speed CITATION and the concept of a bed or nest CITATION. __label__MISC
It has also been demonstrated that the exact timing of place cell discharge, relative to the theta oscillation which dominates the hippocampal EEG during learning, correlates with distance travelled through a place field CITATION, CITATION, CITATION CITATION. __label__MISC
Here we present a spiking neural network model which utilises a dual coding system in order to encode and recall both symmetric and asymmetric connections between neurons that exhibit repeated synchronous and asynchronous firing patterns respectively. __label__OWNX
The postulated mnemonic function of the hippocampus has been extensively modelled using recurrent neural networks, and this approach is supported by empirical data CITATION CITATION. __label__MISC
The biological correlate of these models is widely believed to be the CA3 region, which exhibits dense recurrent connectivity and wherein synaptic plasticity can be easily and reliably induced. __label__MISC
Pharmacological and genetic knockout studies have demonstrated that NMDAr-dependent synaptic plasticity in CA3 is critical for the rapid encoding of novel information, and synaptic output from CA3 critical for its retrieval CITATION, CITATION. __label__MISC
Recurrent neural network models of hippocampal mnemonic function have generally utilised rate-coded Hebbian learning rules to generate reciprocal associations between neurons with concurrently elevated firing rates CITATION, CITATION. __label__MISC
Hypothetically, this corresponds to a sequence of place fields being traversed or stimuli being encountered on a behavioural timescale CITATION. __label__MISC
It is not yet clear if rate-coded auto-associative network models of hippocampal mnemonic function are compatible with STDP or theta coded neural dynamics. __label__MISC
Here, we examine the synaptic dynamics generated by several different STDP rules in a spiking recurrent neural network model of CA3 during the encoding of temporal, rate and dual coded activity patterns created by a phenomenological model of phase precession. __label__AIMX
We demonstrate that under certain conditions - the STDP rule can generate both bi-directional connections between neurons which burst at concurrent theta phase and asymmetric connections between neurons which fire at consecutive theta phase. __label__OWNX
Subsequent superthreshold stimulation of a small number of simulated neurons generates putative recall activity, driven by recurrent excitation, that corresponds to pattern completion and/or sequence prediction in auto- and/or hetero- associative connections respectively. __label__OWNX
These findings demonstrate that STDP and theta coded neural dynamics are compatible with rate-coded auto-associative network models of hippocampal function. __label__OWNX
The firing rate of single neurons in the mammalian hippocampus has been demonstrated to encode for a range of spatial and non-spatial stimuli. __label__MISC
It has also been demonstrated that phase of firing, with respect to the theta oscillation that dominates the hippocampal EEG during stereotype learning behaviour, correlates with an animal's spatial location. __label__MISC
We demonstrate that this plasticity rule can generate both symmetric and asymmetric connections between neurons that fire at concurrent or successive theta phase, respectively, and subsequently produce both pattern completion and sequence prediction from partial cues. __label__OWNX
This unifies previously disparate auto- and hetero-associative network models of hippocampal function and provides them with a firmer basis in modern neurobiology. __label__OWNX
Furthermore, the encoding and reactivation of activity in mutually exciting Hebbian cell assemblies demonstrated here is believed to represent a fundamental mechanism of cognitive processing in the brain. __label__MISC
The hippocampus and surrounding medial temporal lobe are implicated in declarative memory function in humans and other mammals CITATION. __label__MISC
It has also been demonstrated that the exact timing of place cell discharge, relative to the theta oscillation which dominates the hippocampal EEG during learning, correlates with distance travelled through a place field CITATION, CITATION, CITATION CITATION. __label__MISC
These findings have led to the hypothesis that the hippocampus operates using a dual rate and temporal coding system CITATION, CITATION. __label__MISC
The postulated mnemonic function of the hippocampus has been extensively modelled using recurrent neural networks, and this approach is supported by empirical data CITATION CITATION. __label__MISC
The biological correlate of these models is widely believed to be the CA3 region, which exhibits dense recurrent connectivity and wherein synaptic plasticity can be easily and reliably induced. __label__MISC
Pharmacological and genetic knockout studies have demonstrated that NMDAr-dependent synaptic plasticity in CA3 is critical for the rapid encoding of novel information, and synaptic output from CA3 critical for its retrieval CITATION, CITATION. __label__MISC
Hypothetically, this corresponds to the presence of either multiple stimuli or multiple overlapping place fields encountered at a single location CITATION CITATION. __label__MISC
The hippocampus is also implicated in sequence learning, and temporally asymmetric plasticity rules have subsequently been employed in recurrent network models to generate hetero-associative connections between neurons that fire with repeated temporal correlation CITATION CITATION. __label__MISC
Hypothetically, this corresponds to a sequence of place fields being traversed or stimuli being encountered on a behavioural timescale CITATION. __label__MISC
Empirical data indicates that changes in the strength of synapses within the hippocampus can depend upon temporal correlations in pre- and post- synaptic firing according to a spike-timing dependent plasticity rule CITATION CITATION. __label__MISC
It is not yet clear if rate-coded auto-associative network models of hippocampal mnemonic function are compatible with STDP or theta coded neural dynamics. __label__MISC
Here, we examine the synaptic dynamics generated by several different STDP rules in a spiking recurrent neural network model of CA3 during the encoding of temporal, rate and dual coded activity patterns created by a phenomenological model of phase precession. __label__AIMX
We demonstrate that under certain conditions - the STDP rule can generate both bi-directional connections between neurons which burst at concurrent theta phase and asymmetric connections between neurons which fire at consecutive theta phase. __label__OWNX
Subsequent superthreshold stimulation of a small number of simulated neurons generates putative recall activity, driven by recurrent excitation, that corresponds to pattern completion and/or sequence prediction in auto- and/or hetero- associative connections respectively. __label__OWNX
Interestingly, these neural dynamics are reminiscent of sharp wave ripple activity observed in vivo CITATION CITATION. __label__MISC
These findings demonstrate that STDP and theta coded neural dynamics are compatible with rate-coded auto-associative network models of hippocampal function. __label__OWNX
Furthermore, the encoding and reactivation of dual coded Hebbian phase sequences of activity in mutually exciting neuronal ensembles demonstrated here has been proposed as a general neural coding mechanism for cognitive processing CITATION, CITATION CITATION . __label__OWNX
Metabolic network reconstructions represent valuable scaffolds for -omics data integration and are used to computationally interrogate network properties. __label__MISC
However, they do not explicitly account for the synthesis of macromolecules. __label__MISC
Here, we present the first genome-scale, fine-grained reconstruction of Escherichia coli's transcriptional and translational machinery, which produces 423 functional gene products in a sequence-specific manner and accounts for all necessary chemical transformations. __label__OWNX
Legacy data from over 500 publications and three databases were reviewed, and many pathways were considered, including stable RNA maturation and modification, protein complex formation, and iron sulfur cluster biogenesis. __label__BASE
This reconstruction represents the most comprehensive knowledge base for these important cellular functions in E. coli and is unique in its scope. __label__OWNX
Furthermore, it was converted into a mathematical model and used to: quantitatively integrate gene expression data as reaction constraints and compute functional network states, which were compared to reported experimental data. __label__OWNX
For example, the model predicted accurately the ribosome production, without any parameterization. __label__OWNX
Also, in silico rRNA operon deletion suggested that a high RNA polymerase density on the remaining rRNA operons is needed to reproduce the reported experimental ribosome numbers. __label__OWNX
This genome-scale reconstruction of E. coli's transcriptional and translational machinery presents a milestone in systems biology because it will enable quantitative integration of -omics datasets and thus the study of the mechanistic principles underlying the genotype phenotype relationship. __label__OWNX
High-throughput experimental technologies enable the production of heterogeneous data, such as expression profiles and proteomic data, for almost any organism of interest. __label__MISC
A detailed mathematical representation of the in vivo cellular network is required to obtain a holistic understanding of cellular processes from these data sets and to quantitatively integrate them into a biological context. __label__MISC
One such approach is the bottom-up network reconstruction, which builds manually networks in a brick-by-brick manner using genome annotation and component-specific information CITATION, CITATION. __label__MISC
This reconstruction procedure is well established for metabolic reaction networks and has been applied to many organisms, including Human CITATION, Saccharomyces cerevisiae CITATION, CITATION, Leishmani major CITATION, Escherichia coli CITATION, Helicobacter pylori CITATION, Pseudomonas aeruginosa CITATION, and Pseudomonas putida CITATION, CITATION . __label__MISC
These bottom-up metabolic networks differ from other network reconstructions as they are tailored to the genomic content of the target organism and built manually using biochemical, physiological, and other experimental information in addition to the genome annotation. __label__MISC
The reconstruction and modeling procedure is a 4-step process: obtaining a draft reaction list based on genome annotation and biochemical databases, refinement of reaction list using experimental information, conversion of the reaction list into a computable format and application of systems boundaries to define condition-specific models, and the evaluation and validation of the model content using various mathematical methods. __label__MISC
By iterating step 2 to 4, reconstructions that are self-consistent within their defined scope can be generated. __label__MISC
Metabolic network reconstruction have demonstrated to be useful in at least 5 areas of applications CITATION : biological discovery CITATION, phenotypic behavior CITATION, bacterial evolution CITATION, network analysis CITATION, and metabolic engineering CITATION. __label__MISC
This wide range of applications of the metabolic reconstructions is possible because they can be readily converted into predictive, condition-specific models. __label__MISC
Unlike more traditional approaches to modeling metabolism, the constraint-based modeling approach requires few, if any, parameters CITATION, CITATION. __label__MISC
The stoichiometric information encoded in the reconstruction can be represented mathematically as a stoichiometric matrix, S, where the rows correspond to the components and the columns correspond to the reactions . __label__MISC
This reconstruction enables quantitative integration of high-throughput data such as gene expression, proteomic, and mRNA degradation data. __label__OWNX
Moreover, proteins are produced in high copy numbers in growing cells; thus, any quantitative mechanistic modeling and analysis of high-throughput data needs to account for the synthesis cost associated with these molecules. __label__OWNX
Numerous studies have been published that investigate protein synthesis using kinetic models CITATION CITATION. __label__MISC
These models are generally tailored to the questions they address making it difficult to readily apply them for modified problems. __label__CONT
Since stoichiometric relationships are a common requisite for any type of mechanistic modeling, organism-specific BiGG knowledge bases can be used as templates to derive problem-specific, mechanistic models. __label__MISC
In fact, network stoichiometry is a dominant feature of kinetic models as well CITATION. __label__MISC
In this study, we present a new generation of network reconstructions, which directly account for the synthesis of individual mRNA and proteins. __label__AIMX
We named the mathematical representation of this reconstruction the Expression matrix, or E-matrix, since it encodes the expression of mRNA and proteins. __label__OWNX
All network reactions were formulated to account for gene-specific and E. coli-specific details, such as nucleotide composition, operon association, and sigma factor usage. __label__OWNX
This reconstruction is the first comprehensive database detailing the available information for these cellular functions and can thus be deemed a knowledge base. __label__OWNX
After conversion of the E-matrix reconstruction into condition-specific models corresponding to different doubling times, we were able to accurately predict the ribosome production reported in literature, without any parameterization. __label__OWNX
Furthermore, we show that the E-matrix can be used to study the effect of rRNA operon deletion. __label__OWNX
Our results predict that a high density of RNA polymerases is required on the remaining rRNA operons, to achieve the reported ribosome numbers. __label__OWNX
Finally, we show that proteins used in the E-matrix could be grouped into functional modules which lead to a more simplified view of the network. __label__OWNX
Metabolic network reconstructions represent valuable scaffolds for -omics data integration and are used to computationally interrogate network properties. __label__MISC
However, they do not explicitly account for the synthesis of macromolecules. __label__MISC
Here, we present the first genome-scale, fine-grained reconstruction of Escherichia coli's transcriptional and translational machinery, which produces 423 functional gene products in a sequence-specific manner and accounts for all necessary chemical transformations. __label__OWNX
Legacy data from over 500 publications and three databases were reviewed, and many pathways were considered, including stable RNA maturation and modification, protein complex formation, and iron sulfur cluster biogenesis. __label__BASE
Furthermore, it was converted into a mathematical model and used to: quantitatively integrate gene expression data as reaction constraints and compute functional network states, which were compared to reported experimental data. __label__OWNX
For example, the model predicted accurately the ribosome production, without any parameterization. __label__OWNX
Also, in silico rRNA operon deletion suggested that a high RNA polymerase density on the remaining rRNA operons is needed to reproduce the reported experimental ribosome numbers. __label__OWNX
Moreover, functional protein modules were determined, and many were found to contain gene products from multiple subsystems, highlighting the functional interaction of these proteins. __label__OWNX
This genome-scale reconstruction of E. coli's transcriptional and translational machinery presents a milestone in systems biology because it will enable quantitative integration of -omics datasets and thus the study of the mechanistic principles underlying the genotype phenotype relationship. __label__OWNX
High-throughput experimental technologies enable the production of heterogeneous data, such as expression profiles and proteomic data, for almost any organism of interest. __label__MISC
A detailed mathematical representation of the in vivo cellular network is required to obtain a holistic understanding of cellular processes from these data sets and to quantitatively integrate them into a biological context. __label__MISC
One such approach is the bottom-up network reconstruction, which builds manually networks in a brick-by-brick manner using genome annotation and component-specific information CITATION, CITATION. __label__MISC
This reconstruction procedure is well established for metabolic reaction networks and has been applied to many organisms, including Human CITATION, Saccharomyces cerevisiae CITATION, CITATION, Leishmani major CITATION, Escherichia coli CITATION, Helicobacter pylori CITATION, Pseudomonas aeruginosa CITATION, and Pseudomonas putida CITATION, CITATION . __label__MISC
These bottom-up metabolic networks differ from other network reconstructions as they are tailored to the genomic content of the target organism and built manually using biochemical, physiological, and other experimental information in addition to the genome annotation. __label__MISC
Hence, these reconstructions can be thought of as biochemically, genetically, and genomically structured knowledge bases CITATION. __label__MISC
The reconstruction and modeling procedure is a 4-step process: obtaining a draft reaction list based on genome annotation and biochemical databases, refinement of reaction list using experimental information, conversion of the reaction list into a computable format and application of systems boundaries to define condition-specific models, and the evaluation and validation of the model content using various mathematical methods. __label__MISC
By iterating step 2 to 4, reconstructions that are self-consistent within their defined scope can be generated. __label__MISC
Metabolic network reconstruction have demonstrated to be useful in at least 5 areas of applications CITATION : biological discovery CITATION, phenotypic behavior CITATION, bacterial evolution CITATION, network analysis CITATION, and metabolic engineering CITATION. __label__MISC
This wide range of applications of the metabolic reconstructions is possible because they can be readily converted into predictive, condition-specific models. __label__MISC
Unlike more traditional approaches to modeling metabolism, the constraint-based modeling approach requires few, if any, parameters CITATION, CITATION. __label__MISC
While the COBRA approach has been successfully applied to metabolic networks, the same principles and assumptions can be also employed to reconstruct and model other cellular functions, such as signaling CITATION CITATION, regulation CITATION, and protein synthesis CITATION. __label__MISC
In this study, we extended and refined earlier work by Allen et al., which proposed a stoichiometric formalism to model protein synthesis and illustrated it on some E. coli genes and operons CITATION. __label__BASE
We created a more detailed, gene-specific representation of the transcriptional and translational processes, which explicitly accounts for the sequence-specific synthesis of DNA, mRNA, and proteins. __label__OWNX
This reconstruction enables quantitative integration of high-throughput data such as gene expression, proteomic, and mRNA degradation data. __label__OWNX
Moreover, proteins are produced in high copy numbers in growing cells; thus, any quantitative mechanistic modeling and analysis of high-throughput data needs to account for the synthesis cost associated with these molecules. __label__OWNX
Numerous studies have been published that investigate protein synthesis using kinetic models CITATION CITATION. __label__MISC
These models are generally tailored to the questions they address making it difficult to readily apply them for modified problems. __label__CONT
In fact, network stoichiometry is a dominant feature of kinetic models as well CITATION. __label__MISC
Thus, network reconstruction serves as a platform for steady-state and kinetic modeling . __label__MISC
In this study, we present a new generation of network reconstructions, which directly account for the synthesis of individual mRNA and proteins. __label__AIMX
Furthermore, we used information from three databases and more than 500 scientific publications to formulate mechanistically detailed and accurate reactions. __label__OWNX
This reconstruction is the first comprehensive database detailing the available information for these cellular functions and can thus be deemed a knowledge base. __label__OWNX
Furthermore, we show that the E-matrix can be used to study the effect of rRNA operon deletion. __label__OWNX
Our results predict that a high density of RNA polymerases is required on the remaining rRNA operons, to achieve the reported ribosome numbers. __label__OWNX
Finally, we show that proteins used in the E-matrix could be grouped into functional modules which lead to a more simplified view of the network. __label__OWNX
Metabolic network reconstructions represent valuable scaffolds for -omics data integration and are used to computationally interrogate network properties. __label__MISC
However, they do not explicitly account for the synthesis of macromolecules. __label__CONT
Here, we present the first genome-scale, fine-grained reconstruction of Escherichia coli's transcriptional and translational machinery, which produces 423 functional gene products in a sequence-specific manner and accounts for all necessary chemical transformations. __label__AIMX
This reconstruction represents the most comprehensive knowledge base for these important cellular functions in E. coli and is unique in its scope. __label__OWNX
Furthermore, it was converted into a mathematical model and used to: quantitatively integrate gene expression data as reaction constraints and compute functional network states, which were compared to reported experimental data. __label__AIMX
For example, the model predicted accurately the ribosome production, without any parameterization. __label__OWNX
Moreover, functional protein modules were determined, and many were found to contain gene products from multiple subsystems, highlighting the functional interaction of these proteins. __label__OWNX
High-throughput experimental technologies enable the production of heterogeneous data, such as expression profiles and proteomic data, for almost any organism of interest. __label__MISC
A detailed mathematical representation of the in vivo cellular network is required to obtain a holistic understanding of cellular processes from these data sets and to quantitatively integrate them into a biological context. __label__MISC
One such approach is the bottom-up network reconstruction, which builds manually networks in a brick-by-brick manner using genome annotation and component-specific information CITATION, CITATION. __label__MISC
This reconstruction procedure is well established for metabolic reaction networks and has been applied to many organisms, including Human CITATION, Saccharomyces cerevisiae CITATION, CITATION, Leishmani major CITATION, Escherichia coli CITATION, Helicobacter pylori CITATION, Pseudomonas aeruginosa CITATION, and Pseudomonas putida CITATION, CITATION . __label__MISC
These bottom-up metabolic networks differ from other network reconstructions as they are tailored to the genomic content of the target organism and built manually using biochemical, physiological, and other experimental information in addition to the genome annotation. __label__MISC
Hence, these reconstructions can be thought of as biochemically, genetically, and genomically structured knowledge bases CITATION. __label__MISC
The reconstruction and modeling procedure is a 4-step process: obtaining a draft reaction list based on genome annotation and biochemical databases, refinement of reaction list using experimental information, conversion of the reaction list into a computable format and application of systems boundaries to define condition-specific models, and the evaluation and validation of the model content using various mathematical methods. __label__MISC
By iterating step 2 to 4, reconstructions that are self-consistent within their defined scope can be generated. __label__MISC
Metabolic network reconstruction have demonstrated to be useful in at least 5 areas of applications CITATION : biological discovery CITATION, phenotypic behavior CITATION, bacterial evolution CITATION, network analysis CITATION, and metabolic engineering CITATION. __label__MISC
This wide range of applications of the metabolic reconstructions is possible because they can be readily converted into predictive, condition-specific models. __label__MISC
Unlike more traditional approaches to modeling metabolism, the constraint-based modeling approach requires few, if any, parameters CITATION, CITATION. __label__CONT
While the COBRA approach has been successfully applied to metabolic networks, the same principles and assumptions can be also employed to reconstruct and model other cellular functions, such as signaling CITATION CITATION, regulation CITATION, and protein synthesis CITATION. __label__MISC
In this study, we extended and refined earlier work by Allen et al., which proposed a stoichiometric formalism to model protein synthesis and illustrated it on some E. coli genes and operons CITATION. __label__BASE
We created a more detailed, gene-specific representation of the transcriptional and translational processes, which explicitly accounts for the sequence-specific synthesis of DNA, mRNA, and proteins. __label__OWNX
This reconstruction enables quantitative integration of high-throughput data such as gene expression, proteomic, and mRNA degradation data. __label__OWNX
Moreover, proteins are produced in high copy numbers in growing cells; thus, any quantitative mechanistic modeling and analysis of high-throughput data needs to account for the synthesis cost associated with these molecules. __label__MISC
These models are generally tailored to the questions they address making it difficult to readily apply them for modified problems. __label__CONT
Since stoichiometric relationships are a common requisite for any type of mechanistic modeling, organism-specific BiGG knowledge bases can be used as templates to derive problem-specific, mechanistic models. __label__MISC
In fact, network stoichiometry is a dominant feature of kinetic models as well CITATION. __label__MISC
Thus, network reconstruction serves as a platform for steady-state and kinetic modeling . __label__MISC
In this study, we present a new generation of network reconstructions, which directly account for the synthesis of individual mRNA and proteins. __label__AIMX
We named the mathematical representation of this reconstruction the Expression matrix, or E-matrix, since it encodes the expression of mRNA and proteins. __label__OWNX
All network reactions were formulated to account for gene-specific and E. coli-specific details, such as nucleotide composition, operon association, and sigma factor usage. __label__OWNX
Furthermore, we used information from three databases and more than 500 scientific publications to formulate mechanistically detailed and accurate reactions. __label__OWNX
This reconstruction is the first comprehensive database detailing the available information for these cellular functions and can thus be deemed a knowledge base. __label__OWNX
After conversion of the E-matrix reconstruction into condition-specific models corresponding to different doubling times, we were able to accurately predict the ribosome production reported in literature, without any parameterization. __label__OWNX
Furthermore, we show that the E-matrix can be used to study the effect of rRNA operon deletion. __label__OWNX
Our results predict that a high density of RNA polymerases is required on the remaining rRNA operons, to achieve the reported ribosome numbers. __label__OWNX
Finally, we show that proteins used in the E-matrix could be grouped into functional modules which lead to a more simplified view of the network. __label__OWNX
Neuronal activity is mediated through changes in the probability of stochastic transitions between open and closed states of ion channels. __label__MISC
While differences in morphology define neuronal cell types and may underlie neurological disorders, very little is known about influences of stochastic ion channel gating in neurons with complex morphology. __label__MISC
Comparison of five morphologically distinct neuronal cell types reveals that when all simulated neurons contain identical densities of stochastic ion channels, the amplitude of stochastic membrane potential fluctuations differs between cell types and depends on sub-cellular location. __label__OWNX
For typical neurons, the amplitude of membrane potential fluctuations depends on channel kinetics as well as open probability. __label__OWNX
Using a detailed model of a hippocampal CA1 pyramidal neuron, we show that when intrinsic ion channels gate stochastically, the probability of initiation of dendritic or somatic spikes by dendritic synaptic input varies continuously between zero and one, whereas when ion channels gate deterministically, the probability is either zero or one. __label__OWNX
At physiological firing rates, stochastic gating of dendritic ion channels almost completely accounts for probabilistic somatic and dendritic spikes generated by the fully stochastic model. __label__OWNX
Whereas dendritic neurons are often assumed to behave deterministically, our simulations suggest that a direct consequence of stochastic gating of intrinsic ion channels is that spike output may instead be a probabilistic function of patterns of synaptic input to dendrites. __label__OWNX
The appropriate level of physical detail required to understand how complex processes such as cognition and behavior emerge from more simple biological structures is unclear CITATION, CITATION. __label__MISC
For example, while it is possible to account for certain aspects of nervous system function using models that represent each neuron as a simple integrate and fire device, it is increasingly clear that this approach does not capture the full range of computations that many real neurons carry out CITATION, CITATION. __label__CONT
Dendritic and axonal morphology are defining features of neuronal cell types and have important influences on the computations that a neuron performs CITATION. __label__MISC
Cable theory and compartmental modeling provide a foundation for predicting the propagation of electrical signals in the dendrites and axons of neurons CITATION, CITATION. __label__BASE
However, while the assumption that transitions between open and closed states of ion channels can be treated as a deterministic process may be sufficient for some purposes, recent evidence suggests that stochastic transitions between the states of individual ion channels could influence computations carried out by neurons CITATION CITATION. __label__MISC
While cable theory suggests that fluctuations of this kind might be particularly important in fine structures such as axons and dendrites CITATION, we nevertheless know very little about how neuronal morphology and stochastic gating of ion channels interact to determine how neurons respond to synaptic input. __label__CONT
Given the difficulty of reducing detailed morphological models to simple analytical forms that could also incorporate stochastic gating of individual ion channels CITATION, experimentally constrained numerical simulations will be important to enable these issues to be explored systematically. __label__MISC
Investigation of stochastic ion channel gating using numerical simulations has been limited by trades-offs between simulation accuracy and computation time CITATION. __label__CONT
A simple approach is to add noise sources to deterministic models. __label__MISC
However, as ion channels have multiple functional states with transitions that often depend on the membrane voltage CITATION, CITATION, CITATION, CITATION, this may not accurately account for the noise introduced by ion channel currents. __label__CONT
A more accurate alternative is to explicitly model transitions between different functional states for each ion channel on a neuron's membrane. __label__MISC
However, for neurons with complex axonal or dendritic architectures there are two substantial obstacles to this approach. __label__CONT
First, typical central neurons express large numbers of ion channels and simulations must be repeated many times to obtain statistically valid descriptions CITATION. __label__CONT
Second, each neuronal ion channel occupies a specific location on the extra-cellular membrane, whereas most neuronal models represent the distribution of ion channels as the density of a deterministic conductance across an area of membrane. __label__CONT
Although this formalism has been successful for simulating many aspects of neuronal activity, it is of less use for models that explore the consequences of the localization of individual ion channels, for example to evaluate the macroscopic effects of short range interactions between ion channels and other signaling molecules CITATION, or the consequences of spatially heterogeneous distributions of ion channels within relatively small sub-cellular structures such as dendritic spines and axon terminals CITATION, CITATION . __label__CONT
To address the functional consequences of stochastic ion channel gating in neurons with extensive dendritic or axonal arborizations we developed a parallel stochastic ion channel simulator, which enables efficient simulation of the electrical activity of neurons with complex morphologies and arbitrary localization of stochastic ion channels on the extracellular membrane, while also addressing limitations of previous approaches. __label__AIMX
Here, we illustrate the use of PSICS and ICING, outline the computational strategies used and provide benchmark data for evaluation. __label__OWNX
We then identify previously unappreciated differences between the effects of stochastic ion channel gating on somatic and dendritic membrane potential activity in several different morphological classes of neuron. __label__OWNX
We show that the consequences of stochastic gating depend on dendritic morphology and suggest novel functional roles for the kinetics of ion channel gating. __label__OWNX
We show that stochastic gating of axonal or dendritic ion channels substantially modifies synaptically driven dendritic and axonal spike output, with stochastic gating of voltage-dependent sodium and potassium channels having the greatest impact and hyperpolarization-activated channels the least. __label__OWNX
Full documentation for PSICS/ICING as well as the software, source code and examples are available from the project website . __label__OWNX
While differences in morphology define neuronal cell types and may underlie neurological disorders, very little is known about influences of stochastic ion channel gating in neurons with complex morphology. __label__MISC
We introduce and validate new computational tools that enable efficient generation and simulation of models containing stochastic ion channels distributed across dendritic and axonal membranes. __label__AIMX
Comparison of five morphologically distinct neuronal cell types reveals that when all simulated neurons contain identical densities of stochastic ion channels, the amplitude of stochastic membrane potential fluctuations differs between cell types and depends on sub-cellular location. __label__OWNX
For typical neurons, the amplitude of membrane potential fluctuations depends on channel kinetics as well as open probability. __label__OWNX
Using a detailed model of a hippocampal CA1 pyramidal neuron, we show that when intrinsic ion channels gate stochastically, the probability of initiation of dendritic or somatic spikes by dendritic synaptic input varies continuously between zero and one, whereas when ion channels gate deterministically, the probability is either zero or one. __label__OWNX
At physiological firing rates, stochastic gating of dendritic ion channels almost completely accounts for probabilistic somatic and dendritic spikes generated by the fully stochastic model. __label__OWNX
These results suggest that the consequences of stochastic ion channel gating differ globally between neuronal cell-types and locally between neuronal compartments. __label__OWNX
Whereas dendritic neurons are often assumed to behave deterministically, our simulations suggest that a direct consequence of stochastic gating of intrinsic ion channels is that spike output may instead be a probabilistic function of patterns of synaptic input to dendrites. __label__OWNX
The appropriate level of physical detail required to understand how complex processes such as cognition and behavior emerge from more simple biological structures is unclear CITATION, CITATION. __label__MISC
For example, while it is possible to account for certain aspects of nervous system function using models that represent each neuron as a simple integrate and fire device, it is increasingly clear that this approach does not capture the full range of computations that many real neurons carry out CITATION, CITATION. __label__CONT
Dendritic and axonal morphology are defining features of neuronal cell types and have important influences on the computations that a neuron performs CITATION. __label__MISC
Differences in morphology determine how neurons respond to synaptic input and are sufficient to produce distinct patterns of spontaneous activity CITATION and degrees of action potential back-propagation from the soma into the dendrites CITATION. __label__MISC
Cable theory and compartmental modeling provide a foundation for predicting the propagation of electrical signals in the dendrites and axons of neurons CITATION, CITATION. __label__BASE
However, while the assumption that transitions between open and closed states of ion channels can be treated as a deterministic process may be sufficient for some purposes, recent evidence suggests that stochastic transitions between the states of individual ion channels could influence computations carried out by neurons CITATION CITATION. __label__MISC
Stochastic opening and closing of ion channels causes noisy fluctuations in the current or voltage recorded from a neuron CITATION CITATION. __label__MISC
While cable theory suggests that fluctuations of this kind might be particularly important in fine structures such as axons and dendrites CITATION, we nevertheless know very little about how neuronal morphology and stochastic gating of ion channels interact to determine how neurons respond to synaptic input. __label__CONT
Given the difficulty of reducing detailed morphological models to simple analytical forms that could also incorporate stochastic gating of individual ion channels CITATION, experimentally constrained numerical simulations will be important to enable these issues to be explored systematically. __label__MISC
Investigation of stochastic ion channel gating using numerical simulations has been limited by trades-offs between simulation accuracy and computation time CITATION. __label__CONT
A simple approach is to add noise sources to deterministic models. __label__MISC
However, as ion channels have multiple functional states with transitions that often depend on the membrane voltage CITATION, CITATION, CITATION, CITATION, this may not accurately account for the noise introduced by ion channel currents. __label__CONT
A more accurate alternative is to explicitly model transitions between different functional states for each ion channel on a neuron's membrane. __label__MISC
However, for neurons with complex axonal or dendritic architectures there are two substantial obstacles to this approach. __label__CONT
This is a formidable computational task and even relatively straightforward simulations of the consequences of stochastic channel gating can require substantial computing time. __label__CONT
Second, each neuronal ion channel occupies a specific location on the extra-cellular membrane, whereas most neuronal models represent the distribution of ion channels as the density of a deterministic conductance across an area of membrane. __label__CONT
Although this formalism has been successful for simulating many aspects of neuronal activity, it is of less use for models that explore the consequences of the localization of individual ion channels, for example to evaluate the macroscopic effects of short range interactions between ion channels and other signaling molecules CITATION, or the consequences of spatially heterogeneous distributions of ion channels within relatively small sub-cellular structures such as dendritic spines and axon terminals CITATION, CITATION . __label__CONT
To address the functional consequences of stochastic ion channel gating in neurons with extensive dendritic or axonal arborizations we developed a parallel stochastic ion channel simulator, which enables efficient simulation of the electrical activity of neurons with complex morphologies and arbitrary localization of stochastic ion channels on the extracellular membrane, while also addressing limitations of previous approaches. __label__AIMX
We have also developed an interactive tool for visualization and development of models of neurons containing uniquely located ion channels. __label__OWNX
Here, we illustrate the use of PSICS and ICING, outline the computational strategies used and provide benchmark data for evaluation. __label__OWNX
We then identify previously unappreciated differences between the effects of stochastic ion channel gating on somatic and dendritic membrane potential activity in several different morphological classes of neuron. __label__OWNX
We show that the consequences of stochastic gating depend on dendritic morphology and suggest novel functional roles for the kinetics of ion channel gating. __label__OWNX
Using a previously well-validated realistic model of a CA1 pyramidal neuron we demonstrate that stochastic ion channel gating influences spike output in response to dendritic synaptic input. __label__BASE
We show that stochastic gating of axonal or dendritic ion channels substantially modifies synaptically driven dendritic and axonal spike output, with stochastic gating of voltage-dependent sodium and potassium channels having the greatest impact and hyperpolarization-activated channels the least. __label__OWNX
By demonstrating that neuronal responses to dendritic synaptic input can be intrinsically probabilistic, these results offer a new and general perspective on synaptic integration by central neurons. __label__OWNX
Full documentation for PSICS/ICING as well as the software, source code and examples are available from the project website . __label__OWNX
Neuronal activity is mediated through changes in the probability of stochastic transitions between open and closed states of ion channels. __label__MISC
We introduce and validate new computational tools that enable efficient generation and simulation of models containing stochastic ion channels distributed across dendritic and axonal membranes. __label__AIMX
Comparison of five morphologically distinct neuronal cell types reveals that when all simulated neurons contain identical densities of stochastic ion channels, the amplitude of stochastic membrane potential fluctuations differs between cell types and depends on sub-cellular location. __label__OWNX
For typical neurons, the amplitude of membrane potential fluctuations depends on channel kinetics as well as open probability. __label__MISC
Using a detailed model of a hippocampal CA1 pyramidal neuron, we show that when intrinsic ion channels gate stochastically, the probability of initiation of dendritic or somatic spikes by dendritic synaptic input varies continuously between zero and one, whereas when ion channels gate deterministically, the probability is either zero or one. __label__OWNX
At physiological firing rates, stochastic gating of dendritic ion channels almost completely accounts for probabilistic somatic and dendritic spikes generated by the fully stochastic model. __label__OWNX
These results suggest that the consequences of stochastic ion channel gating differ globally between neuronal cell-types and locally between neuronal compartments. __label__OWNX
Whereas dendritic neurons are often assumed to behave deterministically, our simulations suggest that a direct consequence of stochastic gating of intrinsic ion channels is that spike output may instead be a probabilistic function of patterns of synaptic input to dendrites. __label__OWNX
The appropriate level of physical detail required to understand how complex processes such as cognition and behavior emerge from more simple biological structures is unclear CITATION, CITATION. __label__MISC
For example, while it is possible to account for certain aspects of nervous system function using models that represent each neuron as a simple integrate and fire device, it is increasingly clear that this approach does not capture the full range of computations that many real neurons carry out CITATION, CITATION. __label__MISC
Dendritic and axonal morphology are defining features of neuronal cell types and have important influences on the computations that a neuron performs CITATION. __label__MISC
Differences in morphology determine how neurons respond to synaptic input and are sufficient to produce distinct patterns of spontaneous activity CITATION and degrees of action potential back-propagation from the soma into the dendrites CITATION. __label__MISC
Cable theory and compartmental modeling provide a foundation for predicting the propagation of electrical signals in the dendrites and axons of neurons CITATION, CITATION. __label__MISC
Stochastic opening and closing of ion channels causes noisy fluctuations in the current or voltage recorded from a neuron CITATION CITATION. __label__MISC
While cable theory suggests that fluctuations of this kind might be particularly important in fine structures such as axons and dendrites CITATION, we nevertheless know very little about how neuronal morphology and stochastic gating of ion channels interact to determine how neurons respond to synaptic input. __label__CONT
Given the difficulty of reducing detailed morphological models to simple analytical forms that could also incorporate stochastic gating of individual ion channels CITATION, experimentally constrained numerical simulations will be important to enable these issues to be explored systematically. __label__MISC
Investigation of stochastic ion channel gating using numerical simulations has been limited by trades-offs between simulation accuracy and computation time CITATION. __label__CONT
A simple approach is to add noise sources to deterministic models. __label__MISC
However, as ion channels have multiple functional states with transitions that often depend on the membrane voltage CITATION, CITATION, CITATION, CITATION, this may not accurately account for the noise introduced by ion channel currents. __label__CONT
A more accurate alternative is to explicitly model transitions between different functional states for each ion channel on a neuron's membrane. __label__MISC
However, for neurons with complex axonal or dendritic architectures there are two substantial obstacles to this approach. __label__CONT
This is a formidable computational task and even relatively straightforward simulations of the consequences of stochastic channel gating can require substantial computing time. __label__CONT
Second, each neuronal ion channel occupies a specific location on the extra-cellular membrane, whereas most neuronal models represent the distribution of ion channels as the density of a deterministic conductance across an area of membrane. __label__CONT
Although this formalism has been successful for simulating many aspects of neuronal activity, it is of less use for models that explore the consequences of the localization of individual ion channels, for example to evaluate the macroscopic effects of short range interactions between ion channels and other signaling molecules CITATION, or the consequences of spatially heterogeneous distributions of ion channels within relatively small sub-cellular structures such as dendritic spines and axon terminals CITATION, CITATION . __label__CONT
To address the functional consequences of stochastic ion channel gating in neurons with extensive dendritic or axonal arborizations we developed a parallel stochastic ion channel simulator, which enables efficient simulation of the electrical activity of neurons with complex morphologies and arbitrary localization of stochastic ion channels on the extracellular membrane, while also addressing limitations of previous approaches. __label__AIMX
Here, we illustrate the use of PSICS and ICING, outline the computational strategies used and provide benchmark data for evaluation. __label__OWNX
We then identify previously unappreciated differences between the effects of stochastic ion channel gating on somatic and dendritic membrane potential activity in several different morphological classes of neuron. __label__OWNX
We show that the consequences of stochastic gating depend on dendritic morphology and suggest novel functional roles for the kinetics of ion channel gating. __label__OWNX
Using a previously well-validated realistic model of a CA1 pyramidal neuron we demonstrate that stochastic ion channel gating influences spike output in response to dendritic synaptic input. __label__BASE
We show that stochastic gating of axonal or dendritic ion channels substantially modifies synaptically driven dendritic and axonal spike output, with stochastic gating of voltage-dependent sodium and potassium channels having the greatest impact and hyperpolarization-activated channels the least. __label__OWNX
By demonstrating that neuronal responses to dendritic synaptic input can be intrinsically probabilistic, these results offer a new and general perspective on synaptic integration by central neurons. __label__OWNX
Alternative splicing contributes to both gene regulation and protein diversity. __label__MISC
To discover broad relationships between regulation of alternative splicing and sequence conservation, we applied a systems approach, using oligonucleotide microarrays designed to capture splicing information across the mouse genome. __label__AIMX
In a set of 22 adult tissues, we observe differential expression of RNA containing at least two alternative splice junctions for about 40 percent of the 6,216 alternative events we could detect. __label__OWNX
Statistical comparisons identify 171 cassette exons whose inclusion or skipping is different in brain relative to other tissues and another 28 exons whose splicing is different in muscle. __label__OWNX
By focusing on sets of exons with similar regulatory patterns, we have identified new sequence motifs implicated in brain and muscle splicing regulation. __label__OWNX
Of note is a motif that is strikingly similar to the branchpoint consensus but is located downstream of the 5 splice site of exons included in muscle. __label__OWNX
Analysis of three paralogous membrane-associated guanylate kinase genes reveals that each contains a paralogous tissue-regulated exon with a similar tissue inclusion pattern. __label__OWNX
While the intron sequences flanking these exons remain highly conserved among mammalian orthologs, the paralogous flanking intron sequences have diverged considerably, suggesting unusually complex evolution of the regulation of alternative splicing in multigene families. __label__OWNX
Splicing is an essential process that constructs protein coding messenger RNA sequences using tiny segments of information buried in the much larger primary transcripts of the eukaryotic gene. __label__MISC
Splicing patterns seem distinct in the vertebrate nervous system compared to other tissues CITATION, CITATION, and it is tempting to hypothesize that neural alternative splicing contributed to the rapid evolution of the vertebrate brain without large increases in gene number CITATION . __label__MISC
Biochemical analysis of alternative splicing has shown that numerous RNA binding proteins influence the use of specific splice sites to stimulate splicing events that lead to particular mRNA isoforms CITATION, CITATION. __label__MISC
These RNA binding proteins may activate or repress the use of splice sites by binding to nearby sequences in the exon or in the intron. __label__MISC
In many cases, multiple RNA binding proteins combine to create repressing and activating influences that produce patterns of splicing control CITATION, CITATION. __label__MISC
Some proteins, such as SR proteins and the CELF proteins, have mostly activating roles, whereas others, such as hnRNP A1, PTB, and nPTB, have mostly repressing roles. __label__MISC
Certain proteins can either activate or repress splicing in different contexts, depending on the position of their binding sites or the expression of other RNA binding proteins CITATION, CITATION . __label__MISC
A complete catalog of the RNA sequences corresponding to the enhancers and silencers bound by splicing regulatory proteins would greatly aid the understanding of splicing regulatory networks. __label__MISC
Thus far, there are only a handful of splicing regulators whose corresponding RNA binding motifs have been identified, whereas there may be many splicing regulators among the hundreds of RNA binding proteins encoded by the mouse genome. __label__MISC
Adding to this complexity is the tendency for the mRNAs of RNA binding proteins to be alternatively spliced, leading to multiple RNA binding protein isoforms with potentially different functions. __label__MISC
Currently, the methods available for expanding the list of known regulators and their target sequences are limited, and the development of this catalog is in the early stage CITATION . __label__CONT
Much of the available genomic information on alternative splicing is derived by the alignment of large numbers of expressed sequence tags and messenger RNAs to genome sequences. __label__MISC
The analysis of exons that appear to be constitutive or alternative has led to the successful identification of many distinguishing features of alternatively spliced regions CITATION CITATION, even allowing their accurate prediction without cDNA evidence CITATION, CITATION, CITATION. __label__MISC
Although cDNA libraries have been invaluable for discovering general features of alternatively spliced exons, it is difficult to connect specific regulatory sequences to specific biological conditions with confidence due to variable and sometimes missing information about the source materials and methods of cDNA library construction. __label__CONT
The relatively low number of transcripts present from any one gene also makes it difficult to estimate differences in expression levels using library representation as a measure. __label__CONT
Thus, more direct methods are needed to associate alternative splicing events with underlying biological conditions. __label__MISC
The recent application of microarray technology to questions of splicing and splicing regulation promises to reveal parallel connections between many splicing events and specific biological or experimental conditions CITATION CITATION. __label__MISC
Analysis of experimental changes in splicing for many genes simultaneously should reveal biological conditions necessary for proper splicing regulation in a way that analysis of cDNA libraries cannot, and with breadth that cannot be achieved by analysis of a reporter construct or a few endogenous target genes. __label__MISC
To demonstrate this, we constructed a DNA microarray designed to capture splicing information for about 6,200 alternative events in the mouse transcriptome, using a combination of splice junction and exon probes, and have hybridized RNA from 22 adult mouse tissues. __label__OWNX
We examine splicing in these tissues by asking three questions. __label__AIMX
First we ask, Which RNA isoforms are present in a particular tissue sample? __label__OWNX
To answer this simple question, we used a new method based on comparing the intensity of the probes in a probe set to the distribution of intensities from all probes with similar G C level. __label__OWNX
This is similar in spirit although different in approach to the present-absent calls from Affymetrix MAS 5.0 algorithms CITATION, as this microarray did not contain mismatch probes. __label__BASE
Using RT-PCR, we show that this method has a true-positive rate of 85 percent. __label__OWNX
Second we ask, Which RNA isoforms are differentially expressed across the tissues examined? __label__OWNX
For each RNA isoform, the intensities of the isoform-specific junction probes were examined across tissues using the Kruskal-Wallis statistical test. __label__BASE
After correcting for multiple testing, about 40 percent of the 6,216 total alternative splicing events examined were found to have more than one RNA form that was differentially expressed, indicating widespread tissue differences in splicing over the tissues. __label__OWNX
To answer this, we used a regression-based bootstrapping method, which also allows an estimate of the relative change in skipping and inclusion in the two sample groups. __label__OWNX
We analyzed the intron sequences associated with exon skipping events that are differentially regulated in brain or muscle relative to other tissues and found unusual patterns of sequence conservation that provide new information about tissue regulation of alternative splicing and its evolution. __label__OWNX
To discover broad relationships between regulation of alternative splicing and sequence conservation, we applied a systems approach, using oligonucleotide microarrays designed to capture splicing information across the mouse genome. __label__AIMX
In a set of 22 adult tissues, we observe differential expression of RNA containing at least two alternative splice junctions for about 40 percent of the 6,216 alternative events we could detect. __label__OWNX
A subset of these exons is associated with unusual blocks of intron sequence whose conservation in vertebrates rivals that of protein-coding exons. __label__OWNX
By focusing on sets of exons with similar regulatory patterns, we have identified new sequence motifs implicated in brain and muscle splicing regulation. __label__OWNX
Of note is a motif that is strikingly similar to the branchpoint consensus but is located downstream of the 5 splice site of exons included in muscle. __label__OWNX
Analysis of three paralogous membrane-associated guanylate kinase genes reveals that each contains a paralogous tissue-regulated exon with a similar tissue inclusion pattern. __label__OWNX
While the intron sequences flanking these exons remain highly conserved among mammalian orthologs, the paralogous flanking intron sequences have diverged considerably, suggesting unusually complex evolution of the regulation of alternative splicing in multigene families. __label__OWNX
Regulated alternative splicing can create different protein coding sequences under different biological circumstances, allowing the production of functionally related but distinct proteins. __label__MISC
In addition, alternative splicing can mediate the repression of gene expression by stimulating the formation of transcripts subject to nonsense-mediated decay CITATION CITATION. __label__MISC
Splicing patterns seem distinct in the vertebrate nervous system compared to other tissues CITATION, CITATION, and it is tempting to hypothesize that neural alternative splicing contributed to the rapid evolution of the vertebrate brain without large increases in gene number CITATION . __label__MISC
Biochemical analysis of alternative splicing has shown that numerous RNA binding proteins influence the use of specific splice sites to stimulate splicing events that lead to particular mRNA isoforms CITATION, CITATION. __label__MISC
These RNA binding proteins may activate or repress the use of splice sites by binding to nearby sequences in the exon or in the intron. __label__MISC
Some proteins, such as SR proteins and the CELF proteins, have mostly activating roles, whereas others, such as hnRNP A1, PTB, and nPTB, have mostly repressing roles. __label__MISC
Certain proteins can either activate or repress splicing in different contexts, depending on the position of their binding sites or the expression of other RNA binding proteins CITATION, CITATION . __label__MISC
A complete catalog of the RNA sequences corresponding to the enhancers and silencers bound by splicing regulatory proteins would greatly aid the understanding of splicing regulatory networks. __label__MISC
In addition, several related but distinct genes produce proteins that bind the same or overlapping sets of sequences; for example, Fox-1 and RBM9 each bind UGCAUG CITATION, CITATION, and the branchpoint binding protein SF1 and the protein quaking each bind UACUAAC-like motifs CITATION CITATION. __label__MISC
Currently, the methods available for expanding the list of known regulators and their target sequences are limited, and the development of this catalog is in the early stage CITATION . __label__CONT
Much of the available genomic information on alternative splicing is derived by the alignment of large numbers of expressed sequence tags and messenger RNAs to genome sequences. __label__MISC
The analysis of exons that appear to be constitutive or alternative has led to the successful identification of many distinguishing features of alternatively spliced regions CITATION CITATION, even allowing their accurate prediction without cDNA evidence CITATION, CITATION, CITATION. __label__MISC
Although cDNA libraries have been invaluable for discovering general features of alternatively spliced exons, it is difficult to connect specific regulatory sequences to specific biological conditions with confidence due to variable and sometimes missing information about the source materials and methods of cDNA library construction. __label__CONT
The relatively low number of transcripts present from any one gene also makes it difficult to estimate differences in expression levels using library representation as a measure. __label__CONT
Thus, more direct methods are needed to associate alternative splicing events with underlying biological conditions. __label__MISC
The recent application of microarray technology to questions of splicing and splicing regulation promises to reveal parallel connections between many splicing events and specific biological or experimental conditions CITATION CITATION. __label__MISC
Analysis of experimental changes in splicing for many genes simultaneously should reveal biological conditions necessary for proper splicing regulation in a way that analysis of cDNA libraries cannot, and with breadth that cannot be achieved by analysis of a reporter construct or a few endogenous target genes. __label__MISC
To demonstrate this, we constructed a DNA microarray designed to capture splicing information for about 6,200 alternative events in the mouse transcriptome, using a combination of splice junction and exon probes, and have hybridized RNA from 22 adult mouse tissues. __label__OWNX
First we ask, Which RNA isoforms are present in a particular tissue sample? __label__OWNX
To answer this simple question, we used a new method based on comparing the intensity of the probes in a probe set to the distribution of intensities from all probes with similar G C level. __label__OWNX
This is similar in spirit although different in approach to the present-absent calls from Affymetrix MAS 5.0 algorithms CITATION, as this microarray did not contain mismatch probes. __label__BASE
Second we ask, Which RNA isoforms are differentially expressed across the tissues examined? __label__OWNX
For each RNA isoform, the intensities of the isoform-specific junction probes were examined across tissues using the Kruskal-Wallis statistical test. __label__BASE
Third we ask, Which cassette exons are included differentially between brain and nonbrain tissues? __label__OWNX
To answer this, we used a regression-based bootstrapping method, which also allows an estimate of the relative change in skipping and inclusion in the two sample groups. __label__OWNX
We analyzed the intron sequences associated with exon skipping events that are differentially regulated in brain or muscle relative to other tissues and found unusual patterns of sequence conservation that provide new information about tissue regulation of alternative splicing and its evolution. __label__OWNX
Alternative splicing contributes to both gene regulation and protein diversity. __label__MISC
To discover broad relationships between regulation of alternative splicing and sequence conservation, we applied a systems approach, using oligonucleotide microarrays designed to capture splicing information across the mouse genome. __label__AIMX
Statistical comparisons identify 171 cassette exons whose inclusion or skipping is different in brain relative to other tissues and another 28 exons whose splicing is different in muscle. __label__OWNX
A subset of these exons is associated with unusual blocks of intron sequence whose conservation in vertebrates rivals that of protein-coding exons. __label__OWNX
By focusing on sets of exons with similar regulatory patterns, we have identified new sequence motifs implicated in brain and muscle splicing regulation. __label__OWNX
Of note is a motif that is strikingly similar to the branchpoint consensus but is located downstream of the 5 splice site of exons included in muscle. __label__OWNX
Analysis of three paralogous membrane-associated guanylate kinase genes reveals that each contains a paralogous tissue-regulated exon with a similar tissue inclusion pattern. __label__OWNX
Splicing is an essential process that constructs protein coding messenger RNA sequences using tiny segments of information buried in the much larger primary transcripts of the eukaryotic gene. __label__MISC
Regulated alternative splicing can create different protein coding sequences under different biological circumstances, allowing the production of functionally related but distinct proteins. __label__MISC
Splicing patterns seem distinct in the vertebrate nervous system compared to other tissues CITATION, CITATION, and it is tempting to hypothesize that neural alternative splicing contributed to the rapid evolution of the vertebrate brain without large increases in gene number CITATION . __label__MISC
Biochemical analysis of alternative splicing has shown that numerous RNA binding proteins influence the use of specific splice sites to stimulate splicing events that lead to particular mRNA isoforms CITATION, CITATION. __label__MISC
These RNA binding proteins may activate or repress the use of splice sites by binding to nearby sequences in the exon or in the intron. __label__MISC
In many cases, multiple RNA binding proteins combine to create repressing and activating influences that produce patterns of splicing control CITATION, CITATION. __label__MISC
Certain proteins can either activate or repress splicing in different contexts, depending on the position of their binding sites or the expression of other RNA binding proteins CITATION, CITATION . __label__MISC
A complete catalog of the RNA sequences corresponding to the enhancers and silencers bound by splicing regulatory proteins would greatly aid the understanding of splicing regulatory networks. __label__MISC
Thus far, there are only a handful of splicing regulators whose corresponding RNA binding motifs have been identified, whereas there may be many splicing regulators among the hundreds of RNA binding proteins encoded by the mouse genome. __label__MISC
Adding to this complexity is the tendency for the mRNAs of RNA binding proteins to be alternatively spliced, leading to multiple RNA binding protein isoforms with potentially different functions. __label__MISC
Currently, the methods available for expanding the list of known regulators and their target sequences are limited, and the development of this catalog is in the early stage CITATION . __label__CONT
Much of the available genomic information on alternative splicing is derived by the alignment of large numbers of expressed sequence tags and messenger RNAs to genome sequences. __label__MISC
Although cDNA libraries have been invaluable for discovering general features of alternatively spliced exons, it is difficult to connect specific regulatory sequences to specific biological conditions with confidence due to variable and sometimes missing information about the source materials and methods of cDNA library construction. __label__CONT
The relatively low number of transcripts present from any one gene also makes it difficult to estimate differences in expression levels using library representation as a measure. __label__CONT
Thus, more direct methods are needed to associate alternative splicing events with underlying biological conditions. __label__CONT
Analysis of experimental changes in splicing for many genes simultaneously should reveal biological conditions necessary for proper splicing regulation in a way that analysis of cDNA libraries cannot, and with breadth that cannot be achieved by analysis of a reporter construct or a few endogenous target genes. __label__CONT
To demonstrate this, we constructed a DNA microarray designed to capture splicing information for about 6,200 alternative events in the mouse transcriptome, using a combination of splice junction and exon probes, and have hybridized RNA from 22 adult mouse tissues. __label__AIMX
We examine splicing in these tissues by asking three questions. __label__AIMX
First we ask, Which RNA isoforms are present in a particular tissue sample? __label__OWNX
To answer this simple question, we used a new method based on comparing the intensity of the probes in a probe set to the distribution of intensities from all probes with similar G C level. __label__OWNX
This is similar in spirit although different in approach to the present-absent calls from Affymetrix MAS 5.0 algorithms CITATION, as this microarray did not contain mismatch probes. __label__BASE
Second we ask, Which RNA isoforms are differentially expressed across the tissues examined? __label__OWNX
After correcting for multiple testing, about 40 percent of the 6,216 total alternative splicing events examined were found to have more than one RNA form that was differentially expressed, indicating widespread tissue differences in splicing over the tissues. __label__OWNX
Third we ask, Which cassette exons are included differentially between brain and nonbrain tissues? __label__OWNX
To answer this, we used a regression-based bootstrapping method, which also allows an estimate of the relative change in skipping and inclusion in the two sample groups. __label__OWNX
We analyzed the intron sequences associated with exon skipping events that are differentially regulated in brain or muscle relative to other tissues and found unusual patterns of sequence conservation that provide new information about tissue regulation of alternative splicing and its evolution. __label__OWNX
Recently, a new class of antiretroviral drugs has entered clinical practice that specifically bind to the co-receptor CCR5, and thus inhibit virus entry. __label__MISC
Accurate prediction of the co-receptor used by the virus in the patient is important as it allows for personalized selection of effective drugs and prognosis of disease progression. __label__MISC
The two-level method predicts usage of CXCR4 co-receptor for new V3 sequences within seconds, with an area under the ROC curve of 0.937 0.004. __label__OWNX
For instance, it quantifies the importance for co-receptor usage of a pocket that probably is responsible for binding sulfated tyrosine. __label__OWNX
Specific protein interactions are central to biological processes, and the infection of cells with viruses is no exception there. __label__MISC
In the case of pathogenic viruses, such protein interactions are potential targets for medical intervention. __label__MISC
An example of particularly high relevance is Human Immunodeficiency Virus 1. __label__MISC
HIV-1 enters human cells in a process that comprises several steps, including the binding of the viral gp120 protein to the cellular receptor protein CD4 and a co-receptor protein, usually one of the two chemokine receptors CCR5 and CXCR4 CITATION. __label__MISC
The type of co-receptor used by the virus, the so-called co-receptor tropism, has a prognostic value, since patients with a CXCR4-tropic virus progress faster to Acquired Immunodeficiency Syndrome compared to patients with a CCR5-tropic virus CITATION. __label__MISC
In addition to the purely X4- and R5-tropic viruses, there are also dual-tropic strains, able to use both co-receptors. __label__MISC
This has made the determination of co-receptor tropism directly relevant to anti-retroviral treatment, as CCR5-inhibitors are of course inactive against X4 virus. __label__MISC
The standard way of determining co-receptor tropism is by cell-based assays CITATION, CITATION. __label__MISC
The main drawbacks of these assays are that they are currently only carried out by a handful of specialized laboratories worldwide, and that the overall procedure typically takes several weeks. __label__CONT
This is a relatively fast and cheap standard procedure established in many clinics. __label__MISC
At first glance, genotypic testing for co-receptor tropism seems to be possible since the main molecular determinant of tropism is known to be the third variable loop of the viral glycoprotein gp120 CITATION, a peptide stretch of about 35 amino-acids with a disulfide bridge connecting the terminal cysteins. __label__MISC
Unfortunately, as suggested by its name, V3 is notorious for its high sequence variability CITATION including also some variability in length, and this has made it difficult to use it as a basis for genotypic co-receptor tropism testing. __label__CONT
Nevertheless, the relevance of the quest has prompted many groups to develop models that link properties of V3 to co-receptor tropism. __label__MISC
The importance of electrostatics for co-receptor tropism has been recognized early on, and the best-known model, the so-called 11/25-rule, refers to charges of V3-residues 11 and 25: if one of these is positive, then the virus is CXCR4-tropic CITATION, CITATION. __label__MISC
This rule has a specificity of more than 0.9, but only a low to moderate sensitivity of about 0.4 0.6, depending on the test data, which is not satisfactory for routine clinical application. __label__MISC
Still, prediction accuracies fall short of what seems reasonable for regular clinical use CITATION. __label__CONT
It is unclear whether the limited accuracies are the footprint of tropism-determinants outside V3, or the consequence of model imperfections. __label__MISC
A milestone for the understanding of co-receptor tropism was the X-ray structure of gp120 with the V3 loop in a biological context CITATION. __label__MISC
This paved the way for the development of prediction methods that use, in addition to V3 sequence, structural information. __label__MISC
To our knowledge, the first of these methods has been that of Sander et al. CITATION, which was mainly based on geometric distances of amino-acid pairs within the structure of V3. __label__MISC
By the latter we consider a seemingly trivial but fundamental fact that so far has not been thoroughly exploited: although V3 is highly variable, all X4-tropic V3 loops share one property, namely, they preferentially have a physical binding interaction with CXCR4, while R5-tropic V3 loops preferably interacts with CCR5. __label__OWNX
Human Immunodeficiency Virus 1 uses for entry into host cells a receptor and one of two co-receptors. __label__MISC
Recently, a new class of antiretroviral drugs has entered clinical practice that specifically bind to the co-receptor CCR5, and thus inhibit virus entry. __label__MISC
We have investigated whether it is possible to predict co-receptor usage accurately by analyzing the amino acid sequence of the main determinant of co-receptor usage, i.e., the third variable loop V3 of the gp120 protein. __label__AIMX
We developed a two-level machine learning approach that in the first level considers two different properties important for protein-protein binding derived from structural models of V3 and V3 sequences. __label__OWNX
The second level combines the two predictions of the first level. __label__OWNX
The two-level method predicts usage of CXCR4 co-receptor for new V3 sequences within seconds, with an area under the ROC curve of 0.937 0.004. __label__OWNX
Moreover, it is relatively robust against insertions and deletions, which frequently occur in V3. __label__OWNX
The approach could help clinicians to find optimal personalized treatments, and it offers new insights into the molecular basis of co-receptor usage. __label__OWNX
Specific protein interactions are central to biological processes, and the infection of cells with viruses is no exception there. __label__MISC
In the case of pathogenic viruses, such protein interactions are potential targets for medical intervention. __label__MISC
An example of particularly high relevance is Human Immunodeficiency Virus 1. __label__MISC
HIV-1 enters human cells in a process that comprises several steps, including the binding of the viral gp120 protein to the cellular receptor protein CD4 and a co-receptor protein, usually one of the two chemokine receptors CCR5 and CXCR4 CITATION. __label__MISC
The type of co-receptor used by the virus, the so-called co-receptor tropism, has a prognostic value, since patients with a CXCR4-tropic virus progress faster to Acquired Immunodeficiency Syndrome compared to patients with a CCR5-tropic virus CITATION. __label__MISC
In addition to the purely X4- and R5-tropic viruses, there are also dual-tropic strains, able to use both co-receptors. __label__MISC
Recently, the first drug that binds to CCR5, and thus inhibits productive binding of gp120, has been approved by regulatory authorities in several countries. __label__MISC
This has made the determination of co-receptor tropism directly relevant to anti-retroviral treatment, as CCR5-inhibitors are of course inactive against X4 virus. __label__MISC
The standard way of determining co-receptor tropism is by cell-based assays CITATION, CITATION. __label__MISC
The main drawbacks of these assays are that they are currently only carried out by a handful of specialized laboratories worldwide, and that the overall procedure typically takes several weeks. __label__CONT
These impediments to the wide application of entry inhibitors could be overcome by an approach similar to genotypic drug resistance testing CITATION, where drug resistance of a viral strain is inferred from comparison of mutational patterns obtained from sequencing parts of the genome of that strain with patterns of validated resistance mutations. __label__MISC
This is a relatively fast and cheap standard procedure established in many clinics. __label__MISC
At first glance, genotypic testing for co-receptor tropism seems to be possible since the main molecular determinant of tropism is known to be the third variable loop of the viral glycoprotein gp120 CITATION, a peptide stretch of about 35 amino-acids with a disulfide bridge connecting the terminal cysteins. __label__MISC
Nevertheless, the relevance of the quest has prompted many groups to develop models that link properties of V3 to co-receptor tropism. __label__MISC
The importance of electrostatics for co-receptor tropism has been recognized early on, and the best-known model, the so-called 11/25-rule, refers to charges of V3-residues 11 and 25: if one of these is positive, then the virus is CXCR4-tropic CITATION, CITATION. __label__MISC
To improve predictions from sequence, several groups have applied machine learning methods, such as artificial neural networks CITATION, position specific scoring matrices CITATION, decision trees, or support vector machines CITATION. __label__MISC
Still, prediction accuracies fall short of what seems reasonable for regular clinical use CITATION. __label__CONT
It is unclear whether the limited accuracies are the footprint of tropism-determinants outside V3, or the consequence of model imperfections. __label__MISC
A milestone for the understanding of co-receptor tropism was the X-ray structure of gp120 with the V3 loop in a biological context CITATION. __label__MISC
This paved the way for the development of prediction methods that use, in addition to V3 sequence, structural information. __label__MISC
Although our method, detailed in the following, relies on the same experimental structure by Huang et al. CITATION, it differs from that of Sander et al. in several respects, e.g. it deals with indels, and, perhaps most crucially, it uses as descriptors properties that directly determine interaction of V3 with the co-receptors. __label__BASE
By the latter we consider a seemingly trivial but fundamental fact that so far has not been thoroughly exploited: although V3 is highly variable, all X4-tropic V3 loops share one property, namely, they preferentially have a physical binding interaction with CXCR4, while R5-tropic V3 loops preferably interacts with CCR5. __label__OWNX
Human Immunodeficiency Virus 1 uses for entry into host cells a receptor and one of two co-receptors. __label__MISC
Recently, a new class of antiretroviral drugs has entered clinical practice that specifically bind to the co-receptor CCR5, and thus inhibit virus entry. __label__MISC
Accurate prediction of the co-receptor used by the virus in the patient is important as it allows for personalized selection of effective drugs and prognosis of disease progression. __label__MISC
The second level combines the two predictions of the first level. __label__OWNX
The two-level method predicts usage of CXCR4 co-receptor for new V3 sequences within seconds, with an area under the ROC curve of 0.937 0.004. __label__OWNX
Moreover, it is relatively robust against insertions and deletions, which frequently occur in V3. __label__OWNX
The approach could help clinicians to find optimal personalized treatments, and it offers new insights into the molecular basis of co-receptor usage. __label__OWNX
For instance, it quantifies the importance for co-receptor usage of a pocket that probably is responsible for binding sulfated tyrosine. __label__OWNX
Specific protein interactions are central to biological processes, and the infection of cells with viruses is no exception there. __label__MISC
In the case of pathogenic viruses, such protein interactions are potential targets for medical intervention. __label__MISC
An example of particularly high relevance is Human Immunodeficiency Virus 1. __label__MISC
HIV-1 enters human cells in a process that comprises several steps, including the binding of the viral gp120 protein to the cellular receptor protein CD4 and a co-receptor protein, usually one of the two chemokine receptors CCR5 and CXCR4 CITATION. __label__MISC
In addition to the purely X4- and R5-tropic viruses, there are also dual-tropic strains, able to use both co-receptors. __label__MISC
Recently, the first drug that binds to CCR5, and thus inhibits productive binding of gp120, has been approved by regulatory authorities in several countries. __label__MISC
This has made the determination of co-receptor tropism directly relevant to anti-retroviral treatment, as CCR5-inhibitors are of course inactive against X4 virus. __label__MISC
The standard way of determining co-receptor tropism is by cell-based assays CITATION, CITATION. __label__MISC
The main drawbacks of these assays are that they are currently only carried out by a handful of specialized laboratories worldwide, and that the overall procedure typically takes several weeks. __label__CONT
These impediments to the wide application of entry inhibitors could be overcome by an approach similar to genotypic drug resistance testing CITATION, where drug resistance of a viral strain is inferred from comparison of mutational patterns obtained from sequencing parts of the genome of that strain with patterns of validated resistance mutations. __label__MISC
This is a relatively fast and cheap standard procedure established in many clinics. __label__MISC
At first glance, genotypic testing for co-receptor tropism seems to be possible since the main molecular determinant of tropism is known to be the third variable loop of the viral glycoprotein gp120 CITATION, a peptide stretch of about 35 amino-acids with a disulfide bridge connecting the terminal cysteins. __label__MISC
Unfortunately, as suggested by its name, V3 is notorious for its high sequence variability CITATION including also some variability in length, and this has made it difficult to use it as a basis for genotypic co-receptor tropism testing. __label__MISC
The importance of electrostatics for co-receptor tropism has been recognized early on, and the best-known model, the so-called 11/25-rule, refers to charges of V3-residues 11 and 25: if one of these is positive, then the virus is CXCR4-tropic CITATION, CITATION. __label__MISC
This rule has a specificity of more than 0.9, but only a low to moderate sensitivity of about 0.4 0.6, depending on the test data, which is not satisfactory for routine clinical application. __label__CONT
To improve predictions from sequence, several groups have applied machine learning methods, such as artificial neural networks CITATION, position specific scoring matrices CITATION, decision trees, or support vector machines CITATION. __label__MISC
It is unclear whether the limited accuracies are the footprint of tropism-determinants outside V3, or the consequence of model imperfections. __label__MISC
A milestone for the understanding of co-receptor tropism was the X-ray structure of gp120 with the V3 loop in a biological context CITATION. __label__MISC
This paved the way for the development of prediction methods that use, in addition to V3 sequence, structural information. __label__MISC
To our knowledge, the first of these methods has been that of Sander et al. CITATION, which was mainly based on geometric distances of amino-acid pairs within the structure of V3. __label__MISC
By the latter we consider a seemingly trivial but fundamental fact that so far has not been thoroughly exploited: although V3 is highly variable, all X4-tropic V3 loops share one property, namely, they preferentially have a physical binding interaction with CXCR4, while R5-tropic V3 loops preferably interacts with CCR5. __label__OWNX
The accuracy of the method makes it attractive as clinical tool for patient tailored decisions on treatment with entry inhibitors, and it suggests that co-receptor tropism can be explained almost exclusively based on V3. __label__OWNX
